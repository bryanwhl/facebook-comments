{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Team-41.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "WITODYEvt2VG"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvjKcwp5tX-0"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from pandas.plotting import scatter_matrix\n",
        "from importlib import reload\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFY9ooxM6SMs"
      },
      "source": [
        "**Data Preprocessing**\n",
        "\n",
        "Reading datasets from github url (**Urls will expire after some time!** If the urls do not work, follow the steps below to get the new Urls)\n",
        "1. Go to https://github.com/bryanwhl/facebook-comments/tree/main/Dataset\n",
        "2. Go to the `Testing/TestSet/` folder.\n",
        "3. For all csv files, open them as raw and copy the url to this notebook.\n",
        "4. Repeat for all csv files in the `Training` folder.\n",
        "\n",
        "Adding a new column for the type of variant\n",
        "\n",
        "Combining columns with similar features (e.g. days)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaAS2X7n58sf"
      },
      "source": [
        "variant1 = 'https://raw.githubusercontent.com/bryanwhl/facebook-comments/main/Dataset/Training/Features_Variant_1.csv?token=AOHDW7AAMZJXPYSGR6C67XDBU5ZG4'\n",
        "variant2 = 'https://raw.githubusercontent.com/bryanwhl/facebook-comments/main/Dataset/Training/Features_Variant_2.csv?token=AOHDW7GLE337N6ZSTDXKNNTBU5ZHA'\n",
        "variant3 = 'https://raw.githubusercontent.com/bryanwhl/facebook-comments/main/Dataset/Training/Features_Variant_3.csv?token=AOHDW7EKC6UB42MC5KCL7WDBU5ZHC'\n",
        "variant4 = 'https://raw.githubusercontent.com/bryanwhl/facebook-comments/main/Dataset/Training/Features_Variant_4.csv?token=AOHDW7CHJDGBBYCH6DAU4ELBU5ZHE'\n",
        "variant5 = 'https://raw.githubusercontent.com/bryanwhl/facebook-comments/main/Dataset/Training/Features_Variant_5.csv?token=AOHDW7CLL254R4A7U6KQBZ3BU5ZHI'\n",
        "\n",
        "training_files = (variant1, variant2, variant3, variant4, variant5)\n",
        "\n",
        "test1 = \"https://raw.githubusercontent.com/bryanwhl/facebook-comments/main/Dataset/Testing/TestSet/Test_Case_1.csv?token=AOHDW7CAN6B62ON5WIAHP6LBU5ZLQ\"\n",
        "test2 = \"https://raw.githubusercontent.com/bryanwhl/facebook-comments/main/Dataset/Testing/TestSet/Test_Case_2.csv?token=AOHDW7C2ZF4WHMYTJ6RNFEDBU5ZLU\"\n",
        "test3 = \"https://raw.githubusercontent.com/bryanwhl/facebook-comments/main/Dataset/Testing/TestSet/Test_Case_3.csv?token=AOHDW7BBWTBGJ6VIBUIUWNLBU5ZLW\"\n",
        "test4 = \"https://raw.githubusercontent.com/bryanwhl/facebook-comments/main/Dataset/Testing/TestSet/Test_Case_4.csv?token=AOHDW7C254EV4TWEKTG7PT3BU5ZLY\"\n",
        "test5 = \"https://raw.githubusercontent.com/bryanwhl/facebook-comments/main/Dataset/Testing/TestSet/Test_Case_5.csv?token=AOHDW7AQASMAXUJDGBBRR5LBU5ZL2\"\n",
        "test6 = \"https://raw.githubusercontent.com/bryanwhl/facebook-comments/main/Dataset/Testing/TestSet/Test_Case_6.csv?token=AOHDW7DQPGGSQ5AEGWXU5SLBU5ZPY\"\n",
        "test7 = \"https://raw.githubusercontent.com/bryanwhl/facebook-comments/main/Dataset/Testing/TestSet/Test_Case_7.csv?token=AOHDW7AUFMFW2UMBD74XNNDBU5ZP4\"\n",
        "test8 = \"https://raw.githubusercontent.com/bryanwhl/facebook-comments/main/Dataset/Testing/TestSet/Test_Case_8.csv?token=AOHDW7APTGWEN7YXPQRFRCTBU5ZP6\"\n",
        "test9 = \"https://raw.githubusercontent.com/bryanwhl/facebook-comments/main/Dataset/Testing/TestSet/Test_Case_9.csv?token=AOHDW7CONSU2GPRJRW4VH33BU5ZQA\"\n",
        "test10 = \"https://raw.githubusercontent.com/bryanwhl/facebook-comments/main/Dataset/Testing/TestSet/Test_Case_10.csv?token=AOHDW7G4NNAW7ER37MCXRVDBU5ZQC\"\n",
        "\n",
        "testing_files = (test1, test2, test3, test4, test5, test6, test7, test8, test9, test10)\n",
        "\n",
        "COLUMNS = (\"page_likes\", \"page_checkins\", \"page_talking_about\", \"page_category\", \n",
        "           \"cc1_min\", \"cc1_max\", \"cc1_average\", \"cc1_median\", \"cc1_std\", \n",
        "           \"cc2_min\", \"cc2_max\", \"cc2_average\", \"cc2_median\", \"cc2_std\", \n",
        "           \"cc3_min\", \"cc3_max\", \"cc3_average\", \"cc3_median\", \"cc3_std\", \n",
        "           \"cc4_min\", \"cc4_max\", \"cc4_average\", \"cc4_median\", \"cc4_std\", \n",
        "           \"cc5_min\", \"cc5_max\", \"cc5_average\", \"cc5_median\", \"cc5_std\", \n",
        "           \"cc1\", \"cc2\", \"cc3\", \"cc4\", \"cc5\", \"base_time\", \n",
        "           \"post_length\", \"post_share_count\", \"post_promotion_status\", \"h_local\", \n",
        "           \"post_published_sun\", \"post_published_mon\", \"post_published_tues\", \n",
        "           \"post_published_wed\", \"post_published_thurs\", \"post_published_fri\", \n",
        "           \"post_published_sat\", \"base_datetime_sun\", \"base_datetime_mon\", \n",
        "           \"base_datetime_tues\", \"base_datetime_wed\", \"base_datetime_thurs\", \n",
        "           \"base_datetime_fri\", \"base_datetime_sat\", \"target\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imJUjAtcd26K"
      },
      "source": [
        "# Reads data from given url, returns list of dataframes, 1 df per url\n",
        "def read_data(urls):\n",
        "  df_list = []\n",
        "  for url in urls:\n",
        "    df = pd.read_csv(url, index_col=False, names=COLUMNS)\n",
        "    df_list.append(df)\n",
        "  return df_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW-Fp4mjCAP9"
      },
      "source": [
        "Add new column variant type for the 5 different variants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Rnd5urv8vGK"
      },
      "source": [
        "# Add a variant column based on the order of the dataframes in the dataframe list\n",
        "def add_variant_column(df_list):\n",
        "  for i in range(len(df_list)):\n",
        "    df = df_list[i]\n",
        "    df[\"variant-type\"] = i\n",
        "  return df_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4vlI0hjCFs0"
      },
      "source": [
        "Merge the day posted (col 39 - 45) and base day (46 - 52) into 1 column and drop the rest for different variants.\n",
        "\n",
        "1 = Sun, 2 = Mon, 3 = Tues, ..., 7 = Sat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw0YgoudAX7N"
      },
      "source": [
        "# Merge columns for Post_Day\n",
        "def merge_days(df_list):\n",
        "  for df in df_list:\n",
        "    df[\"Post_Day\"] = 0\n",
        "    post_Day = 1\n",
        "    cols = (\"post_published_sun\", \"post_published_mon\", \"post_published_tues\", \n",
        "            \"post_published_wed\", \"post_published_thurs\", \"post_published_fri\", \n",
        "            \"post_published_sat\")\n",
        "    for col in cols:\n",
        "      df.loc[df[col] == 1, 'Post_Day'] = post_Day\n",
        "      post_Day += 1\n",
        "  # Merge columns for Base_Day\n",
        "  for df in df_list:\n",
        "    df[\"Base_Day\"] = 0\n",
        "    base_Day = 1\n",
        "    cols = (\"base_datetime_sun\", \"base_datetime_mon\", \"base_datetime_tues\", \n",
        "            \"base_datetime_wed\", \"base_datetime_thurs\", \"base_datetime_fri\", \n",
        "            \"base_datetime_sat\")\n",
        "    for col in cols:\n",
        "      df.loc[df[col] == 1, 'Base_Day'] = base_Day\n",
        "      base_Day += 1\n",
        "  cols_To_Drop = [\"post_published_sun\", \"post_published_mon\", \"post_published_tues\", \n",
        "                  \"post_published_wed\", \"post_published_thurs\", \"post_published_fri\", \n",
        "                  \"post_published_sat\", \"base_datetime_sun\", \"base_datetime_mon\", \n",
        "                  \"base_datetime_tues\", \"base_datetime_wed\", \"base_datetime_thurs\", \n",
        "                  \"base_datetime_fri\", \"base_datetime_sat\"]\n",
        "  df_list2 = []\n",
        "  for df in df_list:\n",
        "    df.drop(cols_To_Drop, axis=1, inplace=True)\n",
        "    # Rearrange columns so that target col is last\n",
        "    cols = list(df.columns.values)\n",
        "    cols.pop(cols.index(\"target\"))\n",
        "    df = df[cols+[\"target\"]]\n",
        "    df_list2.append(df)\n",
        "    \n",
        "  return df_list2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-vnPkGrgpDT"
      },
      "source": [
        "def binarize_labels(df):\n",
        "  df['target'] = df[\"target\"].apply(lambda x: 1 if x > 0 else 0)\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuZx6_bXgTlA"
      },
      "source": [
        "def split_df(df):\n",
        "  features = df.drop(['target'], axis=1)\n",
        "  labels = df[\"target\"]\n",
        "  return features, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGw11pB-qjXK"
      },
      "source": [
        "**Human Heuristic**\n",
        "Remove columns 5-29 as they are derived features from feature 30-35"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJRpsV8xqfkr"
      },
      "source": [
        "def removeCols529(df):\n",
        "  df.drop(df.iloc[:, 4:29], inplace = True, axis = 1)\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsJcGcAXSAcK"
      },
      "source": [
        "**Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M-_CEvSSCiX"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def normalizeTrain(df):\n",
        "  scaler = StandardScaler()\n",
        "  array = scaler.fit_transform(df)\n",
        "\n",
        "  return pd.DataFrame(array, columns=df.columns), scaler\n",
        "\n",
        "\n",
        "def normalizeTrainTarget(df):\n",
        "  array = np.array(df).reshape(-1, 1)\n",
        "  scaler = StandardScaler()\n",
        "  array_transformed = scaler.fit_transform(array)\n",
        "\n",
        "  return pd.DataFrame(array_transformed, columns=[\"target\"]), scaler\n",
        "\n",
        "\n",
        "def normalizeTest(df, scaler):\n",
        "  array = scaler.transform(df)\n",
        "\n",
        "  return pd.DataFrame(array, columns=df.columns)\n",
        "\n",
        "\n",
        "def normalizeTestTarget(df, scaler):\n",
        "  array = np.array(df).reshape(-1, 1)\n",
        "  array_transformed = scaler.transform(array)\n",
        "\n",
        "  return pd.DataFrame(array_transformed, columns=[\"target\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s23ZATCzfCVI"
      },
      "source": [
        "### Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8gAWGE7nP3d"
      },
      "source": [
        "df_list = read_data(training_files)\n",
        "df_list = merge_days(df_list)\n",
        "df_list_2 = []\n",
        "for df in df_list:\n",
        "    df = binarize_labels(df)\n",
        "    df = df.drop(['post_promotion_status'], 1)\n",
        "    df_list_2.append(df)\n",
        "df_list = df_list_2\n",
        "merged_df = pd.concat(df_list)\n",
        "df_list.append(merged_df) # We now have variant 1 - 5 + merged of variant 1 - 5 as the 6th element\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "_tw46BAkUCk_",
        "outputId": "270eeba4-bb15-488b-e5a4-5ac769679c71"
      },
      "source": [
        "df1 = df_list[0]\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_likes</th>\n",
              "      <th>page_checkins</th>\n",
              "      <th>page_talking_about</th>\n",
              "      <th>page_category</th>\n",
              "      <th>cc1_min</th>\n",
              "      <th>cc1_max</th>\n",
              "      <th>cc1_average</th>\n",
              "      <th>cc1_median</th>\n",
              "      <th>cc1_std</th>\n",
              "      <th>cc2_min</th>\n",
              "      <th>cc2_max</th>\n",
              "      <th>cc2_average</th>\n",
              "      <th>cc2_median</th>\n",
              "      <th>cc2_std</th>\n",
              "      <th>cc3_min</th>\n",
              "      <th>cc3_max</th>\n",
              "      <th>cc3_average</th>\n",
              "      <th>cc3_median</th>\n",
              "      <th>cc3_std</th>\n",
              "      <th>cc4_min</th>\n",
              "      <th>cc4_max</th>\n",
              "      <th>cc4_average</th>\n",
              "      <th>cc4_median</th>\n",
              "      <th>cc4_std</th>\n",
              "      <th>cc5_min</th>\n",
              "      <th>cc5_max</th>\n",
              "      <th>cc5_average</th>\n",
              "      <th>cc5_median</th>\n",
              "      <th>cc5_std</th>\n",
              "      <th>cc1</th>\n",
              "      <th>cc2</th>\n",
              "      <th>cc3</th>\n",
              "      <th>cc4</th>\n",
              "      <th>cc5</th>\n",
              "      <th>base_time</th>\n",
              "      <th>post_length</th>\n",
              "      <th>post_share_count</th>\n",
              "      <th>h_local</th>\n",
              "      <th>Post_Day</th>\n",
              "      <th>Base_Day</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>634995</td>\n",
              "      <td>0</td>\n",
              "      <td>463</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>11.291045</td>\n",
              "      <td>1.0</td>\n",
              "      <td>70.495138</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>7.574627</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.435826</td>\n",
              "      <td>0.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>2.604478</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.505502</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>10.649254</td>\n",
              "      <td>1.0</td>\n",
              "      <td>70.254788</td>\n",
              "      <td>-69.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>4.970149</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.850580</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>65</td>\n",
              "      <td>166</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>634995</td>\n",
              "      <td>0</td>\n",
              "      <td>463</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>11.291045</td>\n",
              "      <td>1.0</td>\n",
              "      <td>70.495138</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>7.574627</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.435826</td>\n",
              "      <td>0.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>2.604478</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.505502</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>10.649254</td>\n",
              "      <td>1.0</td>\n",
              "      <td>70.254788</td>\n",
              "      <td>-69.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>4.970149</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.850580</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>132</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>634995</td>\n",
              "      <td>0</td>\n",
              "      <td>463</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>11.291045</td>\n",
              "      <td>1.0</td>\n",
              "      <td>70.495138</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>7.574627</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.435826</td>\n",
              "      <td>0.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>2.604478</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.505502</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>10.649254</td>\n",
              "      <td>1.0</td>\n",
              "      <td>70.254788</td>\n",
              "      <td>-69.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>4.970149</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.850580</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>133</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>634995</td>\n",
              "      <td>0</td>\n",
              "      <td>463</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>11.291045</td>\n",
              "      <td>1.0</td>\n",
              "      <td>70.495138</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>7.574627</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.435826</td>\n",
              "      <td>0.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>2.604478</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.505502</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>10.649254</td>\n",
              "      <td>1.0</td>\n",
              "      <td>70.254788</td>\n",
              "      <td>-69.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>4.970149</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.850580</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>-3</td>\n",
              "      <td>62</td>\n",
              "      <td>131</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>634995</td>\n",
              "      <td>0</td>\n",
              "      <td>463</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>11.291045</td>\n",
              "      <td>1.0</td>\n",
              "      <td>70.495138</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>7.574627</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.435826</td>\n",
              "      <td>0.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>2.604478</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.505502</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>10.649254</td>\n",
              "      <td>1.0</td>\n",
              "      <td>70.254788</td>\n",
              "      <td>-69.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>4.970149</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.850580</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>58</td>\n",
              "      <td>142</td>\n",
              "      <td>5</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40944</th>\n",
              "      <td>7170111</td>\n",
              "      <td>70</td>\n",
              "      <td>497000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>497.200000</td>\n",
              "      <td>269.0</td>\n",
              "      <td>502.318385</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>283.720000</td>\n",
              "      <td>75.0</td>\n",
              "      <td>463.431334</td>\n",
              "      <td>0.0</td>\n",
              "      <td>712.0</td>\n",
              "      <td>129.480000</td>\n",
              "      <td>71.0</td>\n",
              "      <td>189.682075</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>482.400000</td>\n",
              "      <td>240.0</td>\n",
              "      <td>495.255247</td>\n",
              "      <td>-449.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>154.240000</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>490.821538</td>\n",
              "      <td>269</td>\n",
              "      <td>14</td>\n",
              "      <td>58</td>\n",
              "      <td>240</td>\n",
              "      <td>-44</td>\n",
              "      <td>56</td>\n",
              "      <td>12</td>\n",
              "      <td>1511</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40945</th>\n",
              "      <td>7170111</td>\n",
              "      <td>70</td>\n",
              "      <td>497000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>497.200000</td>\n",
              "      <td>269.0</td>\n",
              "      <td>502.318385</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>283.720000</td>\n",
              "      <td>75.0</td>\n",
              "      <td>463.431334</td>\n",
              "      <td>0.0</td>\n",
              "      <td>712.0</td>\n",
              "      <td>129.480000</td>\n",
              "      <td>71.0</td>\n",
              "      <td>189.682075</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>482.400000</td>\n",
              "      <td>240.0</td>\n",
              "      <td>495.255247</td>\n",
              "      <td>-449.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>154.240000</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>490.821538</td>\n",
              "      <td>644</td>\n",
              "      <td>20</td>\n",
              "      <td>106</td>\n",
              "      <td>619</td>\n",
              "      <td>-86</td>\n",
              "      <td>53</td>\n",
              "      <td>149</td>\n",
              "      <td>1099</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40946</th>\n",
              "      <td>7170111</td>\n",
              "      <td>70</td>\n",
              "      <td>497000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>497.200000</td>\n",
              "      <td>269.0</td>\n",
              "      <td>502.318385</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>283.720000</td>\n",
              "      <td>75.0</td>\n",
              "      <td>463.431334</td>\n",
              "      <td>0.0</td>\n",
              "      <td>712.0</td>\n",
              "      <td>129.480000</td>\n",
              "      <td>71.0</td>\n",
              "      <td>189.682075</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>482.400000</td>\n",
              "      <td>240.0</td>\n",
              "      <td>495.255247</td>\n",
              "      <td>-449.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>154.240000</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>490.821538</td>\n",
              "      <td>620</td>\n",
              "      <td>620</td>\n",
              "      <td>0</td>\n",
              "      <td>620</td>\n",
              "      <td>620</td>\n",
              "      <td>19</td>\n",
              "      <td>120</td>\n",
              "      <td>2962</td>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40947</th>\n",
              "      <td>7170111</td>\n",
              "      <td>70</td>\n",
              "      <td>497000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>497.200000</td>\n",
              "      <td>269.0</td>\n",
              "      <td>502.318385</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>283.720000</td>\n",
              "      <td>75.0</td>\n",
              "      <td>463.431334</td>\n",
              "      <td>0.0</td>\n",
              "      <td>712.0</td>\n",
              "      <td>129.480000</td>\n",
              "      <td>71.0</td>\n",
              "      <td>189.682075</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>482.400000</td>\n",
              "      <td>240.0</td>\n",
              "      <td>495.255247</td>\n",
              "      <td>-449.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>154.240000</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>490.821538</td>\n",
              "      <td>629</td>\n",
              "      <td>189</td>\n",
              "      <td>440</td>\n",
              "      <td>588</td>\n",
              "      <td>-251</td>\n",
              "      <td>33</td>\n",
              "      <td>33</td>\n",
              "      <td>1383</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40948</th>\n",
              "      <td>7170111</td>\n",
              "      <td>70</td>\n",
              "      <td>497000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>497.200000</td>\n",
              "      <td>269.0</td>\n",
              "      <td>502.318385</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>283.720000</td>\n",
              "      <td>75.0</td>\n",
              "      <td>463.431334</td>\n",
              "      <td>0.0</td>\n",
              "      <td>712.0</td>\n",
              "      <td>129.480000</td>\n",
              "      <td>71.0</td>\n",
              "      <td>189.682075</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>482.400000</td>\n",
              "      <td>240.0</td>\n",
              "      <td>495.255247</td>\n",
              "      <td>-449.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>154.240000</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>490.821538</td>\n",
              "      <td>975</td>\n",
              "      <td>263</td>\n",
              "      <td>712</td>\n",
              "      <td>960</td>\n",
              "      <td>-449</td>\n",
              "      <td>29</td>\n",
              "      <td>133</td>\n",
              "      <td>3732</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40949 rows Ã— 41 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       page_likes  page_checkins  ...  Base_Day  target\n",
              "0          634995              0  ...         7       0\n",
              "1          634995              0  ...         6       0\n",
              "2          634995              0  ...         7       0\n",
              "3          634995              0  ...         2       0\n",
              "4          634995              0  ...         4       0\n",
              "...           ...            ...  ...       ...     ...\n",
              "40944     7170111             70  ...         6       1\n",
              "40945     7170111             70  ...         6       1\n",
              "40946     7170111             70  ...         5       1\n",
              "40947     7170111             70  ...         6       1\n",
              "40948     7170111             70  ...         6       1\n",
              "\n",
              "[40949 rows x 41 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "oVwaieECoQX0",
        "outputId": "8c4c1d01-23d4-43d9-f04a-337144d7afed"
      },
      "source": [
        "df1.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_likes</th>\n",
              "      <th>page_checkins</th>\n",
              "      <th>page_talking_about</th>\n",
              "      <th>page_category</th>\n",
              "      <th>cc1_min</th>\n",
              "      <th>cc1_max</th>\n",
              "      <th>cc1_average</th>\n",
              "      <th>cc1_median</th>\n",
              "      <th>cc1_std</th>\n",
              "      <th>cc2_min</th>\n",
              "      <th>cc2_max</th>\n",
              "      <th>cc2_average</th>\n",
              "      <th>cc2_median</th>\n",
              "      <th>cc2_std</th>\n",
              "      <th>cc3_min</th>\n",
              "      <th>cc3_max</th>\n",
              "      <th>cc3_average</th>\n",
              "      <th>cc3_median</th>\n",
              "      <th>cc3_std</th>\n",
              "      <th>cc4_min</th>\n",
              "      <th>cc4_max</th>\n",
              "      <th>cc4_average</th>\n",
              "      <th>cc4_median</th>\n",
              "      <th>cc4_std</th>\n",
              "      <th>cc5_min</th>\n",
              "      <th>cc5_max</th>\n",
              "      <th>cc5_average</th>\n",
              "      <th>cc5_median</th>\n",
              "      <th>cc5_std</th>\n",
              "      <th>cc1</th>\n",
              "      <th>cc2</th>\n",
              "      <th>cc3</th>\n",
              "      <th>cc4</th>\n",
              "      <th>cc5</th>\n",
              "      <th>base_time</th>\n",
              "      <th>post_length</th>\n",
              "      <th>post_share_count</th>\n",
              "      <th>h_local</th>\n",
              "      <th>Post_Day</th>\n",
              "      <th>Base_Day</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4.094900e+04</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>4.094900e+04</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "      <td>40949.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.313814e+06</td>\n",
              "      <td>4676.133752</td>\n",
              "      <td>4.480025e+04</td>\n",
              "      <td>24.254780</td>\n",
              "      <td>1.586241</td>\n",
              "      <td>443.333854</td>\n",
              "      <td>55.720384</td>\n",
              "      <td>35.645535</td>\n",
              "      <td>67.464151</td>\n",
              "      <td>0.219468</td>\n",
              "      <td>285.187428</td>\n",
              "      <td>22.186647</td>\n",
              "      <td>7.503724</td>\n",
              "      <td>40.474206</td>\n",
              "      <td>0.024103</td>\n",
              "      <td>268.358275</td>\n",
              "      <td>19.649686</td>\n",
              "      <td>4.921537</td>\n",
              "      <td>38.728848</td>\n",
              "      <td>1.497253</td>\n",
              "      <td>415.395297</td>\n",
              "      <td>52.631591</td>\n",
              "      <td>34.042370</td>\n",
              "      <td>63.154906</td>\n",
              "      <td>-220.046619</td>\n",
              "      <td>275.403722</td>\n",
              "      <td>2.536961</td>\n",
              "      <td>-2.020904</td>\n",
              "      <td>55.840996</td>\n",
              "      <td>55.720384</td>\n",
              "      <td>22.186647</td>\n",
              "      <td>19.649686</td>\n",
              "      <td>52.631591</td>\n",
              "      <td>2.536961</td>\n",
              "      <td>35.322035</td>\n",
              "      <td>163.652470</td>\n",
              "      <td>117.249823</td>\n",
              "      <td>23.767833</td>\n",
              "      <td>4.043737</td>\n",
              "      <td>4.045715</td>\n",
              "      <td>0.448607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>6.785752e+06</td>\n",
              "      <td>20593.184863</td>\n",
              "      <td>1.109338e+05</td>\n",
              "      <td>19.950583</td>\n",
              "      <td>20.753174</td>\n",
              "      <td>496.695198</td>\n",
              "      <td>86.933548</td>\n",
              "      <td>69.960232</td>\n",
              "      <td>81.568249</td>\n",
              "      <td>10.055146</td>\n",
              "      <td>374.441728</td>\n",
              "      <td>36.930662</td>\n",
              "      <td>21.778756</td>\n",
              "      <td>54.277774</td>\n",
              "      <td>1.981360</td>\n",
              "      <td>327.063844</td>\n",
              "      <td>31.094112</td>\n",
              "      <td>13.245799</td>\n",
              "      <td>50.846434</td>\n",
              "      <td>18.715475</td>\n",
              "      <td>472.380251</td>\n",
              "      <td>81.264281</td>\n",
              "      <td>66.153081</td>\n",
              "      <td>76.403985</td>\n",
              "      <td>281.814185</td>\n",
              "      <td>373.330611</td>\n",
              "      <td>17.544907</td>\n",
              "      <td>14.720873</td>\n",
              "      <td>73.811134</td>\n",
              "      <td>136.975705</td>\n",
              "      <td>77.124263</td>\n",
              "      <td>71.078576</td>\n",
              "      <td>128.179920</td>\n",
              "      <td>94.202974</td>\n",
              "      <td>20.916864</td>\n",
              "      <td>376.264387</td>\n",
              "      <td>945.006667</td>\n",
              "      <td>1.919829</td>\n",
              "      <td>1.945059</td>\n",
              "      <td>1.992687</td>\n",
              "      <td>0.497358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>3.600000e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1366.000000</td>\n",
              "      <td>-204.000000</td>\n",
              "      <td>-210.500000</td>\n",
              "      <td>-288.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1366.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.673400e+04</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.980000e+02</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>5.527273</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>8.278756</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>1.911290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.109465</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>2.030303</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.094580</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>5.218182</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>7.600215</td>\n",
              "      <td>-310.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>-0.483221</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>5.990950</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>-6.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.929110e+05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.045000e+03</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>241.000000</td>\n",
              "      <td>23.374101</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>35.069140</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>8.437500</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>17.382709</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>116.000000</td>\n",
              "      <td>8.584270</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>18.639984</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>224.000000</td>\n",
              "      <td>21.859375</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>32.368848</td>\n",
              "      <td>-92.000000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>0.273810</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.547172</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.204214e+06</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>5.026400e+04</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>717.000000</td>\n",
              "      <td>71.828829</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>102.554954</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>405.000000</td>\n",
              "      <td>29.005525</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>60.760334</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>381.000000</td>\n",
              "      <td>24.842520</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>54.523165</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>676.000000</td>\n",
              "      <td>67.913793</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>96.266919</td>\n",
              "      <td>-21.000000</td>\n",
              "      <td>379.000000</td>\n",
              "      <td>2.974684</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.209289</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>172.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.869723e+08</td>\n",
              "      <td>186370.000000</td>\n",
              "      <td>6.089942e+06</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>731.394558</td>\n",
              "      <td>1923.000000</td>\n",
              "      <td>2079.000000</td>\n",
              "      <td>1923.000000</td>\n",
              "      <td>1923.000000</td>\n",
              "      <td>469.538781</td>\n",
              "      <td>324.000000</td>\n",
              "      <td>1605.000000</td>\n",
              "      <td>437.684211</td>\n",
              "      <td>433.000000</td>\n",
              "      <td>533.638557</td>\n",
              "      <td>1923.000000</td>\n",
              "      <td>2184.000000</td>\n",
              "      <td>1923.000000</td>\n",
              "      <td>1923.000000</td>\n",
              "      <td>703.144050</td>\n",
              "      <td>1923.000000</td>\n",
              "      <td>2079.000000</td>\n",
              "      <td>1923.000000</td>\n",
              "      <td>1923.000000</td>\n",
              "      <td>749.709600</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>2079.000000</td>\n",
              "      <td>1605.000000</td>\n",
              "      <td>2184.000000</td>\n",
              "      <td>2079.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>21480.000000</td>\n",
              "      <td>144860.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         page_likes  page_checkins  ...      Base_Day        target\n",
              "count  4.094900e+04   40949.000000  ...  40949.000000  40949.000000\n",
              "mean   1.313814e+06    4676.133752  ...      4.045715      0.448607\n",
              "std    6.785752e+06   20593.184863  ...      1.992687      0.497358\n",
              "min    3.600000e+01       0.000000  ...      1.000000      0.000000\n",
              "25%    3.673400e+04       0.000000  ...      2.000000      0.000000\n",
              "50%    2.929110e+05       0.000000  ...      4.000000      0.000000\n",
              "75%    1.204214e+06      99.000000  ...      6.000000      1.000000\n",
              "max    4.869723e+08  186370.000000  ...      7.000000      1.000000\n",
              "\n",
              "[8 rows x 41 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGoYx-YEoYee"
      },
      "source": [
        "Maybe can consider removing `post_promotion_status` since all the values are 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "dAXgqarKpkfy",
        "outputId": "13d86c58-0bfb-4086-ee7a-a5f745ac5fed"
      },
      "source": [
        "from sklearn.preprocessing import scale\n",
        "\n",
        "features, target = split_df(df1)\n",
        "array = np.array(target).reshape(-1, 1)\n",
        "scaler = StandardScaler()\n",
        "target_transformed = scaler.fit_transform(array)\n",
        "target_transformed = pd.DataFrame(target_transformed, columns=[\"target\"])\n",
        "pd.DataFrame(scaler.inverse_transform(target_transformed))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40944</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40945</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40946</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40947</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40948</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40949 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0\n",
              "0      0.0\n",
              "1      0.0\n",
              "2      0.0\n",
              "3      0.0\n",
              "4      0.0\n",
              "...    ...\n",
              "40944  1.0\n",
              "40945  1.0\n",
              "40946  1.0\n",
              "40947  1.0\n",
              "40948  1.0\n",
              "\n",
              "[40949 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "lwcmfGpOqag6",
        "outputId": "d77bf559-f655-4fb2-efb4-562b564b39ef"
      },
      "source": [
        "df2 = df_list[1]\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_likes</th>\n",
              "      <th>page_checkins</th>\n",
              "      <th>page_talking_about</th>\n",
              "      <th>page_category</th>\n",
              "      <th>cc1_min</th>\n",
              "      <th>cc1_max</th>\n",
              "      <th>cc1_average</th>\n",
              "      <th>cc1_median</th>\n",
              "      <th>cc1_std</th>\n",
              "      <th>cc2_min</th>\n",
              "      <th>cc2_max</th>\n",
              "      <th>cc2_average</th>\n",
              "      <th>cc2_median</th>\n",
              "      <th>cc2_std</th>\n",
              "      <th>cc3_min</th>\n",
              "      <th>cc3_max</th>\n",
              "      <th>cc3_average</th>\n",
              "      <th>cc3_median</th>\n",
              "      <th>cc3_std</th>\n",
              "      <th>cc4_min</th>\n",
              "      <th>cc4_max</th>\n",
              "      <th>cc4_average</th>\n",
              "      <th>cc4_median</th>\n",
              "      <th>cc4_std</th>\n",
              "      <th>cc5_min</th>\n",
              "      <th>cc5_max</th>\n",
              "      <th>cc5_average</th>\n",
              "      <th>cc5_median</th>\n",
              "      <th>cc5_std</th>\n",
              "      <th>cc1</th>\n",
              "      <th>cc2</th>\n",
              "      <th>cc3</th>\n",
              "      <th>cc4</th>\n",
              "      <th>cc5</th>\n",
              "      <th>base_time</th>\n",
              "      <th>post_length</th>\n",
              "      <th>post_share_count</th>\n",
              "      <th>h_local</th>\n",
              "      <th>Post_Day</th>\n",
              "      <th>Base_Day</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>634995</td>\n",
              "      <td>0</td>\n",
              "      <td>463</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1275.0</td>\n",
              "      <td>13.837736</td>\n",
              "      <td>1.0</td>\n",
              "      <td>103.361027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>372.0</td>\n",
              "      <td>4.098113</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.351525</td>\n",
              "      <td>0.0</td>\n",
              "      <td>725.0</td>\n",
              "      <td>5.679245</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49.700223</td>\n",
              "      <td>0.0</td>\n",
              "      <td>872.0</td>\n",
              "      <td>10.94717</td>\n",
              "      <td>1.0</td>\n",
              "      <td>76.051206</td>\n",
              "      <td>-353.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>-1.581132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.775975</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>166</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>634995</td>\n",
              "      <td>0</td>\n",
              "      <td>463</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1275.0</td>\n",
              "      <td>13.837736</td>\n",
              "      <td>1.0</td>\n",
              "      <td>103.361027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>372.0</td>\n",
              "      <td>4.098113</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.351525</td>\n",
              "      <td>0.0</td>\n",
              "      <td>725.0</td>\n",
              "      <td>5.679245</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49.700223</td>\n",
              "      <td>0.0</td>\n",
              "      <td>872.0</td>\n",
              "      <td>10.94717</td>\n",
              "      <td>1.0</td>\n",
              "      <td>76.051206</td>\n",
              "      <td>-353.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>-1.581132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.775975</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>132</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>634995</td>\n",
              "      <td>0</td>\n",
              "      <td>463</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1275.0</td>\n",
              "      <td>13.837736</td>\n",
              "      <td>1.0</td>\n",
              "      <td>103.361027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>372.0</td>\n",
              "      <td>4.098113</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.351525</td>\n",
              "      <td>0.0</td>\n",
              "      <td>725.0</td>\n",
              "      <td>5.679245</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49.700223</td>\n",
              "      <td>0.0</td>\n",
              "      <td>872.0</td>\n",
              "      <td>10.94717</td>\n",
              "      <td>1.0</td>\n",
              "      <td>76.051206</td>\n",
              "      <td>-353.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>-1.581132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.775975</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>133</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>634995</td>\n",
              "      <td>0</td>\n",
              "      <td>463</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1275.0</td>\n",
              "      <td>13.837736</td>\n",
              "      <td>1.0</td>\n",
              "      <td>103.361027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>372.0</td>\n",
              "      <td>4.098113</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.351525</td>\n",
              "      <td>0.0</td>\n",
              "      <td>725.0</td>\n",
              "      <td>5.679245</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49.700223</td>\n",
              "      <td>0.0</td>\n",
              "      <td>872.0</td>\n",
              "      <td>10.94717</td>\n",
              "      <td>1.0</td>\n",
              "      <td>76.051206</td>\n",
              "      <td>-353.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>-1.581132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.775975</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>131</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>634995</td>\n",
              "      <td>0</td>\n",
              "      <td>463</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1275.0</td>\n",
              "      <td>13.837736</td>\n",
              "      <td>1.0</td>\n",
              "      <td>103.361027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>372.0</td>\n",
              "      <td>4.098113</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.351525</td>\n",
              "      <td>0.0</td>\n",
              "      <td>725.0</td>\n",
              "      <td>5.679245</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49.700223</td>\n",
              "      <td>0.0</td>\n",
              "      <td>872.0</td>\n",
              "      <td>10.94717</td>\n",
              "      <td>1.0</td>\n",
              "      <td>76.051206</td>\n",
              "      <td>-353.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>-1.581132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.775975</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>47</td>\n",
              "      <td>142</td>\n",
              "      <td>5</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81307</th>\n",
              "      <td>7170111</td>\n",
              "      <td>70</td>\n",
              "      <td>497000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2147.0</td>\n",
              "      <td>497.620000</td>\n",
              "      <td>226.5</td>\n",
              "      <td>548.462976</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1219.0</td>\n",
              "      <td>196.560000</td>\n",
              "      <td>104.5</td>\n",
              "      <td>258.127733</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1669.0</td>\n",
              "      <td>222.220000</td>\n",
              "      <td>54.0</td>\n",
              "      <td>370.093085</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2082.0</td>\n",
              "      <td>473.52000</td>\n",
              "      <td>218.5</td>\n",
              "      <td>516.188153</td>\n",
              "      <td>-1225.0</td>\n",
              "      <td>960.0</td>\n",
              "      <td>-25.660000</td>\n",
              "      <td>-15.5</td>\n",
              "      <td>383.088638</td>\n",
              "      <td>172</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>172</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>1511</td>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81308</th>\n",
              "      <td>7170111</td>\n",
              "      <td>70</td>\n",
              "      <td>497000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2147.0</td>\n",
              "      <td>497.620000</td>\n",
              "      <td>226.5</td>\n",
              "      <td>548.462976</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1219.0</td>\n",
              "      <td>196.560000</td>\n",
              "      <td>104.5</td>\n",
              "      <td>258.127733</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1669.0</td>\n",
              "      <td>222.220000</td>\n",
              "      <td>54.0</td>\n",
              "      <td>370.093085</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2082.0</td>\n",
              "      <td>473.52000</td>\n",
              "      <td>218.5</td>\n",
              "      <td>516.188153</td>\n",
              "      <td>-1225.0</td>\n",
              "      <td>960.0</td>\n",
              "      <td>-25.660000</td>\n",
              "      <td>-15.5</td>\n",
              "      <td>383.088638</td>\n",
              "      <td>634</td>\n",
              "      <td>58</td>\n",
              "      <td>576</td>\n",
              "      <td>619</td>\n",
              "      <td>-518</td>\n",
              "      <td>39</td>\n",
              "      <td>149</td>\n",
              "      <td>1099</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81309</th>\n",
              "      <td>7170111</td>\n",
              "      <td>70</td>\n",
              "      <td>497000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2147.0</td>\n",
              "      <td>497.620000</td>\n",
              "      <td>226.5</td>\n",
              "      <td>548.462976</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1219.0</td>\n",
              "      <td>196.560000</td>\n",
              "      <td>104.5</td>\n",
              "      <td>258.127733</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1669.0</td>\n",
              "      <td>222.220000</td>\n",
              "      <td>54.0</td>\n",
              "      <td>370.093085</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2082.0</td>\n",
              "      <td>473.52000</td>\n",
              "      <td>218.5</td>\n",
              "      <td>516.188153</td>\n",
              "      <td>-1225.0</td>\n",
              "      <td>960.0</td>\n",
              "      <td>-25.660000</td>\n",
              "      <td>-15.5</td>\n",
              "      <td>383.088638</td>\n",
              "      <td>620</td>\n",
              "      <td>620</td>\n",
              "      <td>0</td>\n",
              "      <td>620</td>\n",
              "      <td>620</td>\n",
              "      <td>19</td>\n",
              "      <td>120</td>\n",
              "      <td>2962</td>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81310</th>\n",
              "      <td>7170111</td>\n",
              "      <td>70</td>\n",
              "      <td>497000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2147.0</td>\n",
              "      <td>497.620000</td>\n",
              "      <td>226.5</td>\n",
              "      <td>548.462976</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1219.0</td>\n",
              "      <td>196.560000</td>\n",
              "      <td>104.5</td>\n",
              "      <td>258.127733</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1669.0</td>\n",
              "      <td>222.220000</td>\n",
              "      <td>54.0</td>\n",
              "      <td>370.093085</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2082.0</td>\n",
              "      <td>473.52000</td>\n",
              "      <td>218.5</td>\n",
              "      <td>516.188153</td>\n",
              "      <td>-1225.0</td>\n",
              "      <td>960.0</td>\n",
              "      <td>-25.660000</td>\n",
              "      <td>-15.5</td>\n",
              "      <td>383.088638</td>\n",
              "      <td>643</td>\n",
              "      <td>137</td>\n",
              "      <td>506</td>\n",
              "      <td>588</td>\n",
              "      <td>-369</td>\n",
              "      <td>36</td>\n",
              "      <td>33</td>\n",
              "      <td>1383</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81311</th>\n",
              "      <td>7170111</td>\n",
              "      <td>70</td>\n",
              "      <td>497000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2147.0</td>\n",
              "      <td>497.620000</td>\n",
              "      <td>226.5</td>\n",
              "      <td>548.462976</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1219.0</td>\n",
              "      <td>196.560000</td>\n",
              "      <td>104.5</td>\n",
              "      <td>258.127733</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1669.0</td>\n",
              "      <td>222.220000</td>\n",
              "      <td>54.0</td>\n",
              "      <td>370.093085</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2082.0</td>\n",
              "      <td>473.52000</td>\n",
              "      <td>218.5</td>\n",
              "      <td>516.188153</td>\n",
              "      <td>-1225.0</td>\n",
              "      <td>960.0</td>\n",
              "      <td>-25.660000</td>\n",
              "      <td>-15.5</td>\n",
              "      <td>383.088638</td>\n",
              "      <td>960</td>\n",
              "      <td>960</td>\n",
              "      <td>0</td>\n",
              "      <td>960</td>\n",
              "      <td>960</td>\n",
              "      <td>24</td>\n",
              "      <td>133</td>\n",
              "      <td>3732</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>81312 rows Ã— 41 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       page_likes  page_checkins  ...  Base_Day  target\n",
              "0          634995              0  ...         6       0\n",
              "1          634995              0  ...         6       0\n",
              "2          634995              0  ...         7       0\n",
              "3          634995              0  ...         7       1\n",
              "4          634995              0  ...         4       0\n",
              "...           ...            ...  ...       ...     ...\n",
              "81307     7170111             70  ...         4       1\n",
              "81308     7170111             70  ...         5       1\n",
              "81309     7170111             70  ...         5       1\n",
              "81310     7170111             70  ...         6       1\n",
              "81311     7170111             70  ...         5       1\n",
              "\n",
              "[81312 rows x 41 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5p_GO5eq-5O"
      },
      "source": [
        "Since the attributes to be removed are the same for all variants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "uJiTAqHC1tPa",
        "outputId": "82289a6c-52ae-45f0-b622-7504f78a557f"
      },
      "source": [
        "df_list = read_data(training_files)\n",
        "df_list = merge_days(df_list)\n",
        "df_list_2 = []\n",
        "\n",
        "for df in df_list:\n",
        "    df = df.drop(['post_promotion_status'], 1)\n",
        "    df = df[df['target'] != 0]\n",
        "    df_list_2.append(df)\n",
        "df_list = df_list_2\n",
        "merged_df = pd.concat(df_list)\n",
        "df_list.append(merged_df) # now have variant 1 - 5 + merged of variant 1 - 5\n",
        "\n",
        "df1 = df_list[0]\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_likes</th>\n",
              "      <th>page_checkins</th>\n",
              "      <th>page_talking_about</th>\n",
              "      <th>page_category</th>\n",
              "      <th>cc1_min</th>\n",
              "      <th>cc1_max</th>\n",
              "      <th>cc1_average</th>\n",
              "      <th>cc1_median</th>\n",
              "      <th>cc1_std</th>\n",
              "      <th>cc2_min</th>\n",
              "      <th>cc2_max</th>\n",
              "      <th>cc2_average</th>\n",
              "      <th>cc2_median</th>\n",
              "      <th>cc2_std</th>\n",
              "      <th>cc3_min</th>\n",
              "      <th>cc3_max</th>\n",
              "      <th>cc3_average</th>\n",
              "      <th>cc3_median</th>\n",
              "      <th>cc3_std</th>\n",
              "      <th>cc4_min</th>\n",
              "      <th>cc4_max</th>\n",
              "      <th>cc4_average</th>\n",
              "      <th>cc4_median</th>\n",
              "      <th>cc4_std</th>\n",
              "      <th>cc5_min</th>\n",
              "      <th>cc5_max</th>\n",
              "      <th>cc5_average</th>\n",
              "      <th>cc5_median</th>\n",
              "      <th>cc5_std</th>\n",
              "      <th>cc1</th>\n",
              "      <th>cc2</th>\n",
              "      <th>cc3</th>\n",
              "      <th>cc4</th>\n",
              "      <th>cc5</th>\n",
              "      <th>base_time</th>\n",
              "      <th>post_length</th>\n",
              "      <th>post_share_count</th>\n",
              "      <th>h_local</th>\n",
              "      <th>Post_Day</th>\n",
              "      <th>Base_Day</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>634995</td>\n",
              "      <td>0</td>\n",
              "      <td>463</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>11.291045</td>\n",
              "      <td>1.0</td>\n",
              "      <td>70.495138</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>7.574627</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.435826</td>\n",
              "      <td>0.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>2.604478</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.505502</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>10.649254</td>\n",
              "      <td>1.0</td>\n",
              "      <td>70.254788</td>\n",
              "      <td>-69.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>4.970149</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.850580</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>157</td>\n",
              "      <td>4</td>\n",
              "      <td>24</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>634995</td>\n",
              "      <td>0</td>\n",
              "      <td>463</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>11.291045</td>\n",
              "      <td>1.0</td>\n",
              "      <td>70.495138</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>7.574627</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.435826</td>\n",
              "      <td>0.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>2.604478</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.505502</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>10.649254</td>\n",
              "      <td>1.0</td>\n",
              "      <td>70.254788</td>\n",
              "      <td>-69.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>4.970149</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.850580</td>\n",
              "      <td>77</td>\n",
              "      <td>46</td>\n",
              "      <td>31</td>\n",
              "      <td>74</td>\n",
              "      <td>15</td>\n",
              "      <td>31</td>\n",
              "      <td>135</td>\n",
              "      <td>19</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>634995</td>\n",
              "      <td>0</td>\n",
              "      <td>463</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>11.291045</td>\n",
              "      <td>1.0</td>\n",
              "      <td>70.495138</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>7.574627</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.435826</td>\n",
              "      <td>0.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>2.604478</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.505502</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>10.649254</td>\n",
              "      <td>1.0</td>\n",
              "      <td>70.254788</td>\n",
              "      <td>-69.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>4.970149</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.850580</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>300</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>634995</td>\n",
              "      <td>0</td>\n",
              "      <td>463</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>11.291045</td>\n",
              "      <td>1.0</td>\n",
              "      <td>70.495138</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>7.574627</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.435826</td>\n",
              "      <td>0.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>2.604478</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.505502</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>10.649254</td>\n",
              "      <td>1.0</td>\n",
              "      <td>70.254788</td>\n",
              "      <td>-69.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>4.970149</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.850580</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>84</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>634995</td>\n",
              "      <td>0</td>\n",
              "      <td>463</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>11.291045</td>\n",
              "      <td>1.0</td>\n",
              "      <td>70.495138</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>7.574627</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.435826</td>\n",
              "      <td>0.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>2.604478</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.505502</td>\n",
              "      <td>0.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>10.649254</td>\n",
              "      <td>1.0</td>\n",
              "      <td>70.254788</td>\n",
              "      <td>-69.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>4.970149</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.850580</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>114</td>\n",
              "      <td>13</td>\n",
              "      <td>24</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40944</th>\n",
              "      <td>7170111</td>\n",
              "      <td>70</td>\n",
              "      <td>497000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>497.200000</td>\n",
              "      <td>269.0</td>\n",
              "      <td>502.318385</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>283.720000</td>\n",
              "      <td>75.0</td>\n",
              "      <td>463.431334</td>\n",
              "      <td>0.0</td>\n",
              "      <td>712.0</td>\n",
              "      <td>129.480000</td>\n",
              "      <td>71.0</td>\n",
              "      <td>189.682075</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>482.400000</td>\n",
              "      <td>240.0</td>\n",
              "      <td>495.255247</td>\n",
              "      <td>-449.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>154.240000</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>490.821538</td>\n",
              "      <td>269</td>\n",
              "      <td>14</td>\n",
              "      <td>58</td>\n",
              "      <td>240</td>\n",
              "      <td>-44</td>\n",
              "      <td>56</td>\n",
              "      <td>12</td>\n",
              "      <td>1511</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40945</th>\n",
              "      <td>7170111</td>\n",
              "      <td>70</td>\n",
              "      <td>497000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>497.200000</td>\n",
              "      <td>269.0</td>\n",
              "      <td>502.318385</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>283.720000</td>\n",
              "      <td>75.0</td>\n",
              "      <td>463.431334</td>\n",
              "      <td>0.0</td>\n",
              "      <td>712.0</td>\n",
              "      <td>129.480000</td>\n",
              "      <td>71.0</td>\n",
              "      <td>189.682075</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>482.400000</td>\n",
              "      <td>240.0</td>\n",
              "      <td>495.255247</td>\n",
              "      <td>-449.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>154.240000</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>490.821538</td>\n",
              "      <td>644</td>\n",
              "      <td>20</td>\n",
              "      <td>106</td>\n",
              "      <td>619</td>\n",
              "      <td>-86</td>\n",
              "      <td>53</td>\n",
              "      <td>149</td>\n",
              "      <td>1099</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40946</th>\n",
              "      <td>7170111</td>\n",
              "      <td>70</td>\n",
              "      <td>497000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>497.200000</td>\n",
              "      <td>269.0</td>\n",
              "      <td>502.318385</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>283.720000</td>\n",
              "      <td>75.0</td>\n",
              "      <td>463.431334</td>\n",
              "      <td>0.0</td>\n",
              "      <td>712.0</td>\n",
              "      <td>129.480000</td>\n",
              "      <td>71.0</td>\n",
              "      <td>189.682075</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>482.400000</td>\n",
              "      <td>240.0</td>\n",
              "      <td>495.255247</td>\n",
              "      <td>-449.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>154.240000</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>490.821538</td>\n",
              "      <td>620</td>\n",
              "      <td>620</td>\n",
              "      <td>0</td>\n",
              "      <td>620</td>\n",
              "      <td>620</td>\n",
              "      <td>19</td>\n",
              "      <td>120</td>\n",
              "      <td>2962</td>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40947</th>\n",
              "      <td>7170111</td>\n",
              "      <td>70</td>\n",
              "      <td>497000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>497.200000</td>\n",
              "      <td>269.0</td>\n",
              "      <td>502.318385</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>283.720000</td>\n",
              "      <td>75.0</td>\n",
              "      <td>463.431334</td>\n",
              "      <td>0.0</td>\n",
              "      <td>712.0</td>\n",
              "      <td>129.480000</td>\n",
              "      <td>71.0</td>\n",
              "      <td>189.682075</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>482.400000</td>\n",
              "      <td>240.0</td>\n",
              "      <td>495.255247</td>\n",
              "      <td>-449.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>154.240000</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>490.821538</td>\n",
              "      <td>629</td>\n",
              "      <td>189</td>\n",
              "      <td>440</td>\n",
              "      <td>588</td>\n",
              "      <td>-251</td>\n",
              "      <td>33</td>\n",
              "      <td>33</td>\n",
              "      <td>1383</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40948</th>\n",
              "      <td>7170111</td>\n",
              "      <td>70</td>\n",
              "      <td>497000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>497.200000</td>\n",
              "      <td>269.0</td>\n",
              "      <td>502.318385</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>283.720000</td>\n",
              "      <td>75.0</td>\n",
              "      <td>463.431334</td>\n",
              "      <td>0.0</td>\n",
              "      <td>712.0</td>\n",
              "      <td>129.480000</td>\n",
              "      <td>71.0</td>\n",
              "      <td>189.682075</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>482.400000</td>\n",
              "      <td>240.0</td>\n",
              "      <td>495.255247</td>\n",
              "      <td>-449.0</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>154.240000</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>490.821538</td>\n",
              "      <td>975</td>\n",
              "      <td>263</td>\n",
              "      <td>712</td>\n",
              "      <td>960</td>\n",
              "      <td>-449</td>\n",
              "      <td>29</td>\n",
              "      <td>133</td>\n",
              "      <td>3732</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18370 rows Ã— 41 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       page_likes  page_checkins  ...  Base_Day  target\n",
              "12         634995              0  ...         3       3\n",
              "21         634995              0  ...         4       5\n",
              "26         634995              0  ...         7       2\n",
              "31         634995              0  ...         2      15\n",
              "38         634995              0  ...         4       2\n",
              "...           ...            ...  ...       ...     ...\n",
              "40944     7170111             70  ...         6       1\n",
              "40945     7170111             70  ...         6       2\n",
              "40946     7170111             70  ...         5      72\n",
              "40947     7170111             70  ...         6      28\n",
              "40948     7170111             70  ...         6      11\n",
              "\n",
              "[18370 rows x 41 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "nUnHRcRT17Oq",
        "outputId": "0eb22167-dab0-45db-a563-15712cb3e149"
      },
      "source": [
        "df1.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_likes</th>\n",
              "      <th>page_checkins</th>\n",
              "      <th>page_talking_about</th>\n",
              "      <th>page_category</th>\n",
              "      <th>cc1_min</th>\n",
              "      <th>cc1_max</th>\n",
              "      <th>cc1_average</th>\n",
              "      <th>cc1_median</th>\n",
              "      <th>cc1_std</th>\n",
              "      <th>cc2_min</th>\n",
              "      <th>cc2_max</th>\n",
              "      <th>cc2_average</th>\n",
              "      <th>cc2_median</th>\n",
              "      <th>cc2_std</th>\n",
              "      <th>cc3_min</th>\n",
              "      <th>cc3_max</th>\n",
              "      <th>cc3_average</th>\n",
              "      <th>cc3_median</th>\n",
              "      <th>cc3_std</th>\n",
              "      <th>cc4_min</th>\n",
              "      <th>cc4_max</th>\n",
              "      <th>cc4_average</th>\n",
              "      <th>cc4_median</th>\n",
              "      <th>cc4_std</th>\n",
              "      <th>cc5_min</th>\n",
              "      <th>cc5_max</th>\n",
              "      <th>cc5_average</th>\n",
              "      <th>cc5_median</th>\n",
              "      <th>cc5_std</th>\n",
              "      <th>cc1</th>\n",
              "      <th>cc2</th>\n",
              "      <th>cc3</th>\n",
              "      <th>cc4</th>\n",
              "      <th>cc5</th>\n",
              "      <th>base_time</th>\n",
              "      <th>post_length</th>\n",
              "      <th>post_share_count</th>\n",
              "      <th>h_local</th>\n",
              "      <th>Post_Day</th>\n",
              "      <th>Base_Day</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.837000e+04</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>1.837000e+04</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "      <td>18370.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.889154e+06</td>\n",
              "      <td>5902.322156</td>\n",
              "      <td>6.894945e+04</td>\n",
              "      <td>21.284377</td>\n",
              "      <td>3.266413</td>\n",
              "      <td>635.833043</td>\n",
              "      <td>89.552273</td>\n",
              "      <td>59.552014</td>\n",
              "      <td>101.264931</td>\n",
              "      <td>0.480457</td>\n",
              "      <td>419.653729</td>\n",
              "      <td>35.872194</td>\n",
              "      <td>13.120250</td>\n",
              "      <td>61.828502</td>\n",
              "      <td>0.045563</td>\n",
              "      <td>388.234622</td>\n",
              "      <td>31.570182</td>\n",
              "      <td>8.557676</td>\n",
              "      <td>58.916138</td>\n",
              "      <td>3.086336</td>\n",
              "      <td>596.791453</td>\n",
              "      <td>84.424181</td>\n",
              "      <td>56.752368</td>\n",
              "      <td>94.732472</td>\n",
              "      <td>-319.320468</td>\n",
              "      <td>407.624986</td>\n",
              "      <td>4.302011</td>\n",
              "      <td>-3.365215</td>\n",
              "      <td>85.704492</td>\n",
              "      <td>102.057594</td>\n",
              "      <td>47.211105</td>\n",
              "      <td>35.660697</td>\n",
              "      <td>96.500817</td>\n",
              "      <td>11.550408</td>\n",
              "      <td>25.991127</td>\n",
              "      <td>170.158846</td>\n",
              "      <td>204.132335</td>\n",
              "      <td>23.801688</td>\n",
              "      <td>4.036527</td>\n",
              "      <td>4.038759</td>\n",
              "      <td>16.323625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.609307e+06</td>\n",
              "      <td>24174.627735</td>\n",
              "      <td>1.205182e+05</td>\n",
              "      <td>17.645641</td>\n",
              "      <td>30.735067</td>\n",
              "      <td>534.253762</td>\n",
              "      <td>110.022614</td>\n",
              "      <td>93.048583</td>\n",
              "      <td>93.898281</td>\n",
              "      <td>15.003967</td>\n",
              "      <td>422.146346</td>\n",
              "      <td>47.319886</td>\n",
              "      <td>30.697959</td>\n",
              "      <td>63.491229</td>\n",
              "      <td>2.884486</td>\n",
              "      <td>358.682091</td>\n",
              "      <td>39.581049</td>\n",
              "      <td>18.438994</td>\n",
              "      <td>60.587585</td>\n",
              "      <td>27.741607</td>\n",
              "      <td>510.082488</td>\n",
              "      <td>102.288392</td>\n",
              "      <td>87.660776</td>\n",
              "      <td>87.480682</td>\n",
              "      <td>312.800411</td>\n",
              "      <td>423.247761</td>\n",
              "      <td>24.653777</td>\n",
              "      <td>21.655614</td>\n",
              "      <td>87.234517</td>\n",
              "      <td>187.051487</td>\n",
              "      <td>109.675273</td>\n",
              "      <td>101.139934</td>\n",
              "      <td>174.536426</td>\n",
              "      <td>138.038216</td>\n",
              "      <td>19.251053</td>\n",
              "      <td>399.716223</td>\n",
              "      <td>649.085520</td>\n",
              "      <td>1.658703</td>\n",
              "      <td>1.944806</td>\n",
              "      <td>1.977367</td>\n",
              "      <td>51.590136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>7.700000e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.016949</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1366.000000</td>\n",
              "      <td>-204.000000</td>\n",
              "      <td>-210.500000</td>\n",
              "      <td>-288.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1366.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.579590e+05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.072000e+03</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>19.825688</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>26.890681</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>7.619266</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>13.458083</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>7.661871</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>15.497005</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>151.000000</td>\n",
              "      <td>18.715596</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>25.012197</td>\n",
              "      <td>-489.000000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>-0.604255</td>\n",
              "      <td>-5.000000</td>\n",
              "      <td>22.281648</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>-14.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.795870e+05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.311600e+04</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>513.000000</td>\n",
              "      <td>56.713568</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>72.631657</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>294.000000</td>\n",
              "      <td>22.015385</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>38.411121</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>278.000000</td>\n",
              "      <td>18.196970</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>40.497788</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>449.000000</td>\n",
              "      <td>54.070352</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>68.771505</td>\n",
              "      <td>-223.000000</td>\n",
              "      <td>270.000000</td>\n",
              "      <td>0.979079</td>\n",
              "      <td>-1.500000</td>\n",
              "      <td>60.663203</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.027759e+06</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>8.428800e+04</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>946.000000</td>\n",
              "      <td>131.923077</td>\n",
              "      <td>81.500000</td>\n",
              "      <td>157.919435</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>621.000000</td>\n",
              "      <td>53.550000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>94.655116</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>611.000000</td>\n",
              "      <td>44.717842</td>\n",
              "      <td>9.500000</td>\n",
              "      <td>87.196844</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>913.000000</td>\n",
              "      <td>125.951220</td>\n",
              "      <td>76.500000</td>\n",
              "      <td>148.971101</td>\n",
              "      <td>-81.000000</td>\n",
              "      <td>612.000000</td>\n",
              "      <td>6.291667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>133.641617</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>174.000000</td>\n",
              "      <td>142.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>11.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.626244e+08</td>\n",
              "      <td>186370.000000</td>\n",
              "      <td>1.298007e+06</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>731.394558</td>\n",
              "      <td>1923.000000</td>\n",
              "      <td>2079.000000</td>\n",
              "      <td>1923.000000</td>\n",
              "      <td>1923.000000</td>\n",
              "      <td>469.538781</td>\n",
              "      <td>324.000000</td>\n",
              "      <td>1605.000000</td>\n",
              "      <td>437.684211</td>\n",
              "      <td>433.000000</td>\n",
              "      <td>533.638557</td>\n",
              "      <td>1923.000000</td>\n",
              "      <td>2184.000000</td>\n",
              "      <td>1923.000000</td>\n",
              "      <td>1923.000000</td>\n",
              "      <td>703.144050</td>\n",
              "      <td>1923.000000</td>\n",
              "      <td>2079.000000</td>\n",
              "      <td>1923.000000</td>\n",
              "      <td>1923.000000</td>\n",
              "      <td>749.709600</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>2079.000000</td>\n",
              "      <td>1605.000000</td>\n",
              "      <td>2184.000000</td>\n",
              "      <td>2079.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>21480.000000</td>\n",
              "      <td>19127.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1305.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         page_likes  page_checkins  ...      Base_Day        target\n",
              "count  1.837000e+04   18370.000000  ...  18370.000000  18370.000000\n",
              "mean   1.889154e+06    5902.322156  ...      4.038759     16.323625\n",
              "std    4.609307e+06   24174.627735  ...      1.977367     51.590136\n",
              "min    7.700000e+01       0.000000  ...      1.000000      1.000000\n",
              "25%    1.579590e+05       0.000000  ...      2.000000      1.000000\n",
              "50%    5.795870e+05       0.000000  ...      4.000000      3.000000\n",
              "75%    2.027759e+06      62.000000  ...      6.000000     11.000000\n",
              "max    1.626244e+08  186370.000000  ...      7.000000   1305.000000\n",
              "\n",
              "[8 rows x 41 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "Jk7TWurZ2MUf",
        "outputId": "3817ee3b-aeb2-4a08-b68d-008c9825f5e0"
      },
      "source": [
        "df_transformed, scaler = normalizeTrain(df1)\n",
        "print(scaler)\n",
        "df_transformed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StandardScaler()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_likes</th>\n",
              "      <th>page_checkins</th>\n",
              "      <th>page_talking_about</th>\n",
              "      <th>page_category</th>\n",
              "      <th>cc1_min</th>\n",
              "      <th>cc1_max</th>\n",
              "      <th>cc1_average</th>\n",
              "      <th>cc1_median</th>\n",
              "      <th>cc1_std</th>\n",
              "      <th>cc2_min</th>\n",
              "      <th>cc2_max</th>\n",
              "      <th>cc2_average</th>\n",
              "      <th>cc2_median</th>\n",
              "      <th>cc2_std</th>\n",
              "      <th>cc3_min</th>\n",
              "      <th>cc3_max</th>\n",
              "      <th>cc3_average</th>\n",
              "      <th>cc3_median</th>\n",
              "      <th>cc3_std</th>\n",
              "      <th>cc4_min</th>\n",
              "      <th>cc4_max</th>\n",
              "      <th>cc4_average</th>\n",
              "      <th>cc4_median</th>\n",
              "      <th>cc4_std</th>\n",
              "      <th>cc5_min</th>\n",
              "      <th>cc5_max</th>\n",
              "      <th>cc5_average</th>\n",
              "      <th>cc5_median</th>\n",
              "      <th>cc5_std</th>\n",
              "      <th>cc1</th>\n",
              "      <th>cc2</th>\n",
              "      <th>cc3</th>\n",
              "      <th>cc4</th>\n",
              "      <th>cc5</th>\n",
              "      <th>base_time</th>\n",
              "      <th>post_length</th>\n",
              "      <th>post_share_count</th>\n",
              "      <th>h_local</th>\n",
              "      <th>Post_Day</th>\n",
              "      <th>Base_Day</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.272100</td>\n",
              "      <td>-0.244160</td>\n",
              "      <td>-0.568282</td>\n",
              "      <td>-1.149572</td>\n",
              "      <td>-0.106279</td>\n",
              "      <td>0.318522</td>\n",
              "      <td>-0.711339</td>\n",
              "      <td>-0.629280</td>\n",
              "      <td>-0.327702</td>\n",
              "      <td>-0.032023</td>\n",
              "      <td>0.91522</td>\n",
              "      <td>-0.598022</td>\n",
              "      <td>-0.427410</td>\n",
              "      <td>0.11982</td>\n",
              "      <td>-0.015796</td>\n",
              "      <td>-0.870529</td>\n",
              "      <td>-0.731827</td>\n",
              "      <td>-0.46412</td>\n",
              "      <td>-0.832052</td>\n",
              "      <td>-0.111256</td>\n",
              "      <td>0.410158</td>\n",
              "      <td>-0.721264</td>\n",
              "      <td>-0.636019</td>\n",
              "      <td>-0.279814</td>\n",
              "      <td>0.800278</td>\n",
              "      <td>0.941259</td>\n",
              "      <td>0.027102</td>\n",
              "      <td>0.155401</td>\n",
              "      <td>-0.181744</td>\n",
              "      <td>-0.545627</td>\n",
              "      <td>-0.430474</td>\n",
              "      <td>-0.352597</td>\n",
              "      <td>-0.552913</td>\n",
              "      <td>-0.083678</td>\n",
              "      <td>-1.194311</td>\n",
              "      <td>-0.032921</td>\n",
              "      <td>-0.308338</td>\n",
              "      <td>0.119562</td>\n",
              "      <td>-0.532987</td>\n",
              "      <td>-0.525339</td>\n",
              "      <td>-0.258266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.272100</td>\n",
              "      <td>-0.244160</td>\n",
              "      <td>-0.568282</td>\n",
              "      <td>-1.149572</td>\n",
              "      <td>-0.106279</td>\n",
              "      <td>0.318522</td>\n",
              "      <td>-0.711339</td>\n",
              "      <td>-0.629280</td>\n",
              "      <td>-0.327702</td>\n",
              "      <td>-0.032023</td>\n",
              "      <td>0.91522</td>\n",
              "      <td>-0.598022</td>\n",
              "      <td>-0.427410</td>\n",
              "      <td>0.11982</td>\n",
              "      <td>-0.015796</td>\n",
              "      <td>-0.870529</td>\n",
              "      <td>-0.731827</td>\n",
              "      <td>-0.46412</td>\n",
              "      <td>-0.832052</td>\n",
              "      <td>-0.111256</td>\n",
              "      <td>0.410158</td>\n",
              "      <td>-0.721264</td>\n",
              "      <td>-0.636019</td>\n",
              "      <td>-0.279814</td>\n",
              "      <td>0.800278</td>\n",
              "      <td>0.941259</td>\n",
              "      <td>0.027102</td>\n",
              "      <td>0.155401</td>\n",
              "      <td>-0.181744</td>\n",
              "      <td>-0.133965</td>\n",
              "      <td>-0.011043</td>\n",
              "      <td>-0.046083</td>\n",
              "      <td>-0.128921</td>\n",
              "      <td>0.024991</td>\n",
              "      <td>0.260194</td>\n",
              "      <td>-0.087962</td>\n",
              "      <td>-0.285228</td>\n",
              "      <td>0.119562</td>\n",
              "      <td>-1.047191</td>\n",
              "      <td>-0.019602</td>\n",
              "      <td>-0.219498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.272100</td>\n",
              "      <td>-0.244160</td>\n",
              "      <td>-0.568282</td>\n",
              "      <td>-1.149572</td>\n",
              "      <td>-0.106279</td>\n",
              "      <td>0.318522</td>\n",
              "      <td>-0.711339</td>\n",
              "      <td>-0.629280</td>\n",
              "      <td>-0.327702</td>\n",
              "      <td>-0.032023</td>\n",
              "      <td>0.91522</td>\n",
              "      <td>-0.598022</td>\n",
              "      <td>-0.427410</td>\n",
              "      <td>0.11982</td>\n",
              "      <td>-0.015796</td>\n",
              "      <td>-0.870529</td>\n",
              "      <td>-0.731827</td>\n",
              "      <td>-0.46412</td>\n",
              "      <td>-0.832052</td>\n",
              "      <td>-0.111256</td>\n",
              "      <td>0.410158</td>\n",
              "      <td>-0.721264</td>\n",
              "      <td>-0.636019</td>\n",
              "      <td>-0.279814</td>\n",
              "      <td>0.800278</td>\n",
              "      <td>0.941259</td>\n",
              "      <td>0.027102</td>\n",
              "      <td>0.155401</td>\n",
              "      <td>-0.181744</td>\n",
              "      <td>-0.524242</td>\n",
              "      <td>-0.394002</td>\n",
              "      <td>-0.352597</td>\n",
              "      <td>-0.529994</td>\n",
              "      <td>-0.054699</td>\n",
              "      <td>-0.674845</td>\n",
              "      <td>0.324842</td>\n",
              "      <td>-0.311419</td>\n",
              "      <td>0.119562</td>\n",
              "      <td>1.009626</td>\n",
              "      <td>1.497609</td>\n",
              "      <td>-0.277650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.272100</td>\n",
              "      <td>-0.244160</td>\n",
              "      <td>-0.568282</td>\n",
              "      <td>-1.149572</td>\n",
              "      <td>-0.106279</td>\n",
              "      <td>0.318522</td>\n",
              "      <td>-0.711339</td>\n",
              "      <td>-0.629280</td>\n",
              "      <td>-0.327702</td>\n",
              "      <td>-0.032023</td>\n",
              "      <td>0.91522</td>\n",
              "      <td>-0.598022</td>\n",
              "      <td>-0.427410</td>\n",
              "      <td>0.11982</td>\n",
              "      <td>-0.015796</td>\n",
              "      <td>-0.870529</td>\n",
              "      <td>-0.731827</td>\n",
              "      <td>-0.46412</td>\n",
              "      <td>-0.832052</td>\n",
              "      <td>-0.111256</td>\n",
              "      <td>0.410158</td>\n",
              "      <td>-0.721264</td>\n",
              "      <td>-0.636019</td>\n",
              "      <td>-0.279814</td>\n",
              "      <td>0.800278</td>\n",
              "      <td>0.941259</td>\n",
              "      <td>0.027102</td>\n",
              "      <td>0.155401</td>\n",
              "      <td>-0.181744</td>\n",
              "      <td>-0.545627</td>\n",
              "      <td>-0.430474</td>\n",
              "      <td>-0.352597</td>\n",
              "      <td>-0.552913</td>\n",
              "      <td>-0.083678</td>\n",
              "      <td>-1.350151</td>\n",
              "      <td>-0.215556</td>\n",
              "      <td>-0.311419</td>\n",
              "      <td>0.119562</td>\n",
              "      <td>-1.047191</td>\n",
              "      <td>-1.031076</td>\n",
              "      <td>-0.025657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.272100</td>\n",
              "      <td>-0.244160</td>\n",
              "      <td>-0.568282</td>\n",
              "      <td>-1.149572</td>\n",
              "      <td>-0.106279</td>\n",
              "      <td>0.318522</td>\n",
              "      <td>-0.711339</td>\n",
              "      <td>-0.629280</td>\n",
              "      <td>-0.327702</td>\n",
              "      <td>-0.032023</td>\n",
              "      <td>0.91522</td>\n",
              "      <td>-0.598022</td>\n",
              "      <td>-0.427410</td>\n",
              "      <td>0.11982</td>\n",
              "      <td>-0.015796</td>\n",
              "      <td>-0.870529</td>\n",
              "      <td>-0.731827</td>\n",
              "      <td>-0.46412</td>\n",
              "      <td>-0.832052</td>\n",
              "      <td>-0.111256</td>\n",
              "      <td>0.410158</td>\n",
              "      <td>-0.721264</td>\n",
              "      <td>-0.636019</td>\n",
              "      <td>-0.279814</td>\n",
              "      <td>0.800278</td>\n",
              "      <td>0.941259</td>\n",
              "      <td>0.027102</td>\n",
              "      <td>0.155401</td>\n",
              "      <td>-0.181744</td>\n",
              "      <td>-0.502857</td>\n",
              "      <td>-0.357530</td>\n",
              "      <td>-0.352597</td>\n",
              "      <td>-0.507076</td>\n",
              "      <td>-0.025721</td>\n",
              "      <td>-0.726792</td>\n",
              "      <td>-0.140501</td>\n",
              "      <td>-0.294472</td>\n",
              "      <td>0.119562</td>\n",
              "      <td>-0.532987</td>\n",
              "      <td>-0.019602</td>\n",
              "      <td>-0.277650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18365</th>\n",
              "      <td>1.145747</td>\n",
              "      <td>-0.241265</td>\n",
              "      <td>3.551847</td>\n",
              "      <td>-0.696190</td>\n",
              "      <td>-0.106279</td>\n",
              "      <td>2.330729</td>\n",
              "      <td>3.705228</td>\n",
              "      <td>2.251014</td>\n",
              "      <td>4.271264</td>\n",
              "      <td>-0.032023</td>\n",
              "      <td>3.46180</td>\n",
              "      <td>5.237852</td>\n",
              "      <td>2.015816</td>\n",
              "      <td>6.32550</td>\n",
              "      <td>-0.015796</td>\n",
              "      <td>0.902677</td>\n",
              "      <td>2.473721</td>\n",
              "      <td>3.38652</td>\n",
              "      <td>2.158355</td>\n",
              "      <td>-0.111256</td>\n",
              "      <td>2.517717</td>\n",
              "      <td>3.890829</td>\n",
              "      <td>2.090475</td>\n",
              "      <td>4.578539</td>\n",
              "      <td>-0.414587</td>\n",
              "      <td>3.481212</td>\n",
              "      <td>6.081911</td>\n",
              "      <td>-0.121671</td>\n",
              "      <td>4.644126</td>\n",
              "      <td>0.892519</td>\n",
              "      <td>-0.302821</td>\n",
              "      <td>0.220881</td>\n",
              "      <td>0.822196</td>\n",
              "      <td>-0.402439</td>\n",
              "      <td>1.558860</td>\n",
              "      <td>-0.395689</td>\n",
              "      <td>2.013453</td>\n",
              "      <td>-13.144174</td>\n",
              "      <td>-0.018782</td>\n",
              "      <td>0.991872</td>\n",
              "      <td>-0.297034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18366</th>\n",
              "      <td>1.145747</td>\n",
              "      <td>-0.241265</td>\n",
              "      <td>3.551847</td>\n",
              "      <td>-0.696190</td>\n",
              "      <td>-0.106279</td>\n",
              "      <td>2.330729</td>\n",
              "      <td>3.705228</td>\n",
              "      <td>2.251014</td>\n",
              "      <td>4.271264</td>\n",
              "      <td>-0.032023</td>\n",
              "      <td>3.46180</td>\n",
              "      <td>5.237852</td>\n",
              "      <td>2.015816</td>\n",
              "      <td>6.32550</td>\n",
              "      <td>-0.015796</td>\n",
              "      <td>0.902677</td>\n",
              "      <td>2.473721</td>\n",
              "      <td>3.38652</td>\n",
              "      <td>2.158355</td>\n",
              "      <td>-0.111256</td>\n",
              "      <td>2.517717</td>\n",
              "      <td>3.890829</td>\n",
              "      <td>2.090475</td>\n",
              "      <td>4.578539</td>\n",
              "      <td>-0.414587</td>\n",
              "      <td>3.481212</td>\n",
              "      <td>6.081911</td>\n",
              "      <td>-0.121671</td>\n",
              "      <td>4.644126</td>\n",
              "      <td>2.897369</td>\n",
              "      <td>-0.248113</td>\n",
              "      <td>0.695484</td>\n",
              "      <td>2.993721</td>\n",
              "      <td>-0.706711</td>\n",
              "      <td>1.403020</td>\n",
              "      <td>-0.052936</td>\n",
              "      <td>1.378697</td>\n",
              "      <td>-12.541277</td>\n",
              "      <td>-0.018782</td>\n",
              "      <td>0.991872</td>\n",
              "      <td>-0.277650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18367</th>\n",
              "      <td>1.145747</td>\n",
              "      <td>-0.241265</td>\n",
              "      <td>3.551847</td>\n",
              "      <td>-0.696190</td>\n",
              "      <td>-0.106279</td>\n",
              "      <td>2.330729</td>\n",
              "      <td>3.705228</td>\n",
              "      <td>2.251014</td>\n",
              "      <td>4.271264</td>\n",
              "      <td>-0.032023</td>\n",
              "      <td>3.46180</td>\n",
              "      <td>5.237852</td>\n",
              "      <td>2.015816</td>\n",
              "      <td>6.32550</td>\n",
              "      <td>-0.015796</td>\n",
              "      <td>0.902677</td>\n",
              "      <td>2.473721</td>\n",
              "      <td>3.38652</td>\n",
              "      <td>2.158355</td>\n",
              "      <td>-0.111256</td>\n",
              "      <td>2.517717</td>\n",
              "      <td>3.890829</td>\n",
              "      <td>2.090475</td>\n",
              "      <td>4.578539</td>\n",
              "      <td>-0.414587</td>\n",
              "      <td>3.481212</td>\n",
              "      <td>6.081911</td>\n",
              "      <td>-0.121671</td>\n",
              "      <td>4.644126</td>\n",
              "      <td>2.769058</td>\n",
              "      <td>5.222731</td>\n",
              "      <td>-0.352597</td>\n",
              "      <td>2.999451</td>\n",
              "      <td>4.407954</td>\n",
              "      <td>-0.363165</td>\n",
              "      <td>-0.125490</td>\n",
              "      <td>4.248967</td>\n",
              "      <td>0.119562</td>\n",
              "      <td>-0.018782</td>\n",
              "      <td>0.486135</td>\n",
              "      <td>1.079235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18368</th>\n",
              "      <td>1.145747</td>\n",
              "      <td>-0.241265</td>\n",
              "      <td>3.551847</td>\n",
              "      <td>-0.696190</td>\n",
              "      <td>-0.106279</td>\n",
              "      <td>2.330729</td>\n",
              "      <td>3.705228</td>\n",
              "      <td>2.251014</td>\n",
              "      <td>4.271264</td>\n",
              "      <td>-0.032023</td>\n",
              "      <td>3.46180</td>\n",
              "      <td>5.237852</td>\n",
              "      <td>2.015816</td>\n",
              "      <td>6.32550</td>\n",
              "      <td>-0.015796</td>\n",
              "      <td>0.902677</td>\n",
              "      <td>2.473721</td>\n",
              "      <td>3.38652</td>\n",
              "      <td>2.158355</td>\n",
              "      <td>-0.111256</td>\n",
              "      <td>2.517717</td>\n",
              "      <td>3.890829</td>\n",
              "      <td>2.090475</td>\n",
              "      <td>4.578539</td>\n",
              "      <td>-0.414587</td>\n",
              "      <td>3.481212</td>\n",
              "      <td>6.081911</td>\n",
              "      <td>-0.121671</td>\n",
              "      <td>4.644126</td>\n",
              "      <td>2.817175</td>\n",
              "      <td>1.292842</td>\n",
              "      <td>3.997929</td>\n",
              "      <td>2.816103</td>\n",
              "      <td>-1.902064</td>\n",
              "      <td>0.364087</td>\n",
              "      <td>-0.343150</td>\n",
              "      <td>1.816247</td>\n",
              "      <td>-8.923895</td>\n",
              "      <td>-0.018782</td>\n",
              "      <td>0.991872</td>\n",
              "      <td>0.226336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18369</th>\n",
              "      <td>1.145747</td>\n",
              "      <td>-0.241265</td>\n",
              "      <td>3.551847</td>\n",
              "      <td>-0.696190</td>\n",
              "      <td>-0.106279</td>\n",
              "      <td>2.330729</td>\n",
              "      <td>3.705228</td>\n",
              "      <td>2.251014</td>\n",
              "      <td>4.271264</td>\n",
              "      <td>-0.032023</td>\n",
              "      <td>3.46180</td>\n",
              "      <td>5.237852</td>\n",
              "      <td>2.015816</td>\n",
              "      <td>6.32550</td>\n",
              "      <td>-0.015796</td>\n",
              "      <td>0.902677</td>\n",
              "      <td>2.473721</td>\n",
              "      <td>3.38652</td>\n",
              "      <td>2.158355</td>\n",
              "      <td>-0.111256</td>\n",
              "      <td>2.517717</td>\n",
              "      <td>3.890829</td>\n",
              "      <td>2.090475</td>\n",
              "      <td>4.578539</td>\n",
              "      <td>-0.414587</td>\n",
              "      <td>3.481212</td>\n",
              "      <td>6.081911</td>\n",
              "      <td>-0.121671</td>\n",
              "      <td>4.644126</td>\n",
              "      <td>4.666983</td>\n",
              "      <td>1.967579</td>\n",
              "      <td>6.687346</td>\n",
              "      <td>4.947521</td>\n",
              "      <td>-3.336489</td>\n",
              "      <td>0.156301</td>\n",
              "      <td>-0.092966</td>\n",
              "      <td>5.435283</td>\n",
              "      <td>-8.923895</td>\n",
              "      <td>-0.018782</td>\n",
              "      <td>0.991872</td>\n",
              "      <td>-0.103194</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18370 rows Ã— 41 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       page_likes  page_checkins  ...  Base_Day    target\n",
              "0       -0.272100      -0.244160  ... -0.525339 -0.258266\n",
              "1       -0.272100      -0.244160  ... -0.019602 -0.219498\n",
              "2       -0.272100      -0.244160  ...  1.497609 -0.277650\n",
              "3       -0.272100      -0.244160  ... -1.031076 -0.025657\n",
              "4       -0.272100      -0.244160  ... -0.019602 -0.277650\n",
              "...           ...            ...  ...       ...       ...\n",
              "18365    1.145747      -0.241265  ...  0.991872 -0.297034\n",
              "18366    1.145747      -0.241265  ...  0.991872 -0.277650\n",
              "18367    1.145747      -0.241265  ...  0.486135  1.079235\n",
              "18368    1.145747      -0.241265  ...  0.991872  0.226336\n",
              "18369    1.145747      -0.241265  ...  0.991872 -0.103194\n",
              "\n",
              "[18370 rows x 41 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X65e-SYr6spj"
      },
      "source": [
        "The attributes to removed are different for each variant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "EFru6wfeYoZ-",
        "outputId": "72ea2740-4192-4373-f2f7-7d8abb817be7"
      },
      "source": [
        "df_list = read_data(testing_files)\n",
        "df_list = merge_days(df_list)\n",
        "df_list_2 = []\n",
        "for df in df_list:\n",
        "    df = df.drop(['post_promotion_status'], 1)\n",
        "    df = df[df['target'] != 0]\n",
        "    df_list_2.append(df)\n",
        "df_list = df_list_2\n",
        "merged_df = pd.concat(df_list)\n",
        "df_list.append(merged_df) # now have variant 1 - 5 + merged of variant 1 - 5\n",
        "\n",
        "df1 = df_list[0]\n",
        "df_transformed = normalizeTest(df1, scaler)\n",
        "df_transformed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_likes</th>\n",
              "      <th>page_checkins</th>\n",
              "      <th>page_talking_about</th>\n",
              "      <th>page_category</th>\n",
              "      <th>cc1_min</th>\n",
              "      <th>cc1_max</th>\n",
              "      <th>cc1_average</th>\n",
              "      <th>cc1_median</th>\n",
              "      <th>cc1_std</th>\n",
              "      <th>cc2_min</th>\n",
              "      <th>cc2_max</th>\n",
              "      <th>cc2_average</th>\n",
              "      <th>cc2_median</th>\n",
              "      <th>cc2_std</th>\n",
              "      <th>cc3_min</th>\n",
              "      <th>cc3_max</th>\n",
              "      <th>cc3_average</th>\n",
              "      <th>cc3_median</th>\n",
              "      <th>cc3_std</th>\n",
              "      <th>cc4_min</th>\n",
              "      <th>cc4_max</th>\n",
              "      <th>cc4_average</th>\n",
              "      <th>cc4_median</th>\n",
              "      <th>cc4_std</th>\n",
              "      <th>cc5_min</th>\n",
              "      <th>cc5_max</th>\n",
              "      <th>cc5_average</th>\n",
              "      <th>cc5_median</th>\n",
              "      <th>cc5_std</th>\n",
              "      <th>cc1</th>\n",
              "      <th>cc2</th>\n",
              "      <th>cc3</th>\n",
              "      <th>cc4</th>\n",
              "      <th>cc5</th>\n",
              "      <th>base_time</th>\n",
              "      <th>post_length</th>\n",
              "      <th>post_share_count</th>\n",
              "      <th>h_local</th>\n",
              "      <th>Post_Day</th>\n",
              "      <th>Base_Day</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.118979</td>\n",
              "      <td>1.159622</td>\n",
              "      <td>-0.162282</td>\n",
              "      <td>-0.696190</td>\n",
              "      <td>-0.106279</td>\n",
              "      <td>0.247393</td>\n",
              "      <td>-0.112273</td>\n",
              "      <td>-0.247748</td>\n",
              "      <td>0.336506</td>\n",
              "      <td>-0.032023</td>\n",
              "      <td>-0.342672</td>\n",
              "      <td>-0.153686</td>\n",
              "      <td>0.028659</td>\n",
              "      <td>-0.257705</td>\n",
              "      <td>-0.015796</td>\n",
              "      <td>0.913830</td>\n",
              "      <td>0.410683</td>\n",
              "      <td>-0.46412</td>\n",
              "      <td>1.075075</td>\n",
              "      <td>-0.111256</td>\n",
              "      <td>0.288605</td>\n",
              "      <td>-0.082359</td>\n",
              "      <td>-0.231037</td>\n",
              "      <td>0.397186</td>\n",
              "      <td>-1.101945</td>\n",
              "      <td>-0.313359</td>\n",
              "      <td>-0.954322</td>\n",
              "      <td>0.386294</td>\n",
              "      <td>0.519671</td>\n",
              "      <td>-0.545627</td>\n",
              "      <td>-0.430474</td>\n",
              "      <td>-0.352597</td>\n",
              "      <td>-0.552913</td>\n",
              "      <td>-0.083678</td>\n",
              "      <td>-1.350151</td>\n",
              "      <td>-0.050434</td>\n",
              "      <td>-0.279065</td>\n",
              "      <td>-1.086232</td>\n",
              "      <td>0.495422</td>\n",
              "      <td>0.486135</td>\n",
              "      <td>0.362024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.374839</td>\n",
              "      <td>-0.244160</td>\n",
              "      <td>-0.522520</td>\n",
              "      <td>-0.979553</td>\n",
              "      <td>-0.008668</td>\n",
              "      <td>-1.049779</td>\n",
              "      <td>-0.607510</td>\n",
              "      <td>-0.478817</td>\n",
              "      <td>-0.829384</td>\n",
              "      <td>0.167930</td>\n",
              "      <td>-0.816454</td>\n",
              "      <td>-0.401852</td>\n",
              "      <td>-0.231952</td>\n",
              "      <td>-0.594099</td>\n",
              "      <td>-0.015796</td>\n",
              "      <td>-1.040601</td>\n",
              "      <td>-0.692960</td>\n",
              "      <td>-0.46412</td>\n",
              "      <td>-0.881851</td>\n",
              "      <td>-0.003112</td>\n",
              "      <td>-1.022983</td>\n",
              "      <td>-0.618673</td>\n",
              "      <td>-0.510531</td>\n",
              "      <td>-0.816622</td>\n",
              "      <td>0.988902</td>\n",
              "      <td>-0.785909</td>\n",
              "      <td>0.341226</td>\n",
              "      <td>0.386294</td>\n",
              "      <td>-0.681380</td>\n",
              "      <td>-0.428009</td>\n",
              "      <td>-0.275467</td>\n",
              "      <td>-0.303159</td>\n",
              "      <td>-0.438321</td>\n",
              "      <td>0.003257</td>\n",
              "      <td>0.104354</td>\n",
              "      <td>-0.375674</td>\n",
              "      <td>-0.312960</td>\n",
              "      <td>0.119562</td>\n",
              "      <td>1.009626</td>\n",
              "      <td>1.497609</td>\n",
              "      <td>-0.277650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.558325</td>\n",
              "      <td>-0.244119</td>\n",
              "      <td>19.798142</td>\n",
              "      <td>-1.092899</td>\n",
              "      <td>-0.106279</td>\n",
              "      <td>3.538054</td>\n",
              "      <td>7.895224</td>\n",
              "      <td>6.001845</td>\n",
              "      <td>6.825116</td>\n",
              "      <td>-0.032023</td>\n",
              "      <td>4.989747</td>\n",
              "      <td>13.752820</td>\n",
              "      <td>17.978224</td>\n",
              "      <td>9.964454</td>\n",
              "      <td>-0.015796</td>\n",
              "      <td>3.331078</td>\n",
              "      <td>5.015686</td>\n",
              "      <td>-0.46412</td>\n",
              "      <td>6.694044</td>\n",
              "      <td>-0.111256</td>\n",
              "      <td>3.782253</td>\n",
              "      <td>8.304140</td>\n",
              "      <td>6.402669</td>\n",
              "      <td>7.246931</td>\n",
              "      <td>-2.233688</td>\n",
              "      <td>5.005183</td>\n",
              "      <td>18.344279</td>\n",
              "      <td>20.058403</td>\n",
              "      <td>9.491787</td>\n",
              "      <td>2.758366</td>\n",
              "      <td>5.204495</td>\n",
              "      <td>-0.352597</td>\n",
              "      <td>2.987992</td>\n",
              "      <td>4.393465</td>\n",
              "      <td>-0.986525</td>\n",
              "      <td>-0.150508</td>\n",
              "      <td>-0.029477</td>\n",
              "      <td>-10.732586</td>\n",
              "      <td>-1.047191</td>\n",
              "      <td>-1.031076</td>\n",
              "      <td>1.854598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.335906</td>\n",
              "      <td>-0.244160</td>\n",
              "      <td>-0.441924</td>\n",
              "      <td>0.380593</td>\n",
              "      <td>-0.106279</td>\n",
              "      <td>-1.124652</td>\n",
              "      <td>-0.745580</td>\n",
              "      <td>-0.597038</td>\n",
              "      <td>-0.975089</td>\n",
              "      <td>-0.032023</td>\n",
              "      <td>-0.911211</td>\n",
              "      <td>-0.617210</td>\n",
              "      <td>-0.362257</td>\n",
              "      <td>-0.821104</td>\n",
              "      <td>-0.015796</td>\n",
              "      <td>-1.068481</td>\n",
              "      <td>-0.779584</td>\n",
              "      <td>-0.46412</td>\n",
              "      <td>-0.949018</td>\n",
              "      <td>-0.111256</td>\n",
              "      <td>-1.101404</td>\n",
              "      <td>-0.756476</td>\n",
              "      <td>-0.613203</td>\n",
              "      <td>-0.978662</td>\n",
              "      <td>1.014478</td>\n",
              "      <td>-0.880418</td>\n",
              "      <td>0.066944</td>\n",
              "      <td>0.247758</td>\n",
              "      <td>-0.869918</td>\n",
              "      <td>-0.513550</td>\n",
              "      <td>-0.375766</td>\n",
              "      <td>-0.352597</td>\n",
              "      <td>-0.518535</td>\n",
              "      <td>-0.040210</td>\n",
              "      <td>-0.882632</td>\n",
              "      <td>-0.340648</td>\n",
              "      <td>-0.138864</td>\n",
              "      <td>0.119562</td>\n",
              "      <td>1.009626</td>\n",
              "      <td>0.991872</td>\n",
              "      <td>-0.297034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.039670</td>\n",
              "      <td>-0.237707</td>\n",
              "      <td>0.675481</td>\n",
              "      <td>2.024103</td>\n",
              "      <td>-0.106279</td>\n",
              "      <td>-0.097022</td>\n",
              "      <td>-0.618143</td>\n",
              "      <td>-0.521806</td>\n",
              "      <td>-0.542489</td>\n",
              "      <td>-0.032023</td>\n",
              "      <td>0.389322</td>\n",
              "      <td>-0.346938</td>\n",
              "      <td>-0.134223</td>\n",
              "      <td>-0.179328</td>\n",
              "      <td>-0.015796</td>\n",
              "      <td>-0.906774</td>\n",
              "      <td>-0.744854</td>\n",
              "      <td>-0.46412</td>\n",
              "      <td>-0.845142</td>\n",
              "      <td>-0.111256</td>\n",
              "      <td>-0.025078</td>\n",
              "      <td>-0.614910</td>\n",
              "      <td>-0.521939</td>\n",
              "      <td>-0.507569</td>\n",
              "      <td>0.825854</td>\n",
              "      <td>0.416729</td>\n",
              "      <td>0.529940</td>\n",
              "      <td>0.547920</td>\n",
              "      <td>-0.389570</td>\n",
              "      <td>-0.406624</td>\n",
              "      <td>-0.193404</td>\n",
              "      <td>-0.352597</td>\n",
              "      <td>-0.403943</td>\n",
              "      <td>0.104681</td>\n",
              "      <td>-1.090418</td>\n",
              "      <td>-0.278102</td>\n",
              "      <td>-0.312960</td>\n",
              "      <td>-10.129689</td>\n",
              "      <td>0.495422</td>\n",
              "      <td>0.486135</td>\n",
              "      <td>-0.238882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>0.838301</td>\n",
              "      <td>-0.243871</td>\n",
              "      <td>-0.149421</td>\n",
              "      <td>-0.979553</td>\n",
              "      <td>0.251628</td>\n",
              "      <td>-1.169575</td>\n",
              "      <td>-0.713984</td>\n",
              "      <td>-0.521806</td>\n",
              "      <td>-1.078483</td>\n",
              "      <td>0.701137</td>\n",
              "      <td>-0.968064</td>\n",
              "      <td>-0.525633</td>\n",
              "      <td>-0.069070</td>\n",
              "      <td>-0.973838</td>\n",
              "      <td>-0.015796</td>\n",
              "      <td>-1.082421</td>\n",
              "      <td>-0.797630</td>\n",
              "      <td>-0.46412</td>\n",
              "      <td>-0.972439</td>\n",
              "      <td>0.285271</td>\n",
              "      <td>-1.148456</td>\n",
              "      <td>-0.717835</td>\n",
              "      <td>-0.521939</td>\n",
              "      <td>-1.082925</td>\n",
              "      <td>1.056039</td>\n",
              "      <td>-0.937124</td>\n",
              "      <td>0.271689</td>\n",
              "      <td>0.663366</td>\n",
              "      <td>-0.982488</td>\n",
              "      <td>-0.486818</td>\n",
              "      <td>-0.330176</td>\n",
              "      <td>-0.352597</td>\n",
              "      <td>-0.489887</td>\n",
              "      <td>-0.003987</td>\n",
              "      <td>-0.415112</td>\n",
              "      <td>-0.255585</td>\n",
              "      <td>-0.291391</td>\n",
              "      <td>0.119562</td>\n",
              "      <td>0.495422</td>\n",
              "      <td>0.486135</td>\n",
              "      <td>-0.238882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>0.039670</td>\n",
              "      <td>-0.237707</td>\n",
              "      <td>0.675481</td>\n",
              "      <td>2.024103</td>\n",
              "      <td>-0.106279</td>\n",
              "      <td>-0.097022</td>\n",
              "      <td>-0.618143</td>\n",
              "      <td>-0.521806</td>\n",
              "      <td>-0.542489</td>\n",
              "      <td>-0.032023</td>\n",
              "      <td>0.389322</td>\n",
              "      <td>-0.346938</td>\n",
              "      <td>-0.134223</td>\n",
              "      <td>-0.179328</td>\n",
              "      <td>-0.015796</td>\n",
              "      <td>-0.906774</td>\n",
              "      <td>-0.744854</td>\n",
              "      <td>-0.46412</td>\n",
              "      <td>-0.845142</td>\n",
              "      <td>-0.111256</td>\n",
              "      <td>-0.025078</td>\n",
              "      <td>-0.614910</td>\n",
              "      <td>-0.521939</td>\n",
              "      <td>-0.507569</td>\n",
              "      <td>0.825854</td>\n",
              "      <td>0.416729</td>\n",
              "      <td>0.529940</td>\n",
              "      <td>0.547920</td>\n",
              "      <td>-0.389570</td>\n",
              "      <td>-0.219505</td>\n",
              "      <td>0.125728</td>\n",
              "      <td>-0.352597</td>\n",
              "      <td>-0.203406</td>\n",
              "      <td>0.358241</td>\n",
              "      <td>-1.246258</td>\n",
              "      <td>0.134702</td>\n",
              "      <td>-0.200491</td>\n",
              "      <td>-7.718100</td>\n",
              "      <td>1.523830</td>\n",
              "      <td>1.497609</td>\n",
              "      <td>-0.161346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>-0.270800</td>\n",
              "      <td>-0.244160</td>\n",
              "      <td>0.127275</td>\n",
              "      <td>-1.149572</td>\n",
              "      <td>-0.106279</td>\n",
              "      <td>-1.072241</td>\n",
              "      <td>-0.733837</td>\n",
              "      <td>-0.586290</td>\n",
              "      <td>-0.971380</td>\n",
              "      <td>-0.032023</td>\n",
              "      <td>-0.896997</td>\n",
              "      <td>-0.627962</td>\n",
              "      <td>-0.313393</td>\n",
              "      <td>-0.852593</td>\n",
              "      <td>-0.015796</td>\n",
              "      <td>-0.937442</td>\n",
              "      <td>-0.742667</td>\n",
              "      <td>-0.46412</td>\n",
              "      <td>-0.867564</td>\n",
              "      <td>-0.111256</td>\n",
              "      <td>-1.058272</td>\n",
              "      <td>-0.740561</td>\n",
              "      <td>-0.590387</td>\n",
              "      <td>-0.971934</td>\n",
              "      <td>0.889794</td>\n",
              "      <td>-0.866242</td>\n",
              "      <td>-0.012962</td>\n",
              "      <td>0.293937</td>\n",
              "      <td>-0.864355</td>\n",
              "      <td>-0.545627</td>\n",
              "      <td>-0.430474</td>\n",
              "      <td>-0.352597</td>\n",
              "      <td>-0.552913</td>\n",
              "      <td>-0.083678</td>\n",
              "      <td>-1.350151</td>\n",
              "      <td>-0.258087</td>\n",
              "      <td>-0.220520</td>\n",
              "      <td>-13.747071</td>\n",
              "      <td>-1.047191</td>\n",
              "      <td>-1.031076</td>\n",
              "      <td>-0.103194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>0.086891</td>\n",
              "      <td>7.447253</td>\n",
              "      <td>0.420127</td>\n",
              "      <td>-0.696190</td>\n",
              "      <td>-0.106279</td>\n",
              "      <td>-0.576208</td>\n",
              "      <td>-0.301731</td>\n",
              "      <td>-0.296112</td>\n",
              "      <td>-0.344027</td>\n",
              "      <td>-0.032023</td>\n",
              "      <td>-0.217120</td>\n",
              "      <td>0.383101</td>\n",
              "      <td>0.549881</td>\n",
              "      <td>0.126985</td>\n",
              "      <td>-0.015796</td>\n",
              "      <td>-0.945807</td>\n",
              "      <td>-0.738107</td>\n",
              "      <td>-0.46412</td>\n",
              "      <td>-0.839185</td>\n",
              "      <td>-0.111256</td>\n",
              "      <td>-0.526971</td>\n",
              "      <td>-0.275736</td>\n",
              "      <td>-0.282373</td>\n",
              "      <td>-0.294224</td>\n",
              "      <td>0.947341</td>\n",
              "      <td>-0.188134</td>\n",
              "      <td>1.920328</td>\n",
              "      <td>1.540761</td>\n",
              "      <td>-0.160295</td>\n",
              "      <td>-0.144657</td>\n",
              "      <td>0.253381</td>\n",
              "      <td>-0.352597</td>\n",
              "      <td>-0.123191</td>\n",
              "      <td>0.459665</td>\n",
              "      <td>-1.246258</td>\n",
              "      <td>-0.140501</td>\n",
              "      <td>-0.023314</td>\n",
              "      <td>-8.320997</td>\n",
              "      <td>-1.047191</td>\n",
              "      <td>-1.031076</td>\n",
              "      <td>0.362024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>0.014848</td>\n",
              "      <td>-0.244160</td>\n",
              "      <td>0.300407</td>\n",
              "      <td>0.267247</td>\n",
              "      <td>-0.106279</td>\n",
              "      <td>-0.568721</td>\n",
              "      <td>-0.667514</td>\n",
              "      <td>-0.597038</td>\n",
              "      <td>-0.581235</td>\n",
              "      <td>-0.032023</td>\n",
              "      <td>-0.207644</td>\n",
              "      <td>-0.537539</td>\n",
              "      <td>-0.362257</td>\n",
              "      <td>-0.354221</td>\n",
              "      <td>-0.015796</td>\n",
              "      <td>-0.956959</td>\n",
              "      <td>-0.722190</td>\n",
              "      <td>-0.46412</td>\n",
              "      <td>-0.864596</td>\n",
              "      <td>-0.111256</td>\n",
              "      <td>-0.519129</td>\n",
              "      <td>-0.675837</td>\n",
              "      <td>-0.601795</td>\n",
              "      <td>-0.579799</td>\n",
              "      <td>0.928159</td>\n",
              "      <td>-0.178683</td>\n",
              "      <td>0.127720</td>\n",
              "      <td>0.155401</td>\n",
              "      <td>-0.520993</td>\n",
              "      <td>-0.337123</td>\n",
              "      <td>-0.074869</td>\n",
              "      <td>-0.352597</td>\n",
              "      <td>-0.329458</td>\n",
              "      <td>0.198860</td>\n",
              "      <td>-0.934578</td>\n",
              "      <td>-0.393187</td>\n",
              "      <td>-0.069534</td>\n",
              "      <td>0.119562</td>\n",
              "      <td>1.009626</td>\n",
              "      <td>0.991872</td>\n",
              "      <td>-0.103194</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>71 rows Ã— 41 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    page_likes  page_checkins  page_talking_about  ...  Post_Day  Base_Day    target\n",
              "0    -0.118979       1.159622           -0.162282  ...  0.495422  0.486135  0.362024\n",
              "1    -0.374839      -0.244160           -0.522520  ...  1.009626  1.497609 -0.277650\n",
              "2     4.558325      -0.244119           19.798142  ... -1.047191 -1.031076  1.854598\n",
              "3    -0.335906      -0.244160           -0.441924  ...  1.009626  0.991872 -0.297034\n",
              "4     0.039670      -0.237707            0.675481  ...  0.495422  0.486135 -0.238882\n",
              "..         ...            ...                 ...  ...       ...       ...       ...\n",
              "66    0.838301      -0.243871           -0.149421  ...  0.495422  0.486135 -0.238882\n",
              "67    0.039670      -0.237707            0.675481  ...  1.523830  1.497609 -0.161346\n",
              "68   -0.270800      -0.244160            0.127275  ... -1.047191 -1.031076 -0.103194\n",
              "69    0.086891       7.447253            0.420127  ... -1.047191 -1.031076  0.362024\n",
              "70    0.014848      -0.244160            0.300407  ...  1.009626  0.991872 -0.103194\n",
              "\n",
              "[71 rows x 41 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpOb4jybEFr1"
      },
      "source": [
        "**Create df to store test data row to its target value**\n",
        "\n",
        "Store test data target values for transiation from classification to regression\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w9s0nIgEEp2"
      },
      "source": [
        "def initializeTestTargetDF(urls):\n",
        "  df_list = read_data(urls)\n",
        "  df_list = merge_days(df_list)\n",
        "  df_list_2 = []\n",
        "  for df in df_list:\n",
        "     df = removeCols529(df)\n",
        "     df = df.drop(['post_promotion_status'], 1)\n",
        "     df_list_2.append(df)\n",
        "  df_list = df_list_2\n",
        "  merged_df = pd.concat(df_list)\n",
        "  merged_df.reset_index(drop=True, inplace=True)\n",
        "  merged_df = merged_df[[\"target\"]]\n",
        "\n",
        "  return merged_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "dSv0M7gxBRN2",
        "outputId": "845855b5-7906-42f1-eff7-125b09830429"
      },
      "source": [
        "test_target = initializeTestTargetDF(testing_files)\n",
        "test_target"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     target\n",
              "0        35\n",
              "1         2\n",
              "2         0\n",
              "3         0\n",
              "4         0\n",
              "..      ...\n",
              "995       0\n",
              "996       1\n",
              "997       0\n",
              "998       0\n",
              "999       5\n",
              "\n",
              "[1000 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7Mugu0Pr_2x"
      },
      "source": [
        "#### **Data Processing for Individual Variants**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppJCxQ2QsFce"
      },
      "source": [
        "def process_train_data(urls, method):\n",
        "  df_list = read_data(urls)\n",
        "  df_list = merge_days(df_list)\n",
        "  df_list_2 = []\n",
        "  scaler = None\n",
        "\n",
        "  for df in df_list:\n",
        "     df = removeCols529(df)\n",
        "     df = df.drop(['post_promotion_status'], 1)\n",
        "     df = binarize_labels(df)\n",
        "     df_list_2.append(df)\n",
        "\n",
        "  df_list = df_list_2\n",
        "  merged_df = pd.concat(df_list)\n",
        "  df_list.append(merged_df)\n",
        "  uncurse_df_list = []\n",
        "  unwanted_attributes = []\n",
        "\n",
        "  for df in df_list:\n",
        "    uncurse_df_list.append(df)\n",
        "\n",
        "  x_train_list = []\n",
        "  y_train_list = []\n",
        "  scaler_x_list = []\n",
        "  scaler_y_list = []\n",
        "\n",
        "  for df in uncurse_df_list:\n",
        "    features, labels = split_df(df)\n",
        "    features, scaler_x = normalizeTrain(features)\n",
        "    labels, scaler_y = normalizeTrainTarget(labels)\n",
        "    labels = binarize_labels(labels)\n",
        "    x_train_list.append(features)\n",
        "    y_train_list.append(labels)\n",
        "    scaler_x_list.append(scaler_x)\n",
        "    scaler_y_list.append(scaler_y)\n",
        "\n",
        "  return x_train_list, y_train_list, unwanted_attributes, scaler_x_list, scaler_y_list\n",
        "\n",
        "def process_test_data(urls, columns_to_drop, scaler_x, scaler_y):\n",
        "  df_list = read_data(urls)\n",
        "  df_list = merge_days(df_list)\n",
        "  df_list_2 = []\n",
        "  for df in df_list:\n",
        "    df = removeCols529(df)\n",
        "    df = df.drop(['post_promotion_status'], 1)\n",
        "    df = binarize_labels(df)\n",
        "    df_list_2.append(df)\n",
        "  df_list = df_list_2\n",
        "  merged_df = pd.concat(df_list)\n",
        "  merged_df.reset_index(drop=True, inplace=True)\n",
        "  df_list.append(merged_df)\n",
        "  uncurse_df_list = []\n",
        "  for df in df_list:\n",
        "    uncurse_df_list.append(df)\n",
        "  x_test_list = []\n",
        "  y_test_list = []\n",
        "  for df in uncurse_df_list:\n",
        "    features, labels = split_df(df)\n",
        "    features = normalizeTest(features, scaler_x)\n",
        "    labels = normalizeTestTarget(labels, scaler_y)\n",
        "    labels = binarize_labels(labels)\n",
        "    x_test_list.append(features)\n",
        "    y_test_list.append(labels)\n",
        "  return x_test_list, y_test_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gLc1ZtswitI"
      },
      "source": [
        "x_train_list_pearson, y_train_list_pearson, columns_to_drop_pearson, scaler_x_list_pearson, scaler_y_list_pearson = process_train_data(training_files, \"pearson\")\n",
        "x_train_list_spearman, y_train_list_spearman, columns_to_drop_spearman, scaler_x_list_spearman, scaler_y_list_spearman = process_train_data(training_files, \"spearman\")\n",
        "x_train_list_kendall, y_train_list_kendall, columns_to_drop_kendall, scaler_x_list_kendall, scaler_y_list_kendall = process_train_data(training_files, \"kendall\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mm81l9newlT0",
        "outputId": "61c2dc39-ce5b-4056-9f63-43a551344766"
      },
      "source": [
        "x_test_list_pearson, y_test_list_pearson = process_test_data(testing_files, columns_to_drop_pearson, scaler_x_list_pearson[5], scaler_y_list_pearson[5])\n",
        "x_test_merged_pearson = x_test_list_pearson[10]\n",
        "y_test_merged_pearson = y_test_list_pearson[10]\n",
        "\n",
        "x_test_list_spearman, y_test_list_spearman = process_test_data(testing_files, columns_to_drop_spearman, scaler_x_list_spearman[5], scaler_y_list_spearman[5])\n",
        "x_test_merged_spearman = x_test_list_spearman[10]\n",
        "y_test_merged_spearman = y_test_list_spearman[10]\n",
        "\n",
        "x_test_list_kendall, y_test_list_kendall = process_test_data(testing_files, columns_to_drop_kendall, scaler_x_list_kendall[5], scaler_y_list_kendall[5])\n",
        "x_test_merged_kendall = x_test_list_kendall[10]\n",
        "y_test_merged_kendall = y_test_list_kendall[10]\n",
        "\n",
        "print((y_test_merged_pearson))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     target\n",
            "0         1\n",
            "1         1\n",
            "2         0\n",
            "3         0\n",
            "4         0\n",
            "..      ...\n",
            "995       0\n",
            "996       1\n",
            "997       0\n",
            "998       0\n",
            "999       1\n",
            "\n",
            "[1000 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86rn_6zFDt2b"
      },
      "source": [
        "def display_scores(scores):\n",
        "    print(\"Scores:\", scores)\n",
        "    print(\"Mean:\", scores.mean())\n",
        "    print(\"Standard deviation:\", scores.std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OvN7PP9aa3L"
      },
      "source": [
        "## Classifier for 1 and 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSCCjcu_rxGp"
      },
      "source": [
        "**Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a4CX8bcn_Vc3",
        "outputId": "e444f68a-bba2-465b-9c46-5fd501792fb2"
      },
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "max_iterations = np.linspace(1, 100, 100, endpoint=True)\n",
        "train_results = []\n",
        "test_results = []\n",
        "for max_iter in max_iterations:\n",
        "   logistic_regr = LogisticRegression(max_iter=max_iter)\n",
        "   logistic_regr.fit(x_train_list_pearson[5], y_train_list_pearson[5])\n",
        "   train_pred = logistic_regr.predict(x_train_list_pearson[5])\n",
        "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train_list_pearson[5], train_pred)\n",
        "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "   train_results.append(roc_auc)\n",
        "   y_pred = logistic_regr.predict(x_test_merged_pearson)\n",
        "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test_merged_pearson, y_pred)\n",
        "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "   test_results.append(roc_auc)\n",
        "\n",
        "from matplotlib.legend_handler import HandlerLine2D\n",
        "line1, = plt.plot(max_iterations, train_results, 'b', label=\"Train AUC\")\n",
        "line2, = plt.plot(max_iterations, test_results, 'r', label=\"Test AUC\")\n",
        "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
        "plt.ylabel(\"AUC score\")\n",
        "plt.xlabel(\"Max iteration\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Rg7NrkU-Al8",
        "outputId": "9682a48d-1b2b-4321-fb7a-8cb9adc31627"
      },
      "source": [
        "print(test_results.index(max(test_results)))\n",
        "print(max(test_results))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26\n",
            "0.7776986377754834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv8hjVQlbLBz",
        "outputId": "dd33dce0-b504-4d3c-a5b1-d279f3f1d009"
      },
      "source": [
        "log_regr_data = {\"Pearson\": [], \"Spearman\": [], \"Kendall\": [], \"Time Taken\": []}\n",
        "log_regr_index = [\"Variant 1\", \"Variant 2\", \"Variant 3\", \"Variant 4\", \"Variant 5\", \"Variant Merged\", \"Average over 5 variants\"]\n",
        "logistic_regr = LogisticRegression(max_iter=35)\n",
        "\n",
        "for i in range(6):\n",
        "    start = time.time()\n",
        "    logistic_regr.fit(x_train_list_pearson[i], y_train_list_pearson[i])\n",
        "    score_train = logistic_regr.score(x_train_list_pearson[i], y_train_list_pearson[i])\n",
        "    print(score_train)\n",
        "    score = logistic_regr.score(x_test_merged_pearson, y_test_merged_pearson)\n",
        "    log_regr_data[\"Pearson\"].append(score)\n",
        "\n",
        "    logistic_regr.fit(x_train_list_spearman[i], y_train_list_spearman[i])\n",
        "    score = logistic_regr.score(x_test_merged_spearman, y_test_merged_spearman)\n",
        "    log_regr_data[\"Spearman\"].append(score)\n",
        "\n",
        "    logistic_regr.fit(x_train_list_kendall[i], y_train_list_kendall[i])\n",
        "    score = logistic_regr.score(x_test_merged_kendall, y_test_merged_kendall)\n",
        "    log_regr_data[\"Kendall\"].append(score)\n",
        "    end = time.time()\n",
        "    log_regr_data[\"Time Taken\"].append(end - start)\n",
        "\n",
        "log_regr_data[\"Pearson\"].append(sum(log_regr_data[\"Pearson\"][:-1])/5)\n",
        "log_regr_data[\"Spearman\"].append(sum(log_regr_data[\"Spearman\"][:-1])/5)\n",
        "log_regr_data[\"Kendall\"].append(sum(log_regr_data[\"Kendall\"][:-1])/5)\n",
        "log_regr_data[\"Time Taken\"].append(sum(log_regr_data[\"Time Taken\"][:-1])/5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8257344501697234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8231626328217237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8261655848981816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8245462025632075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8250565241420892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8256789418940865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "Vcs5SYp7c1r7",
        "outputId": "dd51ded4-e19b-423e-df85-28eeba9eff94"
      },
      "source": [
        "log_regr_df = pd.DataFrame(log_regr_data)\n",
        "log_regr_df.index = log_regr_index\n",
        "print(\"Logistic Regression Classifier Score\")\n",
        "log_regr_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classifier Score\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pearson</th>\n",
              "      <th>Spearman</th>\n",
              "      <th>Kendall</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Variant 1</th>\n",
              "      <td>0.7610</td>\n",
              "      <td>0.7610</td>\n",
              "      <td>0.7610</td>\n",
              "      <td>0.833843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 2</th>\n",
              "      <td>0.7620</td>\n",
              "      <td>0.7620</td>\n",
              "      <td>0.7620</td>\n",
              "      <td>1.677274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 3</th>\n",
              "      <td>0.7590</td>\n",
              "      <td>0.7590</td>\n",
              "      <td>0.7590</td>\n",
              "      <td>2.350913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 4</th>\n",
              "      <td>0.7590</td>\n",
              "      <td>0.7590</td>\n",
              "      <td>0.7590</td>\n",
              "      <td>3.359592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 5</th>\n",
              "      <td>0.7610</td>\n",
              "      <td>0.7610</td>\n",
              "      <td>0.7610</td>\n",
              "      <td>4.024827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant Merged</th>\n",
              "      <td>0.7640</td>\n",
              "      <td>0.7640</td>\n",
              "      <td>0.7640</td>\n",
              "      <td>11.942633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Average over 5 variants</th>\n",
              "      <td>0.7604</td>\n",
              "      <td>0.7604</td>\n",
              "      <td>0.7604</td>\n",
              "      <td>2.449290</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Pearson  Spearman  Kendall  Time Taken\n",
              "Variant 1                 0.7610    0.7610   0.7610    0.833843\n",
              "Variant 2                 0.7620    0.7620   0.7620    1.677274\n",
              "Variant 3                 0.7590    0.7590   0.7590    2.350913\n",
              "Variant 4                 0.7590    0.7590   0.7590    3.359592\n",
              "Variant 5                 0.7610    0.7610   0.7610    4.024827\n",
              "Variant Merged            0.7640    0.7640   0.7640   11.942633\n",
              "Average over 5 variants   0.7604    0.7604   0.7604    2.449290"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "ZkR1rwLWvBJh",
        "outputId": "b3a35f7c-77eb-403b-f300-947d60767849"
      },
      "source": [
        "plt.title(\"Logistic Regression Score\")\n",
        "plt.bar([\"Variant 1\", \"Variant 2\", \"Variant 3\", \"Variant 4\", \"Variant 5\", \"Merged\", \"Average over 5\"], log_regr_data['Pearson'], width = 0.1, label = 'Pearson')\n",
        "plt.bar(np.arange(len(log_regr_data['Spearman'])) + 0.1, log_regr_data['Spearman'], width = 0.1, label = 'Spearman')\n",
        "plt.bar(np.arange(len(log_regr_data['Kendall'])) + 0.2, log_regr_data['Kendall'], width = 0.1, label = 'Kendall')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5xVZb3H8c+XAQQULwiWcnEo8EKCF0aIvIsXTAUt9YBpoCVpB4/lFY2D5KXSNLUyTlhKkopoqKgYmWGaoYIgNxElRAHNUAEFRRj4nT/WmnEzzDAbZg8z4/q+X6/9mnV51rN+a83ev/3sZ639bEUEZmaWHY3qOgAzM9u2nPjNzDLGid/MLGOc+M3MMsaJ38wsY5z4zcwyxonftpqk/5P0v1uxXQdJqyQV1UZc9ZWkJyQNrOs4zJz4M0LSIknHFLLOiDg/Iq7d0n1HxFsRsUNErN+S/UkaJGl9+qbxoaSZkk7amtjrQkScEBF/KHS9ktpJ+pOk9yStlDRH0qBC78c+P5z4raGZEhE7ADsDvwHGStq50DtpYJ9GxgCLgT2BXYGzgXcLuQNJjQtZn9UtJ/6Mk7SdpFslvZ0+bpW0Xc76yyW9k677rqSQ1CldN1rSdel0a0mPSVoh6QNJz0pqJGkM0AF4NG2pXy6pOK2ncbptK0l3pftYLunh6uKOiA0kCW97oHPOsdwk6S1J76ZdUc234FhGSpooaTVwlKQ90pb0MklvSPqfnLp6SJqWfvJ4V9Iv0uXNJP1R0vvpuZgq6QvpuqclfTedbiRpmKQ3Jf1H0t2SdkrXlZ2fgemxvCfpR5s5HQcDoyNidUSURsSMiHgiJ9ZDJf0zjWdx2acBSTul+12WxjFMUqN03SBJz0m6RdL7wIjqzq81HE789iPgq8ABwP5AD2AYgKQ+wMXAMUAn4MjN1HMJsARoA3wBuAqIiDgbeAs4Oe3eubGSbccALYCvALsBt1QXdNoiPwdYB7yZLv4ZsFd6LJ2AtsDwLTiWM4HrgZbAP4FHgZlpPb2BH0g6Pi17G3BbROwIfBkYly4fCOwEtCdpfZ8PfFLJvgalj6OALwE7AL+uUOZQYO9038Ml7VvF6XgeuF1Sf0kdcldI2hN4AvgVyf/mAODldPWv0li/BBwBfJvknJbpCSwk+X9ez2bOrzUwEeFHBh7AIuCYSpb/C/h6zvzxwKJ0+k7gpznrOgEBdErnRwPXpdPXAI+UrdvcvoHitJ7GwO7ABmCXPI5hEFAKrCBJ+J8AZ6TrBKwGvpxTvhfwxhYcy90563sCb1XY/5XAXen0M8CPgdYVypxL8qbRrZL4nwa+m04/BXw/Z93e6TE1zjk/7XLWvwj0r+K87EKSlOcC60kS+8E5MT9UyTZFwFqgS86y7wFP55zrt3LWbfb8+tGwHm7x2x581mImnd4jZ93inHW50xX9HFgA/EXSQklD89x/e+CDiFieZ/nnI2JnkmQ3ATgsXd6G5FPDS2mXxgrgz+lyyO9YcpftCexRVlda31UkrV+A75C0fl9Nu3PKLjKPASaRXHt4W9KNkppUsq/KznvjnPoB/p0z/THJp4JNRMTyiBgaEV9Jt38ZeFiSSM7vvyrZrDXQpJIY2ubM556P6s6vNSBO/PY2SZIr0yFdBvAO0C5nXfuqKomIjyLikoj4EtAXuFhS77LVm9n/YqCVtvACbUSsAi4AzpZ0IPAeySeAr0TEzuljp0guBOd7LLlxLiZpze6c82gZEV9P9/96RAwg6Zq6AXhQ0vYRsS4ifhwRXYCvASeRdKFUVNl5L6WGF2Uj4j3gJpI3llbpcXy5kqLvkXzCqBjD0tzqKpTf3Pm1BsSJP1uapBcfyx6NgfuAYZLaSGpN0mf7x7T8OOAcSftKagFUec++pJMkdUpbmStJuhw2pKvfJelH3kREvEPSB/0bSbtIaiLp8HwOJiI+AH4HDI/kYu8dwC2SdktjapvTJ5/3saReBD6SdIWk5pKKJO0n6eC07rMktUn3uyLdZoOkoyR1Ta9BfEiSXDdUUv99wA8ldZS0A/AT4P6IKM3n2HNJuiGNrbGkliRviAsi4n3gHuAYSWek63eVdEAkt9KOA66X1DK9FnAxn/3vN5LH+bUGxIk/WyaStNrKHiOA64BpwCxgNjA9XUYkd4b8EphM0o3zfFrPp5XU3Rn4K7AKmAL8JiImp+t+SvLmskLSpZVsezZJgnwV+A/wgy04pluBr0vqBlxRFqekD9N49t6KYyFNjCeRXMh8g6TF+zuSi6EAfYC5klaRXOjtHxGfAF8EHiRJ+vOAv5N0/1R0Z7r8mbT+NcCFW3DcuVoAD5G8AS0kacX3TY/jLeDrJBffPyDpBto/3e5Ckn77hcA/gHvTuKpS5fm1hkUR/iEWy096V8kcYLutaZnWJ5+nYzHbUm7x22ZJOjW9f3sXkr7sRxtqovw8HYtZTTjxW3W+R9L98i+SfvsL6jacGvk8HYvZVsurqyf98sttJPf+/i4iflZhfQfgDyRfoy8ChkbExMKHa2ZmNVVt4k/vTngNOJbkm5lTgQER8UpOmVHAjIgYKakLMDEiimstajMz22r5DLzUg+TWsIUAksYC/YBXcsoEsGM6vROf3QdepdatW0dxcfEWBWtmlnUvvfTSexFRoy/O5ZP427LxN/iWkHydPdcIkm9sXkgyaFalw/9KGgwMBujQoQPTpk3b0njNzDJN0pvVl9q8Ql3cHUAyOmA7knuGx5SN8pcrIkZFRElElLRp4296m5nVhXwS/1I2/np7Ozb+Wjck45aMA4iIKUAzkrFAzMysnskn8U8FOqdfLW8K9CcZHCvXWyRDx5Z9MaYZsKyQgZqZWWFUm/jTL7gMIRlxcB4wLiLmSrpGUt+02CXAeZJmkoxBMij8lWAzs3opr59TS+/Jn1hh2fCc6VeAQwobmpmZ1QZ/c9fMLGOc+M3MMsaJ38wsY5z4zcwyJq+Lu1Z4xUMf32h+UbMzNynTtWOHTZbNHji71mIy25YqvgYgv9eBXwM11yAT/9Y+YcBPmkJp6C/az8NzyI2HutWQn0Pu6jEzyxgnfjOzjHHiNzPLGCd+M7OMceI3M8sYJ34zs4xx4jczyxgnfjOzjHHiNzPLGCd+M7OMceI3M8sYJ34zs4zJK/FL6iNpvqQFkoZWsv4WSS+nj9ckrSh8qGZmVgjVjs4pqQi4HTgWWAJMlTQh/Z1dACLihznlLwQOrIVYzcysAPJp8fcAFkTEwohYC4wF+m2m/ADgvkIEZ2ZmhZdP4m8LLM6ZX5Iu24SkPYGOwN+qWD9Y0jRJ05YtW7alsZqZWQEU+uJuf+DBiFhf2cqIGBURJRFR0qZNmwLv2szM8pFP4l8KtM+Zb5cuq0x/3M1jZlav5ZP4pwKdJXWU1JQkuU+oWEjSPsAuwJTChmhmZoVUbeKPiFJgCDAJmAeMi4i5kq6R1DenaH9gbERE7YRqZmaFkNePrUfERGBihWXDK8yPKFxYZmZWW/zNXTOzjHHiNzPLGCd+M7OMceI3M8sYJ34zs4xx4jczyxgnfjOzjHHiNzPLGCd+M7OMceI3M8sYJ34zs4xx4jczyxgnfjOzjHHiNzPLGCd+M7OMceI3M8sYJ34zs4xx4jczy5i8Er+kPpLmS1ogaWgVZc6Q9IqkuZLuLWyYZmZWKNX+5q6kIuB24FhgCTBV0oSIeCWnTGfgSuCQiFguabfaCtjMzGomnxZ/D2BBRCyMiLXAWKBfhTLnAbdHxHKAiPhPYcM0M7NCySfxtwUW58wvSZfl2gvYS9Jzkp6X1KeyiiQNljRN0rRly5ZtXcRmZlYjhbq42xjoDBwJDADukLRzxUIRMSoiSiKipE2bNgXatZmZbYl8Ev9SoH3OfLt0Wa4lwISIWBcRbwCvkbwRmJlZPZNP4p8KdJbUUVJToD8woUKZh0la+0hqTdL1s7CAcZqZWYFUm/gjohQYAkwC5gHjImKupGsk9U2LTQLel/QKMBm4LCLer62gzcxs61V7OydAREwEJlZYNjxnOoCL04eZmdVj/uaumVnGOPGbmWWME7+ZWcY48ZuZZYwTv5lZxjjxm5lljBO/mVnGOPGbmWWME7+ZWcY48ZuZZYwTv5lZxjjxm5lljBO/mVnGOPGbmWWME7+ZWcY48ZuZZYwTv5lZxjjxm5llTF6JX1IfSfMlLZA0tJL1gyQtk/Ry+vhu4UM1M7NCqPY3dyUVAbcDxwJLgKmSJkTEKxWK3h8RQ2ohRjMzK6B8Wvw9gAURsTAi1gJjgX61G5aZmdWWfBJ/W2BxzvySdFlF35Q0S9KDktpXVpGkwZKmSZq2bNmyrQjXzMxqqlAXdx8FiiOiG/Ak8IfKCkXEqIgoiYiSNm3aFGjXZma2JfJJ/EuB3BZ8u3RZuYh4PyI+TWd/B3QvTHhmZlZo+ST+qUBnSR0lNQX6AxNyC0jaPWe2LzCvcCGamVkhVXtXT0SUShoCTAKKgDsjYq6ka4BpETEB+B9JfYFS4ANgUC3GbGZmNVBt4geIiInAxArLhudMXwlcWdjQzMysNvibu2ZmGePEb2aWMU78ZmYZ48RvZpYxTvxmZhnjxG9mljFO/GZmGePEb2aWMU78ZmYZ48RvZpYxTvxmZhnjxG9mljFO/GZmGePEb2aWMU78ZmYZ48RvZpYxTvxmZhnjxG9mljF5JX5JfSTNl7RA0tDNlPumpJBUUrgQzcyskKpN/JKKgNuBE4AuwABJXSop1xK4CHih0EGamVnh5NPi7wEsiIiFEbEWGAv0q6TctcANwJoCxmdmZgWWT+JvCyzOmV+SLisn6SCgfUQ8vrmKJA2WNE3StGXLlm1xsGZmVnM1vrgrqRHwC+CS6spGxKiIKImIkjZt2tR012ZmthXySfxLgfY58+3SZWVaAvsBT0taBHwVmOALvGZm9VM+iX8q0FlSR0lNgf7AhLKVEbEyIlpHRHFEFAPPA30jYlqtRGxmZjVSbeKPiFJgCDAJmAeMi4i5kq6R1Le2AzQzs8JqnE+hiJgITKywbHgVZY+seVhmZlZb/M1dM7OMceI3M8sYJ34zs4xx4jczyxgnfjOzjHHiNzPLGCd+M7OMceI3M8sYJ34zs4xx4jczyxgnfjOzjHHiNzPLGCd+M7OMceI3M8sYJ34zs4xx4jczyxgnfjOzjHHiNzPLmLwSv6Q+kuZLWiBpaCXrz5c0W9LLkv4hqUvhQzUzs0KoNvFLKgJuB04AugADKkns90ZE14g4ALgR+EXBIzUzs4LIp8XfA1gQEQsjYi0wFuiXWyAiPsyZ3R6IwoVoZmaF1DiPMm2BxTnzS4CeFQtJ+m/gYqApcHRlFUkaDAwG6NChw5bGamZmBVCwi7sRcXtEfBm4AhhWRZlREVESESVt2rQp1K7NzGwL5JP4lwLtc+bbpcuqMhY4pSZBmZlZ7ckn8U8FOkvqKKkp0B+YkFtAUuec2ROB1wsXopmZFVK1ffwRUSppCDAJKALujIi5kq4BpkXEBGCIpGOAdcByYGBtBm1mZlsvn4u7RMREYGKFZcNzpi8qcFxmZlZL/M1dM7OMceI3M8sYJ34zs4xx4jczyxgnfjOzjHHiNzPLGCd+M7OMceI3M8sYJ34zs4xx4jczyxgnfjOzjHHiNzPLGCd+M7OMceI3M8sYJ34zs4xx4jczyxgnfjOzjHHiNzPLmLwSv6Q+kuZLWiBpaCXrL5b0iqRZkp6StGfhQzUzs0KoNvFLKgJuB04AugADJHWpUGwGUBIR3YAHgRsLHaiZmRVGPi3+HsCCiFgYEWuBsUC/3AIRMTkiPk5nnwfaFTZMMzMrlHwSf1tgcc78knRZVb4DPFGToMzMrPY0LmRlks4CSoAjqlg/GBgM0KFDh0Lu2szM8pRP4l8KtM+Zb5cu24ikY4AfAUdExKeVVRQRo4BRACUlJbHF0VqD1bKoJed1OI958+bVdSgA3NF3902WzdO4TZbd2njTl0h9OYZRfb/ImyvW8asXlvPhpxvqOhxrQPJJ/FOBzpI6kiT8/sCZuQUkHQj8FugTEf8peJTW4J3X4Tz2b7c/+3TcB0l1HQ7rlqzYZNm+jTaNa0PTppuWa71vrcS0pdYuXs6uu37IhcD1z7xf1+FYA1JtH39ElAJDgEnAPGBcRMyVdI2kvmmxnwM7AA9IelnShFqL2Bqk9s3b07Rl03qR9D8vJNG4xY7suXOTug7FGpi8+vgjYiIwscKy4TnTxxQ4LvucEXLSrwWSED6vtmX8zV0zs4wp6F09ZvkqHvp4Qetb9LMTqy1TVFRE165dKS0tZY/iTlx7y29o3rxFQeMwawjc4rfMaN68OS+//DJz5syhSZMmPDDmrhrVV1paWqDIzLYtJ37LpAN79GLxooV8/PFqhl8yhDNP6s2Bxw3gkUlPA7Bo8dscduq5nH706Zx+9OnMeHEGAC8+9yKHHXYYffv2pUuXLqxevZoTTzyR/fffn/3224/7778fgKeeeooDDzyQrl27cu655/Lpp8kdzsXFxVx99dUcdNBBdO3alVdffbVOjt+yzYnfMqe0tJTnJv+Vzvt04Xe/vJkehxzGvY89xeQHRnHZtbey+uNP2K31Ljx530ge+NsD3HTHTfz0qp+Wbz99+nRuu+02XnvtNf785z+zxx57MHPmTObMmUOfPn1Ys2YNgwYN4v7772f27NmUlpYycuTI8u1bt27N9OnTueCCC7jpppvq4hRYxjnxW2Z88sknHHDAAZSUlPDFtu04tf/ZTHlmMnfefitnHH8YR552Hms+XctbS99h3bpSzrvsWk49/FQu/s7FLHxtYXk9PXr0oGPHjgB07dqVJ598kiuuuIJnn32WnXbaifnz59OxY0f22msvAAYOHMgzzzxTvv03vvENALp3786iRYu23QkwS/nirmVGWR8/wKz0C1xB8ItRd1P85c50a/RGedkRN/8fX2izK38a+TM2bNhA93bdy9dtv/325dN77bUX06dPZ+LEiQwbNozevXvTr99GYxhuYrvttgOSi82+TmB1wS1+y7SvHX409941iohkBJEZc5I+95UfrmL33VrTqFEjHh33KOvXr690+7fffpsWLVpw1llncdlllzF9+nT23ntvFi1axIIFCwAYM2YMRxxR6fBVZnXCLX6rE/ncfrktDL7oMm788ZWcduwhNI1P6dh+Dx67+5d8f+AZfHPwpYwa/ziHHn0ozVs0r3T72bNnc9lll9GoUSOaNGnCyJEjadasGXfddRenn346paWlHHzwwZx//vnb+MjMqubEb5mxatWqTZY1a96c4T+7FWCjrp7OX+rArL+OY246Vs/Fwy8GoMchPTin3znl5Y4//niOP/74Tert3bs3M2bM2GR5bp9+SUkJTz/99FYdi1lNuKvHzCxjnPjNzDLGid/MLGOc+M3MMsaJ38wsY5z4zcwyxrdzWt0YsVOB61uZV7Hrr7+ee++9l3UboFGjRgz72S10O7CksLGY1XNO/JYZU6ZM4bHHHmP69OnMX/YJyz94n3Vr19bKvkpLS2lcyQ+1m9UHfmZaZrzzzju0bt06HSvnE3ZptSsAJ/TqxnEnncK0p5+gebPtuPfX19OpYweWvb+cH1z5U95Z+g4AV1x3BQf1PIgXX3yRiy66iDVr1tC8eXPuuusu9t57b0aPHs348eNZtWoV69ev55xzzuHhhx9m9erVvP7661x66aWsXbuWMWPGsN122zFx4kRatWrFHXfcwahRo1i7di2dOnVizJgxtGjRgkGDBrHjjjsybdo0/v3vf3PjjTdy2mmn1eEZtM+LvPr4JfWRNF/SAklDK1l/uKTpkkol+Zlp9dJxxx3H4sWL2Wuvvbj+qkuYNuW58nU7tNyR2U+NY8ig/+IHVydDJV80/Od8+/xvc/+T93PrXbdy9Q+vBmCfffbh2WefZcaMGVxzzTVcddVV5fVMnz6dBx98kL///e8AzJkzh/HjxzN16lR+9KMf0aJFC2bMmEGvXr24++67gWS0zqlTpzJz5kz23Xdffv/735fX98477/CPf/yDxx57jKFDN3npmW2Valv8koqA24FjgSXAVEkTIuKVnGJvAYOAS2sjSLNC2GGHHXjppZd49tlnGfvIE1z+3+dy0dAkmZ/Q7zQgGHDK8fxwxM0A/PXZF5j++mfDOKz+aDUfr/qYlUUrGThwIK+//jqSWLduXXmZY489llatWpXPH3XUUbRs2ZKWLVuy0047cfLJJwPJcM6zZs0CkjeHYcOGsWLFClatWrXREBCnnHIKjRo1okuXLrz77ru1dm4sW/Lp6ukBLIiIhQCSxgL9gPLEHxGL0nUbaiFGs4IpKiriyCOPpFWnA+i8TxcmPHhfskICIp0UABs2BPf++V62a7bdRnX876X/y1FHHcVDDz3EokWLOPLII8vX5Q7ZDJ8NwQzJxeSy+UaNGpUPyTxo0CAefvhh9t9/f0aPHr3R+D2525eNIGpWU/l09bQFFufML0mXbTFJgyVNkzRt2bJlW1OF2VabP38+r7/++mfzc2eze9v2AEx6dDwA90/4C726dwXguCO+yj2/u6e8/Kuz0yGbV66kbdvkJTB69Ogax/XRRx+x++67s27dOu65557qNzCroW16cTciRgGjAEpKStx8ybI8b78spFWrVnHhhReyYsUKSkO0L/4Sw2+4lWefmsSHK1fQ7Zgz2K5pU+67/ScA/PLayzhr2I2cesSprC9dT/de3bn6pqu5/PLLGThwINdddx0nnljz4aWvvfZaevbsSZs2bejZsycfffRRjes025x8Ev9SoH3OfLt0mVmD0r17d/75z38Cn/0CV5lB5/8Pdw0btNGy1q124ebf3bxJPb169eK1114rn7/uuuuSOgYNYtCgz+qoOJ87JHPuugsuuIALLrhgk/1U/DRR2bDSZlsjn66eqUBnSR0lNQX6AxNqNywzM6st1Sb+iCgFhgCTgHnAuIiYK+kaSX0BJB0saQlwOvBbSXNrM2izQnpiyqzye/rNsiCvPv6ImAhMrLBseM70VJIuIDMzq+c8SJuZWcY48ZuZZYwTv5lZxniQNqsTXf/QtaD1zR44u9oyO+ywQ/ktkc/+7S/cOOIqfnvvePZo16FG+86tt7oyixYt4qSTTmLOnDk12qdZTTjxW+Y89dRT3DB8KCP/+KcaJ32zhshdPZYpzzzzDOeddx6/Gj2W9sUdAXhs/P2ceVJvDji2P9+7/DrWr18PwA6dD+G262/jG0d+gzP7nMl7/3kPgDfeeINevXrRtWtXhg0bVl73qlWr6N27NwcddBBdu3blkUce2fYHaJYHJ37LjE8//ZRTTjmFhx9+mI6d9gJg4evzmfToQ/zhoT/z8pNjKSoq4p7xTwCw+uNP2L9kf8Y/PZ7uvbrzpzF/AuCiiy7iggsuYPbs2ey+++7l9Tdr1oyHHnqI6dOnM3nyZC655BIPrGb1khO/ZUaTJk342te+ttF49y8893fmzZrJt046mgOO7c9T/3iRhW8tAaBp0yYccdwRAHTp1oWli5ORSp577jkGDBgAwNlnn11eV0Rw1VVX0a1bN4455hiWLl3qoZStXnIfv2VGo0aNGDduHL179yZ+dTPfvfASIuDk0/tz0dCr6dbojY3KN2ncuHyI5qKiItaXri9fV7Y81z333MOyZct46aWXaNKkCcXFxaxZs6Z2D8psK7jFb5nSokULHn/8cR5/+EHGjx1Dz0MO56+PT+D995Jhwj9YvpI3l7y92ToOOeQQxo4dC7DRMMorV65kt912o0mTJkyePJk333yz9g7ErAbc4rc6kc/tl7WlVatWjBzzAOecdiJXjPgp/33Zj7jgW9+gaayhSePG3H79UPZst0eV2992222ceeaZ3HDDDfTr1698+be+9S1OPvlkunbtSklJCfvss8+2OByzLebEb5mRe6/9F/doxxP/nFk+36fvNzbp6ln1+nOUjTZ4XN/jOK7vcQB07NiRKVOmlJcrG5a5devWGy2vbN/FxcW+h9/qnLt6zMwyxonfzCxjnPhtmwjC97TXgogg8Hm1LePEb9vE4k8Ws/ajtU7+BRQRlH78IW+uWFfXoVgD44u7tk3c8dYdnMd5NP+0eV2HAsC7yz/ZZNk8Ldtk2b8bb/oSabSsfrSX3l3+MW+uWMevXlhe16FYA+PEb9vER+s/4hdv/ILZh9fdbZy5Thj6+CbLFjU7c5NlZ3TcdBC3urwVNVdlx2CWj7yaLpL6SJovaYGkoZWs307S/en6FyQVFzpQMzMrjGoTv6Qi4HbgBKALMEBSlwrFvgMsj4hOwC3ADYUO1MzMCiOfFn8PYEFELIyItcBYoF+FMv2AP6TTDwK9VdlgJmZmVudU3V0Wkk4D+kTEd9P5s4GeETEkp8yctMySdP5faZn3KtQ1GBiczu4NzC/AMbQG3qu2VP3l+OteQz8Gx1/3tuUx7BkRbWpSwTa9uBsRo4BRhaxT0rSIKClknduS4697Df0YHH/da2jHkE9Xz1Kgfc58u3RZpWUkNQZ2At4vRIBmZlZY+ST+qUBnSR0lNQX6AxMqlJkADEynTwP+Fv6mjplZvVRtV09ElEoaAkwCioA7I2KupGuAaRExAfg9MEbSAuADkjeHbaWgXUd1wPHXvYZ+DI6/7jWoY6j24q6ZmX2+1I/vnpuZ2TbjxG9mljHbJPFLmizp+ArLfiBp5BbUcY2kY7Zy/wdI+noV63ZN41sl6ddVlKnP8R8r6SVJs9O/R1dRrj4fQw9JL6ePmZJOraRMvY0/p0yH9Hl0aSXr6m38koolfZLzP/i/POsMSX/MmW8saZmkx7Ymxi0h6ZR0//tIOnJb7LM+kzRC0tKc/+Fmn6vJeN61/CD50tZdFZY9Dxye5/ZFNdz/IODXVazbHjgUOH8zZepz/AcCe6TT+wFLG+AxtAAap9O7A/8pm28I8eeUeRB4ALi0gZ3/YmDOVtS5CngZaJ7On5DOP7YFdTTe0v2m290PPAv8GDhyS/ZZG+d3Wz8qxguMqOx5V+X22yjIVumLuWk6Xwy8BQgYCUwD5gI/ztlmEcmYP9NJ7hIaDZyWrhtOcpvpHJKr6WUXqZ9Ot3kReA04DGia7mtZ+qT8rypi3NwLo97Hn24vkruqtmvAx9AReJdNE2BoBz8AAAYISURBVH+9jh84Bfg5VbwA63P81Czx/yQnpruBK0iTMEmj6s40lhlAv5zX2gTgb8DfSd74xwGvAA8BLwAladnjgCnpOXgA2CF9vAf8C1gD/DLd5oGc2I7MiWOTOqo4v+el53Qm8CegRVruyyRv0rOB64BVOfu5LN1mVu7/rsJ5GpBuOwe4IV12PvDzyvIPcFZ6zl4Gfkua5NPzfXMa36EV9jGC+pb408Aey/nHDwVuKntBpH+L0idtt5x/yuU524/OeYK1ylk+Bjg550l/czr9deCvFU/qZuLbbJn6Hn9a7rSybRraMQA9SRLfKuDUhhQ/SSKakv4dQRUvwHocfzGwmiQ5/x04LM/X9CqgG8knnWYkiepIPku4PwHOSqd3Jnkj2j6NZUnOcV8K/Dad3g8oBUpIhkF4Btg+XXcFyRveoHTfnYF/Ak8Cj5O8uZWVHUmSQCuto4rzu2vO9HXAhTn/twHp9PmkiZ/kDWUUyZt3o7Tc4RXO0R5pXG1Ibp//G0kjoQ3JGGhl5Z4g6XnYF3gUaJIu/w3w7XQ6gDOq+F+MSI9nFsmb7S6b+99ty4u79/HZ/f3903mAMyRNJ3nSfYVkBNAy91dR11Hp8M+zgaPT7cqMT/++RPKELpR6Hb+kr5C0Xr7XEI8hIl6IiK8ABwNXSmrWgOIfAdwSEauqKVdf438H6BARBwIXA/dK2jGP7YiIWek+BgATK6w+Dhgq6WWSN6RmQNkPHDwZER+k04eSDP5IRMwhSV4AXyU5F8+ldQwE9gTOBRZGxOvpdqtIkuKfgZPT0QNOBB7ZTB1lcs/vfpKeTc/pt/jsnPYi+aQAcG+F4zuO5P82HdiH5M0o18HA0xGxLCJKgXtI3hyWAQslfVXSrum2zwG9ge7A1DTe3sCX0rrWk3wSqcxIkk8mB5D8P2+uohywbcfqeQS4RdJBJB+hXpLUkeTd/uCIWC5pNMmTo8zqipWkCeE3JB8FF0saUWGbT9O/6yns8dXb+CW1I/mI/O2I+FdDPIYyETFP0iqSlt+0BhJ/T+A0STeStGw3SFoTERVvFqiX8UfEp2XbpDH9C9iLTc9/VSYAN5G09nfNDRX4ZkRsNBijpJ5UclyVEMkbxICcbVuRDBEjSYtIPiU1I+nqGQsMIenunBYRH0napI4KcuMYDZwSETMlDUqPp7r4fhoRv83jWCozFjgDeBV4KCIijfcPEXFlJeXXRMT6yiqKiHfLg5LuIPn0UaVt1uJPW0OTST6GlLV0diQ58SslfYHk4lB1yp7g70nagaR7ozofAS23LOKN1df4Je1M8jF3aEQ8t7lK6vExdExbaUjak6T1s6ihxB8Rh0VEcUQUA7cCP6kk6dfb+CW1UfK7G0j6EkmrdWEedZa5k6R/u+JPk00CLkyTGZIOrGL750gSIEp+66Nruvx54BBJndJ12wPfJ2k1/wfoHRHtSVr7rUi6qQ4i6asfW1UdkvaqIo6WwDuSmpC0+Ms8D3wznc4dlWAScG76P0BSW0m7VajzReAISa3TczwgjROSxlq/dFlZvE+RNCJ2S+tslb4mNkvS7jmzp5JcT6jStr6P/z5g//QvETGT5GPSqyQfoTabuNJtVgB3kBzYJJILK9WZDHRJb3P6r4or05bDL4BBkpZo0x+aqc/xDwE6AcNzbuWq+OSr78dwKDAz/Wj7EPD9qDCkdz2Pf0vUx/gPB2al5/9B4PycbphqRcSSiPhlJauuBZqkdc9N5yvzG6CNpFdI+tbnAivT7pBBwH2SZpFcRzkjjXEw8HjaRfYKyZ1t60lauiekf6mijn2qiON/ST45PEfy/yjzA+DidPtOwMq07r+Q/M+mpN1DD1LhzTUi3iG5njOZ5KLsSxHxSLpuOTCPZJjlF9NlrwDDgL+k+3uS5E636tyo5JbuWcBRwA83V9hDNphZnUpbwk0iYo2kLwN/BfaO5Ief6pykFsAnaVdMf5ILvRV/jKpB8Y+tm1ldawFMTrtYRPKJr14k/VR34Ndpl9UKkovLDZpb/GZmGeOxeszMMsaJ38wsY5z4zcwyxonfzCxjnPjNzDLm/wGbxtr0icMbQwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVmURSrmjTWy",
        "outputId": "cbb4e3c6-3027-4ad6-b3e9-e4fcb3184334"
      },
      "source": [
        "cm_index = [\"Actual Negative\", \"Actual Positive\"]\n",
        "\n",
        "logistic_regr.fit(x_train_list_pearson[5], y_train_list_pearson[5])\n",
        "y_pred = logistic_regr.predict(x_test_merged_pearson)\n",
        "print(\"Pearson\")\n",
        "cm_pearson = confusion_matrix(y_test_merged_pearson, y_pred)\n",
        "tn, fp, fn, tp = confusion_matrix(y_test_merged_pearson, y_pred).ravel()\n",
        "print(\"True Negative: \" + str(tn))\n",
        "print(\"False Positive: \" + str(fp))\n",
        "print(\"False Negative: \" + str(fn))\n",
        "print(\"True Positive: \" + str(tp))\n",
        "df_pearson = pd.DataFrame(cm_pearson, columns = [\"Predicted Negative\", \"Predicted Positive\"])\n",
        "df_pearson.index = cm_index\n",
        "print(df_pearson)\n",
        "print(\"Precision, Recall, Fscore\")\n",
        "print(precision_recall_fscore_support(y_test_merged_pearson, y_pred, average=\"weighted\"))\n",
        "log_reg_pearson = logistic_regr\n",
        "\n",
        "logistic_regr.fit(x_train_list_spearman[5], y_train_list_spearman[5])\n",
        "y_pred = logistic_regr.predict(x_test_merged_spearman)\n",
        "print(\"Spearman\")\n",
        "cm_spearman = confusion_matrix(y_test_merged_spearman, y_pred)\n",
        "df_spearman = pd.DataFrame(cm_spearman, columns = [\"Predicted Negative\", \"Predicted Positive\"])\n",
        "df_spearman.index = cm_index\n",
        "print(df_spearman)\n",
        "print(\"Precision, Recall, Fscore\")\n",
        "print(precision_recall_fscore_support(y_test_merged_spearman, y_pred, average=\"weighted\"))\n",
        "log_reg_spearman = logistic_regr\n",
        "\n",
        "logistic_regr.fit(x_train_list_kendall[5], y_train_list_kendall[5])\n",
        "y_pred = logistic_regr.predict(x_test_merged_kendall)\n",
        "print(\"Kendall\")\n",
        "cm_kendall = confusion_matrix(y_test_merged_kendall, y_pred)\n",
        "df_kendall = pd.DataFrame(cm_kendall, columns = [\"Predicted Negative\", \"Predicted Positive\"])\n",
        "df_kendall.index = cm_index\n",
        "print(df_kendall)\n",
        "print(\"Precision, Recall, Fscore\")\n",
        "print(precision_recall_fscore_support(y_test_merged_kendall, y_pred, average=\"weighted\"))\n",
        "log_reg_kendall = logistic_regr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pearson\n",
            "True Negative: 271\n",
            "False Positive: 86\n",
            "False Negative: 150\n",
            "True Positive: 493\n",
            "                 Predicted Negative  Predicted Positive\n",
            "Actual Negative                 271                  86\n",
            "Actual Positive                 150                 493\n",
            "Precision, Recall, Fscore\n",
            "(0.777296805451286, 0.764, 0.7675269081408117, None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spearman\n",
            "                 Predicted Negative  Predicted Positive\n",
            "Actual Negative                 271                  86\n",
            "Actual Positive                 150                 493\n",
            "Precision, Recall, Fscore\n",
            "(0.777296805451286, 0.764, 0.7675269081408117, None)\n",
            "Kendall\n",
            "                 Predicted Negative  Predicted Positive\n",
            "Actual Negative                 271                  86\n",
            "Actual Positive                 150                 493\n",
            "Precision, Recall, Fscore\n",
            "(0.777296805451286, 0.764, 0.7675269081408117, None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDiTIvpMr12y"
      },
      "source": [
        "**Random Forest Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaNTX5WIL2Fw"
      },
      "source": [
        "Test overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uh2-yZbZLG6i",
        "outputId": "e6767711-7cc3-4277-9433-ca16c0db21ae"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "max_depths = np.linspace(1, 32, 32, endpoint=True)\n",
        "train_results = []\n",
        "test_results = []\n",
        "for max_depth in max_depths:\n",
        "   rf = RandomForestClassifier(max_depth=max_depth, n_jobs=-1)\n",
        "   rf.fit(x_train_list_pearson[5], y_train_list_pearson[5])\n",
        "   train_pred = rf.predict(x_train_list_pearson[5])\n",
        "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train_list_pearson[5], train_pred)\n",
        "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "   train_results.append(roc_auc)\n",
        "   y_pred = rf.predict(x_test_merged_pearson)\n",
        "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test_merged_pearson, y_pred)\n",
        "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "   test_results.append(roc_auc)\n",
        "\n",
        "from matplotlib.legend_handler import HandlerLine2D\n",
        "line1, = plt.plot(max_depths, train_results, 'b', label=\"Train AUC\")\n",
        "line2, = plt.plot(max_depths, test_results, 'r', label=\"Test AUC\")\n",
        "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
        "plt.ylabel(\"AUC score\")\n",
        "plt.xlabel(\"Tree depth\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Nw2wLHfr5YS",
        "outputId": "3747f361-f599-433f-8044-96a880249389"
      },
      "source": [
        "rfc_data = {\"Pearson\": [], \"Spearman\": [], \"Kendall\": [], \"Time Taken\": []}\n",
        "rfc_index = [\"Variant 1\", \"Variant 2\", \"Variant 3\", \"Variant 4\", \"Variant 5\", \"Variant Merged\", \"Average over 5 variants\"]\n",
        "rfc = RandomForestClassifier(max_depth=16, random_state=0)\n",
        "\n",
        "for i in range(6):\n",
        "    start = time.time()\n",
        "    rfc.fit(x_train_list_pearson[i], y_train_list_pearson[i])\n",
        "    score_train = rfc.score(x_train_list_pearson[i], y_train_list_pearson[i])\n",
        "    print(\"Train score\")\n",
        "    print(score_train)\n",
        "    score = rfc.score(x_test_merged_pearson, y_test_merged_pearson)\n",
        "    print(\"Test score\")\n",
        "    print(score)\n",
        "    rfc_data[\"Pearson\"].append(score)\n",
        "\n",
        "    rfc.fit(x_train_list_spearman[i], y_train_list_spearman[i])\n",
        "    score = rfc.score(x_test_merged_spearman, y_test_merged_spearman)\n",
        "    rfc_data[\"Spearman\"].append(score)\n",
        "\n",
        "    rfc.fit(x_train_list_kendall[i], y_train_list_kendall[i])\n",
        "    score = rfc.score(x_test_merged_kendall, y_test_merged_kendall)\n",
        "    rfc_data[\"Kendall\"].append(score)\n",
        "    end = time.time()\n",
        "    rfc_data[\"Time Taken\"].append(end - start)\n",
        "\n",
        "rfc_data[\"Pearson\"].append(sum(rfc_data[\"Pearson\"][:-1])/5)\n",
        "rfc_data[\"Spearman\"].append(sum(rfc_data[\"Spearman\"][:-1])/5)\n",
        "rfc_data[\"Kendall\"].append(sum(rfc_data[\"Kendall\"][:-1])/5)\n",
        "rfc_data[\"Time Taken\"].append(sum(rfc_data[\"Time Taken\"][:-1])/5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score\n",
            "0.955090478399961\n",
            "Test score\n",
            "0.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score\n",
            "0.9390003935458481\n",
            "Test score\n",
            "0.813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score\n",
            "0.9294868618804605\n",
            "Test score\n",
            "0.817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score\n",
            "0.9212461975764225\n",
            "Test score\n",
            "0.815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score\n",
            "0.9176807516454806\n",
            "Test score\n",
            "0.812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score\n",
            "0.8999772732173991\n",
            "Test score\n",
            "0.816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xpyv-4AZsWRJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "0e7b046c-5cb3-4c88-cbfd-b134b2154caa"
      },
      "source": [
        "rfc_df = pd.DataFrame(rfc_data)\n",
        "rfc_df.index = rfc_index\n",
        "print(\"Random Forest Classification Score\")\n",
        "rfc_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classification Score\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pearson</th>\n",
              "      <th>Spearman</th>\n",
              "      <th>Kendall</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Variant 1</th>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>17.614882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 2</th>\n",
              "      <td>0.8130</td>\n",
              "      <td>0.8130</td>\n",
              "      <td>0.8130</td>\n",
              "      <td>34.896646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 3</th>\n",
              "      <td>0.8170</td>\n",
              "      <td>0.8170</td>\n",
              "      <td>0.8170</td>\n",
              "      <td>52.643489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 4</th>\n",
              "      <td>0.8150</td>\n",
              "      <td>0.8150</td>\n",
              "      <td>0.8150</td>\n",
              "      <td>69.583398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 5</th>\n",
              "      <td>0.8120</td>\n",
              "      <td>0.8120</td>\n",
              "      <td>0.8120</td>\n",
              "      <td>86.995146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant Merged</th>\n",
              "      <td>0.8160</td>\n",
              "      <td>0.8160</td>\n",
              "      <td>0.8160</td>\n",
              "      <td>299.000768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Average over 5 variants</th>\n",
              "      <td>0.8114</td>\n",
              "      <td>0.8114</td>\n",
              "      <td>0.8114</td>\n",
              "      <td>52.346712</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Pearson  Spearman  Kendall  Time Taken\n",
              "Variant 1                 0.8000    0.8000   0.8000   17.614882\n",
              "Variant 2                 0.8130    0.8130   0.8130   34.896646\n",
              "Variant 3                 0.8170    0.8170   0.8170   52.643489\n",
              "Variant 4                 0.8150    0.8150   0.8150   69.583398\n",
              "Variant 5                 0.8120    0.8120   0.8120   86.995146\n",
              "Variant Merged            0.8160    0.8160   0.8160  299.000768\n",
              "Average over 5 variants   0.8114    0.8114   0.8114   52.346712"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPbIRUMmxKIV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d17ba78-2fe2-449f-8235-67841b5c4e54"
      },
      "source": [
        "cm_index = [\"Actual Negative\", \"Actual Positive\"]\n",
        "\n",
        "rfc.fit(x_train_list_pearson[5], y_train_list_pearson[5])\n",
        "y_pred = rfc.predict(x_test_merged_pearson)\n",
        "y_pred_classification = y_pred\n",
        "print(\"Pearson\")\n",
        "cm_pearson = confusion_matrix(y_test_merged_pearson, y_pred)\n",
        "df_pearson = pd.DataFrame(cm_pearson, columns = [\"Predicted Negative\", \"Predicted Positive\"])\n",
        "df_pearson.index = cm_index\n",
        "print(df_pearson)\n",
        "print(\"Precision, Recall, Fscore\")\n",
        "print(precision_recall_fscore_support(y_test_merged_pearson, y_pred, average=\"weighted\"))\n",
        "rfc_pearson = rfc\n",
        "\n",
        "rfc.fit(x_train_list_spearman[5], y_train_list_spearman[5])\n",
        "y_pred = rfc.predict(x_test_merged_spearman)\n",
        "print(\"Spearman\")\n",
        "cm_spearman = confusion_matrix(y_test_merged_spearman, y_pred)\n",
        "df_spearman = pd.DataFrame(cm_spearman, columns = [\"Predicted Negative\", \"Predicted Positive\"])\n",
        "df_spearman.index = cm_index\n",
        "print(df_spearman)\n",
        "print(\"Precision, Recall, Fscore\")\n",
        "print(precision_recall_fscore_support(y_test_merged_spearman, y_pred, average=\"weighted\"))\n",
        "rfc_spearman = rfc\n",
        "\n",
        "rfc.fit(x_train_list_kendall[5], y_train_list_kendall[5])\n",
        "y_pred = rfc.predict(x_test_merged_kendall)\n",
        "print(\"Kendall\")\n",
        "cm_kendall = confusion_matrix(y_test_merged_kendall, y_pred)\n",
        "df_kendall = pd.DataFrame(cm_kendall, columns = [\"Predicted Negative\", \"Predicted Positive\"])\n",
        "df_kendall.index = cm_index\n",
        "print(df_kendall)\n",
        "print(\"Precision, Recall, Fscore\")\n",
        "print(precision_recall_fscore_support(y_test_merged_kendall, y_pred, average=\"weighted\"))\n",
        "rfc_kendall = rfc\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pearson\n",
            "                 Predicted Negative  Predicted Positive\n",
            "Actual Negative                 227                 130\n",
            "Actual Positive                  54                 589\n",
            "Precision, Recall, Fscore\n",
            "(0.8151363251649434, 0.816, 0.8101743793701867, None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spearman\n",
            "                 Predicted Negative  Predicted Positive\n",
            "Actual Negative                 227                 130\n",
            "Actual Positive                  54                 589\n",
            "Precision, Recall, Fscore\n",
            "(0.8151363251649434, 0.816, 0.8101743793701867, None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kendall\n",
            "                 Predicted Negative  Predicted Positive\n",
            "Actual Negative                 227                 130\n",
            "Actual Positive                  54                 589\n",
            "Precision, Recall, Fscore\n",
            "(0.8151363251649434, 0.816, 0.8101743793701867, None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WITODYEvt2VG"
      },
      "source": [
        "### **Support Vector Classifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dRTJaTru8kV"
      },
      "source": [
        "Linear SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytGN5lmUt-in",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18bde00d-10c4-4fff-d134-2524ff5c954c"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#Pick Pearson\n",
        "x_train = x_train_list_pearson[5]\n",
        "y_train = y_train_list_pearson[5]\n",
        "x_test = x_test_merged_pearson\n",
        "y_test = y_test_merged_pearson\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "regularization = 0.001 # L2 regularization\n",
        "\n",
        "svc_linear_train_scores = {}\n",
        "svc_linear_test_scores = {}\n",
        "svc_linear_times = {}\n",
        "\n",
        "# Fit the scaling to training data and test data\n",
        "scaler.fit(x_train)\n",
        "\n",
        "x_train_scaled = scaler.transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "while regularization <= 1000:\n",
        "  start = time.time()\n",
        "  svc_linear = SVC(kernel='linear', C=regularization, max_iter=500)\n",
        "  svc_linear.fit(x_train_scaled, y_train)\n",
        "\n",
        "  print(\"Regularization: \", regularization)\n",
        "\n",
        "  svc_linear_train_score = svc_linear.score(x_train_scaled, y_train)\n",
        "  print(\"Train: \", svc_linear_train_score)\n",
        "\n",
        "  svc_linear_test_score = svc_linear.score(x_test_scaled, y_test)\n",
        "  print(\"Test: \", svc_linear_test_score)\n",
        "\n",
        "  svc_linear_train_scores[regularization] = svc_linear_train_score\n",
        "  svc_linear_test_scores[regularization] = svc_linear_test_score\n",
        "\n",
        "  end = time.time()\n",
        "\n",
        "  svc_linear_times[regularization] = end - start\n",
        "  \n",
        "  regularization *= 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regularization:  0.001\n",
            "Train:  0.44673721369645314\n",
            "Test:  0.643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regularization:  0.01\n",
            "Train:  0.44667085812681545\n",
            "Test:  0.642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regularization:  0.1\n",
            "Train:  0.44673389591797125\n",
            "Test:  0.642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regularization:  1.0\n",
            "Train:  0.5532793751959563\n",
            "Test:  0.356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regularization:  10.0\n",
            "Train:  0.44792166061448574\n",
            "Test:  0.644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regularization:  100.0\n",
            "Train:  0.5778624548574766\n",
            "Test:  0.456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regularization:  1000.0\n",
            "Train:  0.48421981609553877\n",
            "Test:  0.555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hWwe_0xvZBY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "4f37595b-284d-418a-e345-d6b068169492"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(list(svc_linear_train_scores.keys()), list(svc_linear_train_scores.values()), label = 'Training score')\n",
        "plt.plot(list(svc_linear_test_scores.keys()), list(svc_linear_test_scores.values()), label = 'Testing score')\n",
        "plt.title(\"Score vs Regularization factor\")\n",
        "plt.xlabel(\"Regularization\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.legend()\n",
        "svc_linear_df = pd.DataFrame(svc_linear_times, index=[\"Time Taken\"])\n",
        "svc_linear_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0.001</th>\n",
              "      <th>0.010</th>\n",
              "      <th>0.100</th>\n",
              "      <th>1.000</th>\n",
              "      <th>10.000</th>\n",
              "      <th>100.000</th>\n",
              "      <th>1000.000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Time Taken</th>\n",
              "      <td>49.632922</td>\n",
              "      <td>49.622289</td>\n",
              "      <td>49.650115</td>\n",
              "      <td>37.334838</td>\n",
              "      <td>27.830386</td>\n",
              "      <td>22.141036</td>\n",
              "      <td>23.460287</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             0.001      0.010      0.100     ...   10.000     100.000    1000.000\n",
              "Time Taken  49.632922  49.622289  49.650115  ...  27.830386  22.141036  23.460287\n",
              "\n",
              "[1 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prhIbi-U42va",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "43a54e68-0a0f-4888-f4f5-d7ec794e5cf8"
      },
      "source": [
        "best = max(svc_linear_test_scores, key=svc_linear_test_scores.get)\n",
        "svc_linear = SVC(kernel='linear', C=best, max_iter=500)\n",
        "svc_linear.fit(x_train_scaled, y_train)\n",
        "\n",
        "y_pred = svc_linear.predict(x_test_scaled)\n",
        "print(\"Precision, Recall, Fscore\")\n",
        "print(precision_recall_fscore_support(y_test, y_pred, average=\"weighted\"))\n",
        "print(\"Best regularization: \" + str(best))\n",
        "cm_linear = confusion_matrix(y_test, y_pred)\n",
        "df_linear = pd.DataFrame(cm_linear, columns = [\"Predicted Negative\", \"Predicted Positive\"])\n",
        "df_linear.index = cm_index\n",
        "df_linear"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision, Recall, Fscore\n",
            "(0.6520481444333, 0.644, 0.5073886178861788, None)\n",
            "Best regularization: 10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted Negative</th>\n",
              "      <th>Predicted Positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Actual Negative</th>\n",
              "      <td>2</td>\n",
              "      <td>355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual Positive</th>\n",
              "      <td>1</td>\n",
              "      <td>642</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Predicted Negative  Predicted Positive\n",
              "Actual Negative                   2                 355\n",
              "Actual Positive                   1                 642"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cH6xeq9OYhv",
        "outputId": "90e38021-12ae-4deb-8aed-e3b8a29851a4"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "lin_svc_data = {\"Accuracy\": [], \"Time Taken\": []}\n",
        "lin_svc_index = [\"Variant 1\", \"Variant 2\", \"Variant 3\", \"Variant 4\", \"Variant 5\", \"Variant Merged\", \"Average over 5 variants\"]\n",
        "svc_linear = SVC(kernel='linear', C=10, max_iter=500)\n",
        "\n",
        "for i in range(6):\n",
        "    start = time.time()\n",
        "    svc_linear.fit(x_train_list_pearson[i], y_train_list_pearson[i])\n",
        "    score_train = svc_linear.score(x_train_list_pearson[i], y_train_list_pearson[i])\n",
        "    print(score_train)\n",
        "    score = svc_linear.score(x_test_merged_pearson, y_test_merged_pearson)\n",
        "    lin_svc_data[\"Accuracy\"].append(score)\n",
        "\n",
        "    end = time.time()\n",
        "    lin_svc_data[\"Time Taken\"].append(end - start)\n",
        "\n",
        "lin_svc_data[\"Accuracy\"].append(sum(lin_svc_data[\"Accuracy\"][:-1])/5)\n",
        "lin_svc_data[\"Time Taken\"].append(sum(lin_svc_data[\"Time Taken\"][:-1])/5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6877823634276783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5976116686343959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.565715371021817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4443537126614472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4387630005526805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.44792166061448574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "K5QwW8jiPOOa",
        "outputId": "a990f5f6-7c28-4928-9606-a1e6785e7de0"
      },
      "source": [
        "lin_svc_df = pd.DataFrame(lin_svc_data)\n",
        "lin_svc_df.index = lin_svc_index\n",
        "print(\"Linear SVC Classifier Score\")\n",
        "lin_svc_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear SVC Classifier Score\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Variant 1</th>\n",
              "      <td>0.6830</td>\n",
              "      <td>1.071550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 2</th>\n",
              "      <td>0.4560</td>\n",
              "      <td>2.480324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 3</th>\n",
              "      <td>0.3660</td>\n",
              "      <td>3.923224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 4</th>\n",
              "      <td>0.6390</td>\n",
              "      <td>5.091311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 5</th>\n",
              "      <td>0.5940</td>\n",
              "      <td>7.497102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant Merged</th>\n",
              "      <td>0.6440</td>\n",
              "      <td>29.286992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Average over 5 variants</th>\n",
              "      <td>0.5476</td>\n",
              "      <td>4.012703</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Accuracy  Time Taken\n",
              "Variant 1                  0.6830    1.071550\n",
              "Variant 2                  0.4560    2.480324\n",
              "Variant 3                  0.3660    3.923224\n",
              "Variant 4                  0.6390    5.091311\n",
              "Variant 5                  0.5940    7.497102\n",
              "Variant Merged             0.6440   29.286992\n",
              "Average over 5 variants    0.5476    4.012703"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIl6lDqpREeR",
        "outputId": "089dd370-0443-4104-e626-64625da218b8"
      },
      "source": [
        "svc_linear.fit(x_train_list_pearson[5], y_train_list_pearson[5])\n",
        "pred = svc_linear.predict(x_test_merged_pearson)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "-LKr2M3ARbao",
        "outputId": "45cf333b-7736-4de3-a069-0a4ac57151e0"
      },
      "source": [
        "data = {\"Predicted Value\": pred, \"Target Value\": list(y_test_merged_pearson['target'])}\n",
        "lin_svc_df = pd.DataFrame(data)\n",
        "lin_svc_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted Value</th>\n",
              "      <th>Target Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Predicted Value  Target Value\n",
              "0                  1             1\n",
              "1                  1             1\n",
              "2                  1             0\n",
              "3                  1             0\n",
              "4                  1             0\n",
              "..               ...           ...\n",
              "995                1             0\n",
              "996                1             1\n",
              "997                1             0\n",
              "998                1             0\n",
              "999                1             1\n",
              "\n",
              "[1000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cF23r8Rs6JEj"
      },
      "source": [
        "Poly SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2n-4jE46LXy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc758e62-398b-4698-fe5f-c4a3ecbc4e7f"
      },
      "source": [
        "regularization = 0.001 # L2 regularization\n",
        "\n",
        "svc_poly_train_scores = {}\n",
        "svc_poly_test_scores = {}\n",
        "svc_poly_times = {}\n",
        "\n",
        "while regularization <= 1000:\n",
        "  start = time.time()\n",
        "  svc_poly = SVC(kernel='poly', C=regularization, max_iter=500)\n",
        "  svc_poly.fit(x_train_scaled, y_train)\n",
        "\n",
        "  print(\"Regularization: \", regularization)\n",
        "\n",
        "  svc_poly_train_score = svc_poly.score(x_train_scaled, y_train)\n",
        "  print(\"Train: \", svc_poly_train_score)\n",
        "\n",
        "  svc_poly_test_score = svc_poly.score(x_test_scaled, y_test)\n",
        "  print(\"Test: \", svc_poly_test_score)\n",
        "\n",
        "  svc_poly_train_scores[regularization] = svc_poly_train_score\n",
        "  svc_poly_test_scores[regularization] = svc_poly_test_score\n",
        "\n",
        "  end = time.time()\n",
        "  svc_poly_times[regularization] = end - start\n",
        "\n",
        "  regularization *= 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regularization:  0.001\n",
            "Train:  0.44663104478503285\n",
            "Test:  0.643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regularization:  0.01\n",
            "Train:  0.44666256368061075\n",
            "Test:  0.638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regularization:  0.1\n",
            "Train:  0.44666588145909264\n",
            "Test:  0.634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regularization:  1.0\n",
            "Train:  0.4462378880349296\n",
            "Test:  0.629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regularization:  10.0\n",
            "Train:  0.4461499669051596\n",
            "Test:  0.626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regularization:  100.0\n",
            "Train:  0.44471005104402195\n",
            "Test:  0.621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regularization:  1000.0\n",
            "Train:  0.44489252886052555\n",
            "Test:  0.617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_fNwDIn7Zf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "20ba363e-42a4-4933-8b17-8957df1062bb"
      },
      "source": [
        "plt.plot(list(svc_poly_train_scores.keys()), list(svc_poly_train_scores.values()), label = 'Training score')\n",
        "plt.plot(list(svc_poly_test_scores.keys()), list(svc_poly_test_scores.values()), label = 'Testing score')\n",
        "plt.title(\"Score vs Regularization factor\")\n",
        "plt.xlabel(\"Regularization\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.legend()\n",
        "svc_poly_df = pd.DataFrame(svc_poly_times, index=[\"Time Taken\"])\n",
        "svc_poly_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0.001</th>\n",
              "      <th>0.010</th>\n",
              "      <th>0.100</th>\n",
              "      <th>1.000</th>\n",
              "      <th>10.000</th>\n",
              "      <th>100.000</th>\n",
              "      <th>1000.000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Time Taken</th>\n",
              "      <td>54.276927</td>\n",
              "      <td>54.488689</td>\n",
              "      <td>54.349591</td>\n",
              "      <td>41.340313</td>\n",
              "      <td>27.126349</td>\n",
              "      <td>25.761258</td>\n",
              "      <td>17.666214</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             0.001      0.010      0.100     ...   10.000     100.000    1000.000\n",
              "Time Taken  54.276927  54.488689  54.349591  ...  27.126349  25.761258  17.666214\n",
              "\n",
              "[1 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZhUxb3/8feHQUAFRRQ3UMGIEkAcZcTtqrgTbxQ1alyikGtiTKJkMy7Xm6vx6k18kp9G4xajuCRG3BWjiWu4mrgxRFTWgEjCuBIQBInIwPf3x6kemma2A9MMDJ/X8/RDnzpV1VVzmv52nXO6ShGBmZlZc7Vr7QaYmdn6xYHDzMxyceAwM7NcHDjMzCwXBw4zM8vFgcPMzHJx4DBbiyTNknT4GpRfJGnnFm7TjqneipasN9V9gKTpqf7jWrp+ax0OHNYgSf8m6UVJCyTNk/QXSXu3drvWlKQhkpanD7OFkqZJ+mprt6s5IqJzRMxckzpKg1dE/CPVu2zNW7iKy4HrU/2PrG4lksZK+loLtsvWQPvWboCtmyRtBvwe+CZwH9ABOBBY0sKvU1GmD6ymvBsRPSUJ+AIwRtKLETGtFdrSJEntI6K2tduxGnYCJrVmA9IxVkQsb812tCUecVhDdgWIiHsiYllE/CsinoqINwoZJH1d0pT0rX2ypL1S+ufTN8T5kiZJOraozB2SbpL0hKRPgEMkbS/pQUlzJL0taWR9DZK0j6T3i0+pSDpe0hvp+WBJ1ZI+lvSBpKub6mRkngDmAQNTPe0kXSTpLUlzJd0nqVvRa54p6e9p34+Kv8Gn/l1RlHeIpJoG+jNY0kvp7/SepOsldSjaH5K+LWk6ML0obZf0N1tU9FgsKVKez0l6LrXvn5LultQ17fsNsCPwWCp3gaReqd72Kc/2ksakUeYMSV8vatNl6e9xVzrukyRVNdC/t4Cdi16ro6SvFr1nZkr6RkmZYZImpGP4lqShkq4k+9Jyfarn+pR3f0nj0oh4nKT9i+oZK+lKSX8BFqd2WEuJCD/8WOUBbAbMBe4k+0a+Rcn+k4B3gL0BAbuQfbvcCJgB/CfZKOVQYCGwWyp3B7AAOIDsi8smwHjgv1P+nYGZwFENtOst4Iii7fuBi9Lzl4Az0vPOwL4N1DEEqEnP2wHHAsuBPVPad4CXgZ5AR+BXwD1pXz9gEfBvqb0/B5YChxf174r6XittzyrKOwjYl2zk3wuYAny3KG8ATwPdgI2L0napp093F7VxF+CI1PbuwPPAL+prQ9ruleptn7afB24EOgGVwBzg0LTvMuBT4GigAvgJ8HIj76PS1/p34HPpPXMw2Yf6Xmnf4PTeOCIdlx5A37RvLPC1onq6AR8BZ6S/36lpe8ui/P8A+qf9G7X2/6m29Gj1Bvix7j6Az6cPwhqgFhgDbJP2PQl8p54yBwLvA+2K0u4BLkvP7wDuKtq3D/CPkjouBm5voE1XAKPS8y7AJ8BOaft54MfAVk30awhZoJhPduptWckH9hTgsKLt7ciCQ3uyAHdP0b5NgM9YjcBRT7u+CzxctB2FD+yStF1K0i4kC74bN1DvccBrDbWBosAB7JD+Hl2K9v8EuCM9vwx4pmhfP+BfjfytG+xv2v9I4X1EFqCvaSDfWFYOHGcAr5bkeQkYUZT/8tb+P9RWHz5VZQ2KiCkRMSIiegIDgO2BX6TdO5B9+y+1PTA7Vj6f/Heyb48Fs4ue7wRsn07XzJc0n2y0sk0DzfodcIKkjsAJwF8j4u9p31lkp9implMXX2yke+9GRFeykdV1ZCOj4jY9XNSeKWQfptsU+lfIGBGLyUZmuUnaVdLv0+m3j4H/BbYqyTa7nqLFdXyBbIR0XET8K6VtI2m0pHdSvb+tp96GbA/Mi4iFRWmlx+/9oueLgU6F01xNkfQFSS+n02DzyUYuhbY19J5qqJ1/L0lr7H1mLciBw5olIqaSfZsekJJmk51yKPUusIOk4vfWjmSnteqqK3o+G3g7IroWPbpExNENtGMy2QfEF4DTyAJJYd/0iDgV2Bq4CnhA0qZN9GsJ2Tf23bXidtHZwBdK2tQpIt4B3iM7hQWApI2BLYuq/IRsFFKwbSMvfxMwFegTEZuRBUyVNrGhwpJ2IzuVeHJEFH9I/m8qt3uq9ysl9TY2Jfa7QDdJXYrSSo/faknB/kGy03vbpMD9RFHbGnpPwaptfpcswBdr7H1mLciBw+olqa+kH0jqmbZ3IDuP/HLKcitwvqRByuwiaSfgFbJvoRdI2kjSEOAYYHQDL/UqsFDShZI2llQhaYAav+33d2Tfsg8iu8ZRaPNXJHVPo535KbnJO2ki4jPg/5GdhgK4Gbgy9QdJ3SUNS/seAI5JF2Y7kJ26Kf5QngAcLambpG3JTj81pAvwMbBIUl+yO9iaRdldb48Cl0TEn+updxGwQFIP4Icl+z+ggYvFKQC9CPxEUidJA8lGcr9tbtsa0YHsusscoDaNlo4s2n8b8FVJhym7QaFH+rvU1+YngF0lnSapvaQvk502+30LtNOa4MBhDVlIdv3hFWV3P70MTAR+ABAR9wNXkn2ILyQ7V90tfQgfQzYi+CfZRdYz04hlFZHdivtFsouwb6cytwKbN9K2e8gurD4XEf8sSh8KTJK0CLgWOKVw+qYZRgE7SjomlR0DPCVpYer7Pqm9k4DzyALhe2Qf0B+y4jbl3wCvk53bfwq4t5HXPJ9s1LQQ+HUTeUvtBewGXFN8d1Xa9+O0fwHwOPBQSdmfAP+VTsWdX0/dp5Jd93gXeBi4NCKeydG2eqXTXyPJbu/+iKzvY4r2vwp8Fbgmtf3/WDGquBY4UdJHkq6LiLlk75sfkJ0qvAD4Ysn7wcpEER7Nma0uSZ3JRjd9IuLt1m6P2drgEYdZTpKOkbRJun7yc+BNshGG2QbBgcMsv2Fkp3HeBfqQnRLz0N02GD5VZWZmuXjEYWZmuZR1kkNJQ8nuhqgAbo2In9aT52SyWxoDeD0iTkvpy8jOHUP2y+JjU3pvsjtatiT7tewZ6U6eBm211VbRq1evluiSmdkGY/z48f+MiO6l6WU7VaVsIrq/kc07UwOMA05NP+Aq5OlDdmveoRHxkaStI+LDtG9RRHSup977gIciYrSkm8mCzU2NtaWqqiqqq6tbrG9mZhsCSeMjYpVJLMt5qmowMCMiZqYRwWiyi4rFvg7cEBEfARSCRkMkiWxqiAdS0p1k8/CYmdlaUs7A0YOV54qpYeV5ZCCbV2hXZQsEvZxObRV0UjZF9stFU0FsCcyPFesS1FcnAJLOTuWr58yZs+a9MTMzoPUXcmpPdjvjELL5f56XtHtEzCeb8fQdZctkPifpTbJfkzZLRNwC3ALZqaoWb7mZ2QaqnCOOd8hmuyzoyaoTpdUAYyJiafrV7d/IAglpQjkiWyZzLLAn2dQCXYtm4qyvTjMzK6NyBo5xQB9JvdNkcKdQNC9N8gjZaANJW5GdupopaYs0k2Yh/QBgcvqR1Z+AE1P54WQTvZmZ2VpStsCRrkOcS7bgzxTgvoiYJOlyrVhK9ElgrqTJZAHhh2nyss8D1ZJeT+k/Lbob60Lg+5JmkF3zuK1cfTAzs1VtEL8c9+24Zmb5tcbtuOu/1++FcR7QmJkVc+BozMQH4LXftHYrzMzWKQ4cZmaWiwOHmZnl4sBhZma5OHCYmVkuDhyNEsTy1m6Emdk6xYGjMWoHG8DvXMzM8nDgaIzkwGFmVsKBozFqR7YwoZmZFThwNKZde6hd0tqtMDNbpzhwNKZjF/hsUWu3wsxsneLA0ZiOm8GSha3dCjOzdYoDR2MKI47ly1q7JWZm6wwHjsZ07JL9u+Tj1m2Hmdk6xIGjMdv0z/79w4Ww3D8ENDODMgcOSUMlTZM0Q9JFDeQ5WdJkSZMk/S6lVUp6KaW9IenLRfnvkPS2pAnpUVm2DnzuEDjkv+CNe+GpS/ybDjMzoH25KpZUAdwAHAHUAOMkjSlaAhZJfYCLgQMi4iNJW6ddi4EzI2K6pO2B8ZKejIj5af8PI+KBcrV9JQedD4v/CS/fCJ99ArscDtsOgK69oJ0HbGa24Slb4AAGAzMiYiaApNHAMGByUZ6vAzdExEcAEfFh+vdvhQwR8a6kD4HuwHzWNgmO+gksXQx/vQv+emeW3qEzbN0vCyLb9Idtdodt+q24LmJm1kaVM3D0AGYXbdcA+5Tk2RVA0l+ACuCyiPhjcQZJg4EOwFtFyVdK+m/gWeCiiFjlV3qSzgbOBthxxx3XrCft2sGxv4ShV8GHU+CDN+GDSfD+RHjzQagetSLvFr1gmwHZY9v0b9edPDoxszajnIGjua/fBxgC9ASel7R74ZSUpO2A3wDDI+qmqb0YeJ8smNwCXAhcXlpxRNyS9lNVVdUyFyc6bAI9B2WPFS8EC2avCCSFoDL1ceqmK+nQOY1K+qeAsjts/XmPTsxsvVTOwPEOsEPRds+UVqwGeCUilgJvS/obWSAZJ2kz4HHgkoh4uVAgIt5LT5dIuh04v1wdaBYJuu6YPXb7wor0zz6BD6dmgeT9iVkwWWV00jsLJtvunkYp/T06MbN1XjkDxzigj6TeZAHjFOC0kjyPAKcCt0vaiuzU1UxJHYCHgbtKL4JL2i4i3pMk4DhgYhn7sPo6bNrw6KQQSApBZaXRSZfsWkn3vrDRJtCuIj3ar3ioXdF2xcr/qqL+9FXKtV+57sbKtaso2l/YbpcFTTPb4JQtcEREraRzgSfJrl+MiohJki4HqiNiTNp3pKTJwDKyu6XmSvoKcBCwpaQRqcoRETEBuFtSd0DABOCccvWhxRWPTvoevSL9s0/StZOJK4LK1Mdh2VJYXrviEevYL9jrAlJDQaeegNNkEKxooN7GAln7bJS2UrnS160vuJaUa7BsfeXqa6tHirZhUGwAv02oqqqK6urq1m7GmovIViSsCybLVvwby0rSl5UEnQbKFQJSs8qV5Ill9dfXnDZF6WvVV2995Uras06t0KgWCIL1lWtq/+oG1+YE+6aCa1MjU49K12eSxkdEVWl6a18ctzykFf9p6djarVk3RDQSkBoLZLXZbAArlasvCDZRrsHXXI0gWNhfu6Tx9qxSb0k969IaMmpqJFiu4Lq6I94yn/ZtI6d4HThs/SZBRfvsYZnlyxsOWKs7Csw9Mm2poLw8nbL9VyPBsxn1rktWd4TZaBBsJEgefCF02bZFu+D/bWZtTbt2QDuo2Ki1W7LuaNYosb6g01i51jpdvDwblTYVPAv79zu3xf+cDhxm1va1awftOpD9/MvWlG8DMTOzXBw4zMwsFwcOMzPLxYHDzMxyceAwM7NcHDjMzCwXBw4zM8vFgcPMzHJx4DAzs1wcOMzMLBcHDjMzy8WBw8zMcilr4JA0VNI0STMkXdRAnpMlTZY0SdLvitKHS5qeHsOL0gdJejPVeV1aQtbMzNaSss2OK6kCuAE4AqgBxkkaExGTi/L0AS4GDoiIjyRtndK7AZcCVWSr0oxPZT8CbgK+DrwCPAEMBf5Qrn6YmdnKyjniGAzMiIiZEfEZMBoYVpLn68ANKSAQER+m9KOApyNiXtr3NDBU0nbAZhHxcmRr3t4FHFfGPpiZWYlyBo4ewOyi7ZqUVmxXYFdJf5H0sqShTZTtkZ43VicAks6WVC2pes6cOWvQDTMzK9baF8fbA32AIcCpwK8ldW2JiiPiloioioiq7t27t0SVZmZGeQPHO8AORds9U1qxGmBMRCyNiLeBv5EFkobKvpOeN1anmZmVUTkDxzigj6TekjoApwBjSvI8QjbaQNJWZKeuZgJPAkdK2kLSFsCRwJMR8R7wsaR9091UZwKPlrEPZmZWomx3VUVEraRzyYJABTAqIiZJuhyojogxrAgQk4FlwA8jYi6ApP8hCz4Al0fEvPT8W8AdwMZkd1P5jiozs7VI2c1JbVtVVVVUV1e3djPMzNYrksZHRFVpemtfHDczs/WMA4eZmeXiwGFmZrk4cJiZWS4OHGZmlosDh5mZ5eLAYWZmuThwmJlZLg4cZmaWiwOHmZnl4sBhZma5OHCYmVkuDhxmZpaLA4eZmeXiwGFmZrk4cJiZWS5lDRyShkqaJmmGpIvq2T9C0hxJE9Ljayn9kKK0CZI+lXRc2neHpLeL9lWWsw9mZraysi0dK6kCuAE4AqgBxkkaExGTS7LeGxHnFidExJ+AylRPN2AG8FRRlh9GxAPlaruZmTWsnCOOwcCMiJgZEZ8Bo4Fhq1HPicAfImJxi7bOzMxWSzkDRw9gdtF2TUor9SVJb0h6QNIO9ew/BbinJO3KVOYaSR3re3FJZ0uqllQ9Z86c1eqAmZmtqrUvjj8G9IqIgcDTwJ3FOyVtB+wOPFmUfDHQF9gb6AZcWF/FEXFLRFRFRFX37t3L0XYzsw1SOQPHO0DxCKJnSqsTEXMjYknavBUYVFLHycDDEbG0qMx7kVkC3E52SszMzNaScgaOcUAfSb0ldSA75TSmOEMaURQcC0wpqeNUSk5TFcpIEnAcMLGF221mZo0o211VEVEr6Vyy00wVwKiImCTpcqA6IsYAIyUdC9QC84ARhfKSepGNWP6vpOq7JXUHBEwAzilXH8zMbFWKiNZuQ9lVVVVFdXV1azfDzGy9Iml8RFSVprf2xXEzM1vPOHCYmVkuDhxmZpaLA4eZmeXiwGFmZrk4cJiZWS4OHGZmlosDh5mZ5eLAYWZmuZRtyhEzM4ClS5dSU1PDp59+2tpNsQZ06tSJnj17stFGGzUrvwOHmZVVTU0NXbp0oVevXmRzk9q6JCKYO3cuNTU19O7du1llfKrKzMrq008/Zcstt3TQWEdJYsstt8w1InTgMLOyc9BYt+U9Pg4cZtamzZ07l8rKSiorK9l2223p0aNH3fZnn33WaNnq6mpGjhzZ5Gvsv//+LdXc9UKzr3FI2hjYMSKmlbE9ZmYtasstt2TChAkAXHbZZXTu3Jnzzz+/bn9tbS3t29f/UVhVVUVV1Sqziq/ixRdfbJnGtrDG+rYmmjXikHQM2aJJf0zblZLGNF7KzGzdNGLECM455xz22WcfLrjgAl599VX2228/9txzT/bff3+mTcu+H48dO5YvfvGLQBZ0/uM//oMhQ4aw8847c91119XV17lz57r8Q4YM4cQTT6Rv376cfvrpFNY8euKJJ+jbty+DBg1i5MiRdfUWmzRpEoMHD6ayspKBAwcyffp0AO666y4GDhzIHnvswRlnnAHArFmzOPTQQxk4cCCHHXYY//jHP+rt21tvvcXQoUMZNGgQBx54IFOnTl3jv19zQ9FlZGt7jwWIiAmSmrz8LmkocC3ZCoC3RsRPS/aPAH7GirXIr4+IW9O+ZcCbKf0fEXFsSu8NjAa2BMYDZ0RE4+NNM1sn/PixSUx+9+MWrbPf9ptx6TH9c5erqanhxRdfpKKigo8//pgXXniB9u3b88wzz/Cf//mfPPjgg6uUmTp1Kn/6059YuHAhu+22G9/85jdXuYX1tddeY9KkSWy//fYccMAB/OUvf6GqqopvfOMbPP/88/Tu3ZtTTz213jbdfPPNfOc73+H000/ns88+Y9myZUyaNIkrrriCF198ka222op58+YBcN555zF8+HCGDx/OqFGjGDlyJI888sgqfTvssMO4+eab6dOnD6+88grf+ta3eO6553L/vYo1N3AsjYgFJRdQGl06UFIFcANwBFADjJM0JiIml2S9NyLOraeKf0VEZT3pVwHXRMRoSTcDZwE3NbMfZmYAnHTSSVRUVACwYMEChg8fzvTp05HE0qVL6y3z7//+73Ts2JGOHTuy9dZb88EHH9CzZ8+V8gwePLgurbKyklmzZtG5c2d23nnnuttdTz31VG655ZZV6t9vv/248sorqamp4YQTTqBPnz4899xznHTSSWy11VYAdOvWDYCXXnqJhx56CIAzzjiDCy64YJW+LVq0iBdffJGTTjqpbt+SJUtW6+9VrLmBY5Kk04AKSX2AkUBTJ/UGAzMiYiaApNHAMKA0cDSbssh1KHBaSrqTbDTkwGG2HlidkUG5bLrppnXPf/SjH3HIIYfw8MMPM2vWLIYMGVJvmY4dO9Y9r6iooLa2drXyNOS0005jn3324fHHH+foo4/mV7/6VbPLFiv0bfny5XTt2rXuGk9Lae5dVecB/YElwO+ABcB3myjTA5hdtF2T0kp9SdIbkh6QtENReidJ1ZJelnRcStsSmB8RhSPRUJ1IOjuVr54zZ04TTTWzDdmCBQvo0SP7KLnjjjtavP7ddtuNmTNnMmvWLADuvffeevPNnDmTnXfemZEjRzJs2DDeeOMNDj30UO6//37mzp0LUHeqav/992f06NEA3H333Rx44IGr1LfZZpvRu3dv7r//fiD7sd/rr7++xv1pMnCkU06PR8QlEbF3evxXRLTE/AGPAb0iYiDwNNkIomCntEj6acAvJH0uT8URcUtEVEVEVffu3VugqWbWVl1wwQVcfPHF7LnnnrlGCM218cYbc+ONN9ZdpO7SpQubb775Kvnuu+8+BgwYQGVlJRMnTuTMM8+kf//+XHLJJRx88MHssccefP/73wfgl7/8JbfffjsDBw7kN7/5Dddee229r3333Xdz2223sccee9C/f38effTRNe6PClf8G80kPQucEBELml2xtB9wWUQclbYvBoiInzSQvwKYFxGr/DUl3QH8HngQmANsGxG1pa/RkKqqqqiurm5u082sBU2ZMoXPf/7zrd2MVrdo0SI6d+5MRPDtb3+bPn368L3vfa+1m1WnvuMkaXz6Ar+S5p6qWgS8Kek2SdcVHk2UGQf0kdRbUgfgFGClW3glbVe0eSwwJaVvIaljer4VcAAwObIo9yfgxFRmOLDm4dPMrMx+/etfU1lZSf/+/VmwYAHf+MY3WrtJq625F8cfSo9mSyOCc4EnyW7HHRURkyRdDlRHxBhgpKRjgVpgHjAiFf888CtJy8mC20+L7sa6EBgt6QrgNeC2PO0yM2sN3/ve99apEcaaaFbgiIg706hh15Q0LSLqv19t5XJPAE+UpP130fOLgYvrKfcisHsDdc4ku2PLzMxaQbMCh6QhZBeuZwECdpA0PCKeL1/TzMxsXdTcU1X/DziyME+VpF2Be4BB5WqYmZmtm5p7cXyj4skNI+JvQPOWijIzszaluSOOakm3Ar9N26cDvr/VzNZ5c+fO5bDDDgPg/fffp6KigsJvu1599VU6dOjQaPmxY8fSoUOHuqnTb775ZjbZZBPOPPPM8jZ8HdbcwPFN4NtkU40AvADcWJYWmZm1oKamVW/K2LFj6dy5c13gOOecc8rSzjUVEUQE7dqVf5ml5r5Ce+DaiDghIk4AriO7xdbMbL0zfvx4Dj74YAYNGsRRRx3Fe++9B8B1111Hv379GDhwIKeccgqzZs3i5ptv5pprrqGyspIXXniByy67jJ///OcADBkyhAsvvJDBgwez66678sILLwCwePFiTj75ZPr168fxxx/PPvvsQ30/Qr7ooovqXq8QzD744AOOP/549thjD/bYY4+6tT6uvvpqBgwYwIABA/jFL34BZFOr77bbbpx55pkMGDCA2bNn87Of/Yy9996bgQMHcumll5bl79fcEcezwOFkPwQE2Bh4Ctiwlr0yszXzh4vg/TebzpfHtrvDF37adL4kIjjvvPN49NFH6d69O/feey+XXHIJo0aN4qc//Slvv/02HTt2ZP78+XTt2pVzzjlnpVHKs88+u1J9tbW1vPrqqzzxxBP8+Mc/5plnnuHGG29kiy22YPLkyUycOJHKylUn+p47dy4PP/wwU6dORRLz588HYOTIkRx88ME8/PDDLFu2jEWLFjF+/Hhuv/12XnnlFSKCffbZh4MPPpgtttiC6dOnc+edd7Lvvvvy1FNPMX36dF599VUigmOPPZbnn3+egw46aA3+wKtq7oijU0QUggbp+SYt2hIzs7VgyZIlTJw4kSOOOILKykquuOIKampqABg4cCCnn346v/3tb5u9ct4JJ5wAwKBBg+omMfzzn//MKaecAsCAAQMYOHDgKuU233xzOnXqxFlnncVDDz3EJptkH6nPPfcc3/zmN4Fsdt3NN9+cP//5zxx//PFsuummdO7cmRNOOKFudLPTTjux7777AvDUU0/x1FNPseeee7LXXnsxderUusWgWlJzRxyfSNorIv4KIKkK+FeLt8bM2rYcI4NyiQj69+/PSy+9tMq+xx9/nOeff57HHnuMK6+8kjffbHp0VJhGPe8U6u3bt+fVV1/l2Wef5YEHHuD6669frQWWiqeHjwguvvjisk9n0twRx3eB+yW9IOkFshX46lt8ycxsndaxY0fmzJlTFziWLl3KpEmTWL58ObNnz+aQQw7hqquuYsGCBSxatIguXbqwcOHCXK9xwAEHcN999wEwefLkegPQokWLWLBgAUcffTTXXHNN3XTnhx12GDfdlC0xtGzZMhYsWMCBBx7II488wuLFi/nkk094+OGH651G/aijjmLUqFEsWpSdIHrnnXf48MMPc7W9ORodcUjaG5gdEeMk9QW+AZxAtvb42y3eGjOzMmvXrh0PPPAAI0eOZMGCBdTW1vLd736XXXfdla985SssWLCAiGDkyJF07dqVY445hhNPPJFHH32UX/7yl816jW9961sMHz6cfv360bdvX/r377/KNOoLFy5k2LBhfPrpp0QEV199NQDXXnstZ599NrfddhsVFRXcdNNN7LfffowYMYLBg7PZlr72ta+x55571p0aKzjyyCOZMmUK++23H5Cthf7b3/6Wrbfeeg3/aitrdFp1SX8FDo+IeZIOIhtpnAdUAp+PiBMbLLwO8bTqZq1nQ5xWfdmyZSxdupROnTrx1ltvcfjhhzNt2rQmfzPSmvJMq97UNY6KiJiXnn8ZuCUiHgQelNSyaxGambURixcv5pBDDmHp0qVEBDfeeOM6HTTyajJwSGqflmo9DDg7R1kzsw1Sly5d6v3dRlvR1If/PcD/Sfon2V1ULwBI2oVs3XEzM9vANBo4IuLKtGzsdsBTseKCSDuyax1mZk2KCCS1djOsAc1ZQrxYk7fjRsTLEfFwRHxSlPa3wm86GiNpqKRpkmZIuqie/SMkzUcl/dMAABCWSURBVJE0IT2+ltIrJb0kaZKkNyR9uajMHZLeLiqz6k8yzWyd0alTJ+bOnZv7w8nWjohg7ty5dOrUqdllynadQlIFcANwBFADjJM0pmgJ2IJ7I6L0NyGLgTMjYrqk7YHxkp6MiPlp/w8j4oFytd3MWk7Pnj2pqalhzpw5rd0Ua0CnTp3o2bNns/OX8wL3YGBGWuoVSaOBYUBp4FhFWu+j8PxdSR8C3YH5DZcys3XRRhttRO/evVu7GdaCyjn/bg9gdtF2TUor9aV0OuoBSTuU7pQ0GOgAvFWUfGUqc42kjvW9uKSzJVVLqvY3HTOzllP+idsb9xjQKyIGAk+TrWteR9J2wG+Ar0bE8pR8MdAX2BvoBlxYX8URcUtEVEVEVWHRFjMzW3PlDBzvAMUjiJ4prU5EzI2IJWnzVorWMJe0GfA4cElEvFxU5r3ILAFuJzslZmZma0k5A8c4oI+k3pI6AKcAY4ozpBFFwbHAlJTeAXgYuKv0InihjLJ7+44DJpatB2ZmtoqyXRyPiFpJ5wJPkq0WOCoiJkm6HKiOiDHASEnHArXAPGBEKn4ycBCwpaRC2oiImADcLak7IGACsG6u42hm1kY1OslhW+FJDs3M8mtoksPWvjhuZmbrGQcOMzPLxYHDzMxyceAwM7NcHDjMzCwXBw4zM8vFgcPMzHJx4DAzs1wcOMzMLBcHDjMzy8WBw8zMcnHgMDOzXBw4zMwsFwcOMzPLxYHDzMxyceAwM7Ncyho4JA2VNE3SDEkX1bN/hKQ5kiakx9eK9g2XND09hhelD5L0ZqrzurSErJmZrSVlCxySKoAbgC8A/YBTJfWrJ+u9EVGZHremst2AS4F9gMHApZK2SPlvAr4O9EmPoeXqg5mZraqcI47BwIyImBkRnwGjgWHNLHsU8HREzIuIj4CngaGStgM2i4iXI1vz9i7guHI03szM6lfOwNEDmF20XZPSSn1J0huSHpC0QxNle6TnTdWJpLMlVUuqnjNnzur2wczMSrT2xfHHgF4RMZBsVHFnS1UcEbdERFVEVHXv3r2lqjUz2+CVM3C8A+xQtN0zpdWJiLkRsSRt3goMaqLsO+l5g3WamVl5lTNwjAP6SOotqQNwCjCmOEO6ZlFwLDAlPX8SOFLSFumi+JHAkxHxHvCxpH3T3VRnAo+WsQ9mZlaifbkqjohaSeeSBYEKYFRETJJ0OVAdEWOAkZKOBWqBecCIVHaepP8hCz4Al0fEvPT8W8AdwMbAH9LDzMzWEmU3J7VtVVVVUV1d3drNMDNbr0gaHxFVpemtfXHczMzWMw4cZmaWiwOHmZnl4sBhZma5OHCYmVkuDhxmZpaLA4eZmeXiwGFmZrk4cJiZWS4OHGZmlosDh5mZ5eLAYWZmuThwmJlZLg4cZmaWiwOHmZnl4sBhZma5lDVwSBoqaZqkGZIuaiTflySFpKq0fbqkCUWP5ZIq076xqc7Cvq3L2QczM1tZ2ZaOlVQB3AAcAdQA4ySNiYjJJfm6AN8BXimkRcTdwN1p/+7AIxExoajY6RHhJf3MzFpBOUccg4EZETEzIj4DRgPD6sn3P8BVwKcN1HNqKmtmZuuAcgaOHsDsou2alFZH0l7ADhHxeCP1fBm4pyTt9nSa6keSVF8hSWdLqpZUPWfOnNVovpmZ1afVLo5LagdcDfygkTz7AIsjYmJR8ukRsTtwYHqcUV/ZiLglIqoioqp79+4t2HIzsw1bOQPHO8AORds9U1pBF2AAMFbSLGBfYEzhAnlyCiWjjYh4J/27EPgd2SkxMzNbS8oZOMYBfST1ltSBLAiMKeyMiAURsVVE9IqIXsDLwLGFi95pRHIyRdc3JLWXtFV6vhHwRaB4NGJmZmVWtruqIqJW0rnAk0AFMCoiJkm6HKiOiDGN18BBwOyImFmU1hF4MgWNCuAZ4NdlaL6ZmTVAEdHabSi7qqqqqK723btmZnlIGh8RVaXp/uW4mZnl4sBhZma5OHCYmVkuDhxmZpaLA4eZmeXiwGFmZrk4cJiZWS4OHGZmlosDh5mZ5eLAYWZmuThwmJlZLg4cZmaWiwOHmZnl4sBhZma5OHCYmVkuZQ0ckoZKmiZphqSLGsn3JUlRWDZWUi9J/5I0IT1uLso7SNKbqc7rJKmcfTAzs5WVbQVASRXADcARQA0wTtKYiJhckq8L8B3glZIq3oqIynqqvgn4esr/BDAU+EMLN9/MzBpQzhHHYGBGRMyMiM/I1g4fVk++/wGuAj5tqkJJ2wGbRcTLkS1deBdwXAu22czMmlDOwNEDmF20XZPS6kjaC9ghIh6vp3xvSa9J+j9JBxbVWdNYnWZmVl5lO1XVFEntgKuBEfXsfg/YMSLmShoEPCKpf876zwbOBthxxx3XsLVmZlZQzhHHO8AORds9U1pBF2AAMFbSLGBfYIykqohYEhFzASJiPPAWsGsq37OROutExC0RURURVd27d2+hLpmZWTlHHOOAPpJ6k324nwKcVtgZEQuArQrbksYC50dEtaTuwLyIWCZpZ6APMDMi5kn6WNK+ZBfHzwR+Wa4O3P3K3xn39jyGDtiWju0r6LhRO7p03IhNO1bQuVN7Ondsz8YbVeAbu8xsQ1K2wBERtZLOBZ4EKoBRETFJ0uVAdUSMaaT4QcDlkpYCy4FzImJe2vct4A5gY7K7qcp2R9WLM+by+Jvv8ciEdxvM006waccsiHTu2J5NO7anS6f2bNqhfV1wKaR3TgGndF/njtm2g5DZhie7z6e+9Aby56ynop1a/HNFDb1YW1JVVRXV1dWrVXb2vMUsWlLLktrlLP6slk+WLGPRkqUsWrKMT5bUsujTWhYtyR6fLFnxfNGnK28vb8afuZ2oCyqbdKg/iDT4Jmuo0np25H3jNZy/oZds/n+EvG+/VmljzrobKtESHwS5+9kC75eGklvjWDRWf/3v9fJ+KOd/b6x9z3z/YHbZuvNqlZU0PiKqStNb7eL4+mKHbpuscR0RwadLl7NwyVI+SQFnYUlgWSnwfFrL4s+WNVxhA18e6ktu6JtGQ98/Gvpi0nD+fPXXt0MN5M7flobyN7/+hr+YrUNtbLDufN8qy9uWhtLX/P2SJZexjS10rOsr0Bpt6bZphwZedfU5cKwFkti4QwUbd6jIbgkwM1uPea4qMzPLxYHDzMxyceAwM7NcHDjMzCwXBw4zM8vFgcPMzHJx4DAzs1wcOMzMLJcNYsoRSXOAv69m8a2Af7Zgc9YH7vOGwX1u+9a0vztFxCrTi28QgWNNSKqub66Wtsx93jC4z21fufrrU1VmZpaLA4eZmeXiwNG0W1q7Aa3Afd4wuM9tX1n662scZmaWi0ccZmaWiwOHmZnl4sDRCElDJU2TNEPSRa3dnpYgaQdJf5I0WdIkSd9J6d0kPS1pevp3i5QuSdelv8EbkvZq3R6sPkkVkl6T9Pu03VvSK6lv90rqkNI7pu0ZaX+v1mz36pLUVdIDkqZKmiJpv7Z+nCV9L72vJ0q6R1KntnacJY2S9KGkiUVpuY+rpOEp/3RJw/O0wYGjAZIqgBuALwD9gFMl9WvdVrWIWuAHEdEP2Bf4durXRcCzEdEHeDZtQ9b/PulxNnDT2m9yi/kOMKVo+yrgmojYBfgIOCulnwV8lNKvSfnWR9cCf4yIvsAeZH1vs8dZUg9gJFAVEQOACuAU2t5xvgMYWpKW67hK6gZcCuwDDAYuLQSbZokIP+p5APsBTxZtXwxc3NrtKkM/HwWOAKYB26W07YBp6fmvgFOL8tflW58eQM/0H+pQ4PdkyzP/E2hferyBJ4H90vP2KZ9auw85+7s58HZpu9vycQZ6ALOBbum4/R44qi0eZ6AXMHF1jytwKvCrovSV8jX18IijYYU3YUFNSmsz0tB8T+AVYJuIeC/teh/YJj1vK3+HXwAXAMvT9pbA/IioTdvF/arrc9q/IOVfn/QG5gC3p9Nzt0ralDZ8nCPiHeDnwD+A98iO23ja9nEuyHtc1+h4O3BsoCR1Bh4EvhsRHxfvi+wrSJu5T1vSF4EPI2J8a7dlLWoP7AXcFBF7Ap+w4vQF0CaP8xbAMLKguT2wKaue0mnz1sZxdeBo2DvADkXbPVPaek/SRmRB4+6IeCglfyBpu7R/O+DDlN4W/g4HAMdKmgWMJjtddS3QVVL7lKe4X3V9Tvs3B+auzQa3gBqgJiJeSdsPkAWStnycDwfejog5EbEUeIjs2Lfl41yQ97iu0fF24GjYOKBPuiOjA9lFtjGt3KY1JknAbcCUiLi6aNcYoHBnxXCyax+F9DPT3Rn7AguKhsTrhYi4OCJ6RkQvsuP4XEScDvwJODFlK+1z4W9xYsq/Xn0zj4j3gdmSdktJhwGTacPHmewU1b6SNknv80Kf2+xxLpL3uD4JHClpizRSOzKlNU9rX+RZlx/A0cDfgLeAS1q7PS3Up38jG8a+AUxIj6PJzu0+C0wHngG6pfwiu7vsLeBNsjtWWr0fa9D/IcDv0/OdgVeBGcD9QMeU3iltz0j7d27tdq9mXyuB6nSsHwG2aOvHGfgxMBWYCPwG6NjWjjNwD9k1nKVkI8uzVue4Av+R+j4D+GqeNnjKETMzy8WnqszMLBcHDjMzy8WBw8zMcnHgMDOzXBw4zMwsFwcO2+BIWiZpQppB9TFJXcvwGmMlVeUsc7mkw1fjtY4rnoBzdesxay4HDtsQ/SsiKiObQXUe8O3WbpCkioj474h4ZjWKH0c2gzMAa1CPWbM4cNiG7iXS5G6SPifpj5LGS3pBUt+i9JclvSnpCkmLUvoQpbU90vb1kkaUvoCkmyRVp3UiflyUPkvSVZL+Cpwk6Q5JJ0qqSiOiCek1I+X/uqRxkl6X9GD6hfT+wLHAz1L+zxXqSWUOS5McvpnWcehY9No/lvTXtK9vmf6+1gY5cNgGK625chgrppK5BTgvIgYB5wM3pvRrgWsjYneyX+rmdUlEVAEDgYMlDSzaNzci9oqI0YWEiKhOI6JK4I9kM74CPBQRe0dEYW2NsyLixdT+H6YybxX1rxPZ2g1fTm1vD3yz6LX/GRF7ka3RcP5q9Ms2UA4ctiHaWNIEVkw//XSaLXh/4P6071dk6xZAtobD/en571bj9U5Oo4rXgP4UnVYC7m2okKQvk01MWJjVdkAaCb0JnJ7qasxuZJP+/S1t3wkcVLS/MMHleLL1HcyapX3TWczanH9FRKWkTcgmdvs22Tfz+elbfnPVsvKXr06lGST1Jvs2v3dEfCTpjpJ8n9RXsaQBwGXAQRGxLCXfARwXEa+nU2JDcrS1PkvSv8vwZ4Hl4BGHbbAiYjHZUqM/ABYDb0s6CerWat4jZX0Z+FJ6fkpRFX8H+ilbu7or2WmvUpuRBYcFkrYhW8qzUamue4AzI2JO0a4uwHtpWvzTi9IXpn2lpgG9JO2Sts8A/q+p1zdrigOHbdAi4jWy2WNPJfswPkvS68AkskWBAL4LfF/SG8AuZCvFERGzgfvIZmK9j+xUVGn9r6f0qWSnuf7SjGYNA3YCfl24SJ7Sf0S2WuNfUn0Fo4Efpovgnyt67U+Br5KdfnuTbPXDm5vx+maN8uy4Zk1Ip7T+FREh6RSytZmHNVXOrK3yeU2zpg0Crk+LA80nW8fAbIPlEYeZmeXiaxxmZpaLA4eZmeXiwGFmZrk4cJiZWS4OHGZmlsv/Byfwv/S3JmqdAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiI0FGt47gho",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "78c6994d-088f-4808-b6fa-a1bd653b5aaa"
      },
      "source": [
        "best = max(svc_poly_test_scores, key=svc_poly_test_scores.get)\n",
        "svc_poly = SVC(kernel='poly', C=best, max_iter=500)\n",
        "svc_poly.fit(x_train_scaled, y_train)\n",
        "\n",
        "y_pred = svc_poly.predict(x_test_scaled)\n",
        "print(\"Precision, Recall, Fscore\")\n",
        "print(precision_recall_fscore_support(y_test, y_pred, average=\"weighted\"))\n",
        "print(\"Best regularization: \" + str(best))\n",
        "cm_poly = confusion_matrix(y_test, y_pred)\n",
        "df_poly = pd.DataFrame(cm_poly, columns = [\"Predicted Negative\", \"Predicted Positive\"])\n",
        "df_poly.index = cm_index\n",
        "df_poly"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision, Recall, Fscore\n",
            "(0.413449, 0.643, 0.5032854534388314, None)\n",
            "Best regularization: 0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted Negative</th>\n",
              "      <th>Predicted Positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Actual Negative</th>\n",
              "      <td>0</td>\n",
              "      <td>357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual Positive</th>\n",
              "      <td>0</td>\n",
              "      <td>643</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Predicted Negative  Predicted Positive\n",
              "Actual Negative                   0                 357\n",
              "Actual Positive                   0                 643"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQ8wepM96zdM"
      },
      "source": [
        "RBF SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ-SWOI36y_E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "683c9cd7-ac0d-4f38-9439-a92259c4c155"
      },
      "source": [
        "regularization = 0.001 # L2 regularization\n",
        "\n",
        "svc_rbf_train_scores = {}\n",
        "svc_rbf_test_scores = {}\n",
        "svc_rbf_times = {}\n",
        "\n",
        "while regularization <= 1000:\n",
        "  start = time.time()\n",
        "  svc_rbf = SVC(kernel='rbf', C=regularization, max_iter=500)\n",
        "  svc_rbf.fit(x_train_scaled, y_train)\n",
        "\n",
        "  print(\"Regularization: \", regularization)\n",
        "\n",
        "  svc_rbf_train_score = svc_rbf.score(x_train_scaled, y_train)\n",
        "  print(\"Train: \", svc_rbf_train_score)\n",
        "\n",
        "  svc_rbf_test_score = svc_rbf.score(x_test_scaled, y_test)\n",
        "  print(\"Test: \", svc_rbf_test_score)\n",
        "\n",
        "  svc_rbf_train_scores[regularization] = svc_rbf_train_score\n",
        "  svc_rbf_test_scores[regularization] = svc_rbf_test_score\n",
        "\n",
        "  end = time.time()\n",
        "  svc_rbf_times[regularization] = end - start\n",
        "\n",
        "  regularization *= 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regularization:  0.001\n",
            "Train:  0.49750088335852083\n",
            "Test:  0.64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regularization:  0.01\n",
            "Train:  0.49750088335852083\n",
            "Test:  0.64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regularization:  0.1\n",
            "Train:  0.4684454383034208\n",
            "Test:  0.642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regularization:  1.0\n",
            "Train:  0.5598684832609782\n",
            "Test:  0.508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regularization:  10.0\n",
            "Train:  0.40596669282182035\n",
            "Test:  0.473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regularization:  100.0\n",
            "Train:  0.42752229961862137\n",
            "Test:  0.427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regularization:  1000.0\n",
            "Train:  0.43772612733965593\n",
            "Test:  0.402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vlhrnc5n9pfP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "be8c666a-2c42-4ea6-cdca-67bd42dc156f"
      },
      "source": [
        "plt.plot(list(svc_rbf_train_scores.keys()), list(svc_rbf_train_scores.values()), label = 'Training score')\n",
        "plt.plot(list(svc_rbf_test_scores.keys()), list(svc_rbf_test_scores.values()), label = 'Testing score')\n",
        "plt.title(\"Score vs Regularization factor\")\n",
        "plt.xlabel(\"Regularization\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.legend()\n",
        "svc_rbf_df = pd.DataFrame(svc_rbf_times, index=[\"Time Taken\"])\n",
        "svc_rbf_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0.001</th>\n",
              "      <th>0.010</th>\n",
              "      <th>0.100</th>\n",
              "      <th>1.000</th>\n",
              "      <th>10.000</th>\n",
              "      <th>100.000</th>\n",
              "      <th>1000.000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Time Taken</th>\n",
              "      <td>92.68099</td>\n",
              "      <td>91.643709</td>\n",
              "      <td>91.811137</td>\n",
              "      <td>92.527648</td>\n",
              "      <td>88.680478</td>\n",
              "      <td>88.582021</td>\n",
              "      <td>84.556544</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            0.001      0.010      0.100     ...   10.000     100.000    1000.000\n",
              "Time Taken  92.68099  91.643709  91.811137  ...  88.680478  88.582021  84.556544\n",
              "\n",
              "[1 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmCXlJAy-Iyd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "889c3fd7-3228-4029-e480-256424fdb4d6"
      },
      "source": [
        "best = max(svc_rbf_test_scores, key=svc_rbf_test_scores.get)\n",
        "svc_rbf = SVC(kernel='rbf', C=best, max_iter=500)\n",
        "svc_rbf.fit(x_train_scaled, y_train)\n",
        "\n",
        "y_pred = svc_rbf.predict(x_test_scaled)\n",
        "print(\"Precision, Recall, Fscore\")\n",
        "print(precision_recall_fscore_support(y_test, y_pred, average=\"weighted\"))\n",
        "print(\"Best regularization: \" + str(best))\n",
        "cm_rbf = confusion_matrix(y_test, y_pred)\n",
        "df_rbf = pd.DataFrame(cm_rbf, columns = [\"Predicted Negative\", \"Predicted Positive\"])\n",
        "df_rbf.index = cm_index\n",
        "df_rbf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision, Recall, Fscore\n",
            "(0.5903236507535573, 0.642, 0.5322855408967639, None)\n",
            "Best regularization: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted Negative</th>\n",
              "      <th>Predicted Positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Actual Negative</th>\n",
              "      <td>18</td>\n",
              "      <td>339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual Positive</th>\n",
              "      <td>19</td>\n",
              "      <td>624</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Predicted Negative  Predicted Positive\n",
              "Actual Negative                  18                 339\n",
              "Actual Positive                  19                 624"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW6J9o942dN9"
      },
      "source": [
        "## Classifier for non-zero"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR5IasiX0iq8"
      },
      "source": [
        "### **Processing for non-zero data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9IoAhLs1Cif"
      },
      "source": [
        "import numpy\n",
        "\n",
        "def filter_non_zero(df):\n",
        "  return df[df['target'] != 0]\n",
        "\n",
        "def filter_non_zero_test_from_classification(df, y_pred_classification, index_start):\n",
        "  temp = y_pred_classification[index_start: index_start + 100]\n",
        "  remove_index = []\n",
        "  for row in range(len(temp)):\n",
        "    if (temp[row] == 0): # Check for zero data\n",
        "      remove_index.append(row)\n",
        "  remove_index = numpy.array(remove_index)\n",
        "  df = df.reset_index()\n",
        "  df = df.drop(remove_index)\n",
        "  df = df.drop(columns=\"index\")\n",
        "  return df\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNxkSLLx12OU"
      },
      "source": [
        "def process_train_data_non_zero(urls):\n",
        "  df_list = read_data(urls)\n",
        "  df_list = merge_days(df_list)\n",
        "  df_list_2 = []\n",
        "  normalize_scalar = []\n",
        "\n",
        "  for df in df_list:\n",
        "     df = removeCols529(df)\n",
        "     df = df.drop(['post_promotion_status'], 1)\n",
        "     df = filter_non_zero(df)\n",
        "     df_list_2.append(df)\n",
        "\n",
        "  df_list = df_list_2\n",
        "  merged_df = pd.concat(df_list)\n",
        "  df_list.append(merged_df)\n",
        "  unwanted_attributes = []\n",
        "  x_train_list = []\n",
        "  y_train_list = []\n",
        "  scaler_x_list = []\n",
        "  scaler_y_list = []\n",
        "\n",
        "  for df in df_list:\n",
        "    features, labels = split_df(df)\n",
        "    features, scaler_x = normalizeTrain(features)\n",
        "    labels, scaler_y = normalizeTrainTarget(labels)\n",
        "    x_train_list.append(features)\n",
        "    y_train_list.append(labels)\n",
        "    scaler_x_list.append(scaler_x)\n",
        "    scaler_y_list.append(scaler_y)   \n",
        "\n",
        "  return x_train_list, y_train_list, unwanted_attributes, scaler_x_list, scaler_y_list\n",
        "\n",
        "def process_test_data_non_zero(urls, columns_to_drop, scaler_x, scaler_y):\n",
        "  df_list = read_data(urls)\n",
        "  df_list = merge_days(df_list)\n",
        "  df_list_2 = []\n",
        "  start = 0\n",
        "\n",
        "  for df in df_list:\n",
        "    df = removeCols529(df)\n",
        "    df = df.drop(['post_promotion_status'], 1)\n",
        "    df = filter_non_zero_test_from_classification(df, y_pred_classification, start)\n",
        "    df_list_2.append(df)\n",
        "    start += 100\n",
        "\n",
        "  df_list = df_list_2\n",
        "  merged_df = pd.concat(df_list)\n",
        "  df_list.append(merged_df)\n",
        "  x_test_list = []\n",
        "  y_test_list = []\n",
        "\n",
        "  for df in df_list:\n",
        "    features, labels = split_df(df)\n",
        "    features = normalizeTest(features, scaler_x)\n",
        "    labels = normalizeTestTarget(labels, scaler_y)\n",
        "    x_test_list.append(features)\n",
        "    y_test_list.append(labels)\n",
        "\n",
        "  return x_test_list, y_test_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFzeEiAo2arG"
      },
      "source": [
        "x_train_non_zero_list, y_train_non_zero_list, columns_to_drop, scaler_x_list, scaler_y_list = process_train_data_non_zero(training_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jbysX0j2j6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "170173ab-5767-4ca8-aadf-0167410149f2"
      },
      "source": [
        "x_test_non_zero_list, y_test_non_zero_list = process_test_data_non_zero(testing_files, columns_to_drop, scaler_x_list[5], scaler_y_list[5])\n",
        "x_test_non_zero_merged = x_test_non_zero_list[10]\n",
        "y_test_non_zero_merged = y_test_non_zero_list[10]\n",
        "print(y_test_non_zero_merged)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       target\n",
            "0    0.377921\n",
            "1   -0.279842\n",
            "2   -0.319706\n",
            "3    1.912700\n",
            "4   -0.299774\n",
            "..        ...\n",
            "714 -0.319706\n",
            "715 -0.299774\n",
            "716 -0.319706\n",
            "717 -0.319706\n",
            "718 -0.220045\n",
            "\n",
            "[719 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpoCaNQSdKJa"
      },
      "source": [
        "**AUC@10 Metric** Idk why not working zzzzzzzzzzzz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK5jrlIVc7Hl"
      },
      "source": [
        "def aucAt10(pred_y, actual_y):\n",
        "  fpr, tpr, thresholds = metrics.roc_curve(actual_y, pred_y)\n",
        "  print(\"fpr\" + str(fpr))\n",
        "  print(\"tpr\", str(tpr))\n",
        "  return metrics.auc(fpr, tpr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxLUV6HK74GQ"
      },
      "source": [
        "**Hits@10 Metric**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWaZWI4E78ww"
      },
      "source": [
        "def hitsAt10(variant_scores, y_test_non_zero_list):\n",
        "  totalHits = 0\n",
        "  totalMisses = 0\n",
        "  auc_pred = []\n",
        "\n",
        "  for i in range(len(variant_scores)):\n",
        "    hits = 0\n",
        "    miss = 0\n",
        "    y_predicted = variant_scores[i]\n",
        "    y_actual = y_test_non_zero_list[i].values.tolist()\n",
        "    y_predicted_with_pos = []\n",
        "    y_actual_with_pos = []\n",
        "    \n",
        "    for j in range(len(y_actual)):\n",
        "      y_actual_with_pos.append([y_actual[j], j])\n",
        "    for j in range(len(y_predicted)):\n",
        "      y_predicted_with_pos.append([y_predicted[j], j])\n",
        "\n",
        "    y_actual_with_pos.sort()\n",
        "    y_actual_with_pos.reverse()\n",
        "\n",
        "    y_predicted_with_pos.sort()\n",
        "    y_predicted_with_pos.reverse()\n",
        "\n",
        "    y_actual_dic = {}\n",
        "    for target, pos in y_actual_with_pos[:10]:\n",
        "      y_actual_dic[pos] = target\n",
        "\n",
        "    \n",
        "    for target, pos in y_predicted_with_pos[:10]:\n",
        "      if (y_actual_dic.get(pos) is not None):\n",
        "        hits += 1 # True Positive\n",
        "        auc_pred.append(1)\n",
        "      else:\n",
        "        auc_pred.append(0)\n",
        "        miss += 1 # False Positive\n",
        "\n",
        "    totalHits += hits\n",
        "    totalMisses += miss\n",
        "  \n",
        "  hitsAt10Score = totalHits/11\n",
        "  \n",
        "  return hitsAt10Score\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7ktNRl2Kg-F"
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "poly_features = PolynomialFeatures(degree=1, include_bias=True)\n",
        "lin_reg = LinearRegression()\n",
        "mlp = MLPRegressor(alpha = 1e-4, hidden_layer_sizes = (150,5,20,5), \n",
        "random_state = 12, max_iter = 500, activation = 'relu', early_stopping = True, learning_rate_init = 0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5Fl5nFtvdyW"
      },
      "source": [
        "**Polynomial Regresion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CU5SO_e0cTZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8d5a7f6-8836-49ed-a1e4-f0684a8f0e5f"
      },
      "source": [
        "scores = []\n",
        "poly_data = {\"Score\": [], \"Mean Absolute Error\": [], \"Mean Squared Error\": [], \"Root Mean Squared Error\": [], \"Time Taken\": []}\n",
        "for i in range(6):\n",
        "  x_test_non_zero_list, y_test_non_zero_list = process_test_data_non_zero(testing_files, columns_to_drop, scaler_x_list[i], scaler_y_list[i])\n",
        "  x_test_non_zero_merged = x_test_non_zero_list[10]\n",
        "  y_test_non_zero_merged = y_test_non_zero_list[10]  \n",
        "  start = time.time()\n",
        "  x_poly_train = poly_features.fit_transform(x_train_non_zero_list[i])\n",
        "  lin_reg.fit(x_poly_train, y_train_non_zero_list[i])\n",
        "\n",
        "  x_poly_test = poly_features.fit_transform(x_test_non_zero_merged)\n",
        "  score = lin_reg.score(x_poly_test, y_test_non_zero_merged)\n",
        "  if i == 5:\n",
        "    print(\"Variant Merged Score: \" +str(score))\n",
        "  else:\n",
        "    print(\"Variant Score\" + str(i + 1) + \": \" + str(score))\n",
        "    scores.append(score)\n",
        "  \n",
        "  y_predicted = lin_reg.predict(x_poly_test)\n",
        "  y_test_non_zero_merged_inversed = scaler_y_list[5].inverse_transform(y_test_non_zero_merged)\n",
        "  y_predicted_inversed = scaler_y_list[5].inverse_transform(y_predicted)\n",
        "  # y_train_predicted_inversed = scaler_y_list[5].inverse_transform(np.array(y_train_predicted).reshape(-1, 1))\n",
        "\n",
        "  mae = mean_absolute_error(y_test_non_zero_merged_inversed, y_predicted_inversed)\n",
        "  mse = mean_squared_error(y_test_non_zero_merged_inversed, y_predicted_inversed)\n",
        "  rms = sqrt(mse)\n",
        "\n",
        "  end = time.time()\n",
        "  poly_data[\"Score\"].append(score)\n",
        "  poly_data[\"Mean Absolute Error\"].append(mae)\n",
        "  poly_data[\"Mean Squared Error\"].append(mse)\n",
        "  poly_data[\"Root Mean Squared Error\"].append(rms)\n",
        "  poly_data[\"Time Taken\"].append(end - start)\n",
        "\n",
        "print(\"Average Score over 5 Variants: \" + str(sum(scores)/len(scores)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Score1: 0.12211427952412324\n",
            "Variant Score2: 0.10337224632135589\n",
            "Variant Score3: 0.11300919654649633\n",
            "Variant Score4: 0.10569461914856548\n",
            "Variant Score5: 0.10446019310657662\n",
            "Variant Merged Score: 0.10765579512654311\n",
            "Average Score over 5 Variants: 0.1097301069294235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrFzzlyT7cLP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "70fef493-44af-47de-99c2-27cc42bf4de1"
      },
      "source": [
        "print(\"Polynomial Regression Score\")\n",
        "poly_df = pd.DataFrame(poly_data, index = [\"Variant 1\", \"Variant 2\", \"Variant 3\", \"Variant 4\", \"Variant 5\", \"Merged\"])\n",
        "poly_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polynomial Regression Score\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Score</th>\n",
              "      <th>Mean Absolute Error</th>\n",
              "      <th>Mean Squared Error</th>\n",
              "      <th>Root Mean Squared Error</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Variant 1</th>\n",
              "      <td>0.122114</td>\n",
              "      <td>34.407153</td>\n",
              "      <td>12348.008183</td>\n",
              "      <td>111.121592</td>\n",
              "      <td>0.049206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 2</th>\n",
              "      <td>0.103372</td>\n",
              "      <td>35.801282</td>\n",
              "      <td>12121.469969</td>\n",
              "      <td>110.097548</td>\n",
              "      <td>0.051141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 3</th>\n",
              "      <td>0.113009</td>\n",
              "      <td>37.297895</td>\n",
              "      <td>14050.464554</td>\n",
              "      <td>118.534655</td>\n",
              "      <td>0.060955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 4</th>\n",
              "      <td>0.105695</td>\n",
              "      <td>37.406219</td>\n",
              "      <td>13398.707602</td>\n",
              "      <td>115.752787</td>\n",
              "      <td>0.078913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 5</th>\n",
              "      <td>0.104460</td>\n",
              "      <td>36.896336</td>\n",
              "      <td>13447.174760</td>\n",
              "      <td>115.961954</td>\n",
              "      <td>0.086344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Merged</th>\n",
              "      <td>0.107656</td>\n",
              "      <td>36.738448</td>\n",
              "      <td>13271.243252</td>\n",
              "      <td>115.200882</td>\n",
              "      <td>0.205821</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Score  Mean Absolute Error  ...  Root Mean Squared Error  Time Taken\n",
              "Variant 1  0.122114            34.407153  ...               111.121592    0.049206\n",
              "Variant 2  0.103372            35.801282  ...               110.097548    0.051141\n",
              "Variant 3  0.113009            37.297895  ...               118.534655    0.060955\n",
              "Variant 4  0.105695            37.406219  ...               115.752787    0.078913\n",
              "Variant 5  0.104460            36.896336  ...               115.961954    0.086344\n",
              "Merged     0.107656            36.738448  ...               115.200882    0.205821\n",
              "\n",
              "[6 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-5yqHONYIdd"
      },
      "source": [
        "**Calculating Hits@10**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Un_BQhINA9f"
      },
      "source": [
        "poly_hits_data = {\"Hits@10\": [], \"Time Taken\": []}\n",
        "for i in range(6):\n",
        "  start = time.time()\n",
        "  x_test_non_zero_list, y_test_non_zero_list = process_test_data_non_zero(testing_files, columns_to_drop, scaler_x_list[i], scaler_y_list[i])\n",
        "  x_test_non_zero_merged = x_test_non_zero_list[10]\n",
        "  y_test_non_zero_merged = y_test_non_zero_list[10]  \n",
        "  x_poly_train = poly_features.fit_transform(x_train_non_zero_list[i])\n",
        "  lin_reg.fit(x_poly_train, y_train_non_zero_list[i])\n",
        "  variant_scores = []\n",
        "\n",
        "  for j in range(11):\n",
        "    x_poly_test = poly_features.fit_transform(x_test_non_zero_list[j])\n",
        "    score = lin_reg.score(x_poly_test, y_test_non_zero_list[j])\n",
        "    y_predicted = lin_reg.predict(x_poly_test)\n",
        "    variant_scores.append(y_predicted)\n",
        "  \n",
        "  hitsAt10Score = hitsAt10(variant_scores, y_test_non_zero_list)\n",
        "  end = time.time()\n",
        "  poly_hits_data[\"Hits@10\"].append(hitsAt10Score)\n",
        "  poly_hits_data[\"Time Taken\"].append(end - start)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgv7SJQH9MnM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "7644d747-064b-4dde-ea1b-2eccb7d22ceb"
      },
      "source": [
        "print(\"Hits @ 10\")\n",
        "poly_hits_df = pd.DataFrame(poly_hits_data, index = [\"Variant 1\", \"Variant 2\", \"Variant 3\", \"Variant 4\", \"Variant 5\", \"Merged\"])\n",
        "poly_hits_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hits @ 10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hits@10</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Variant 1</th>\n",
              "      <td>5.272727</td>\n",
              "      <td>0.834178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 2</th>\n",
              "      <td>4.909091</td>\n",
              "      <td>0.872838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 3</th>\n",
              "      <td>5.090909</td>\n",
              "      <td>0.862420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 4</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.871701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 5</th>\n",
              "      <td>5.181818</td>\n",
              "      <td>0.870066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Merged</th>\n",
              "      <td>5.090909</td>\n",
              "      <td>0.965506</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Hits@10  Time Taken\n",
              "Variant 1  5.272727    0.834178\n",
              "Variant 2  4.909091    0.872838\n",
              "Variant 3  5.090909    0.862420\n",
              "Variant 4  5.000000    0.871701\n",
              "Variant 5  5.181818    0.870066\n",
              "Merged     5.090909    0.965506"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BqOF2CP64Tv"
      },
      "source": [
        "**Random Forest Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yAUKdQ9669Y"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rfr = RandomForestRegressor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MBJHBFDBwHE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fde01891-287d-4072-e839-b8d8401fabd7"
      },
      "source": [
        "scores = []\n",
        "rfr_data = {\"Score\": [], \"Mean Absolute Error\": [], \"Mean Squared Error\": [], \"Root Mean Squared Error\": [], \"Time Taken\": []}\n",
        "for i in range(6):\n",
        "  start = time.time()\n",
        "  x_test_non_zero_list, y_test_non_zero_list = process_test_data_non_zero(testing_files, columns_to_drop, scaler_x_list[i], scaler_y_list[i])\n",
        "  x_test_non_zero_merged = x_test_non_zero_list[10]\n",
        "  y_test_non_zero_merged = y_test_non_zero_list[10]  \n",
        "  rfr.fit(x_train_non_zero_list[i], y_train_non_zero_list[i])\n",
        "  score = rfr.score(x_test_non_zero_merged, y_test_non_zero_merged)\n",
        "  if i == 5:\n",
        "    print(\"Variant Merged Score: \" +str(score))\n",
        "  else:\n",
        "    print(\"Variant Score\" + str(i + 1) + \": \" + str(score))\n",
        "    scores.append(score)\n",
        "  \n",
        "  y_predicted = rfr.predict(x_test_non_zero_merged)\n",
        "\n",
        "  y_test_non_zero_merged_inversed = scaler_y_list[5].inverse_transform(y_test_non_zero_merged)\n",
        "  y_predicted_inversed = scaler_y_list[5].inverse_transform(np.array(y_predicted).reshape(-1, 1))\n",
        "  mae = mean_absolute_error(y_test_non_zero_merged_inversed, y_predicted_inversed)\n",
        "  mse = mean_squared_error(y_test_non_zero_merged_inversed, y_predicted_inversed)\n",
        "  rms = sqrt(mse)\n",
        "\n",
        "  end = time.time()\n",
        "  rfr_data[\"Score\"].append(score)\n",
        "  rfr_data[\"Mean Absolute Error\"].append(mae)\n",
        "  rfr_data[\"Mean Squared Error\"].append(mse)\n",
        "  rfr_data[\"Root Mean Squared Error\"].append(rms)\n",
        "  rfr_data[\"Time Taken\"].append(end - start)\n",
        "\n",
        "print(\"Average Score over 5 Variants: \" + str(sum(scores)/len(scores)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Score1: 0.2674572475839474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Score2: 0.2181346121457507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Score3: 0.3213943995745163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Score4: 0.28956669410903857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Score5: 0.24241298938042055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Merged Score: 0.3123927131253037\n",
            "Average Score over 5 Variants: 0.2677931885587347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB9XwfU6B953",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "1e33553e-c633-4840-d69d-cd232aef6db9"
      },
      "source": [
        "print(\"Random Forest Score\")\n",
        "rfr_df = pd.DataFrame(rfr_data, index = [\"Variant 1\", \"Variant 2\", \"Variant 3\", \"Variant 4\", \"Variant 5\", \"Merged\"])\n",
        "rfr_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Score\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Score</th>\n",
              "      <th>Mean Absolute Error</th>\n",
              "      <th>Mean Squared Error</th>\n",
              "      <th>Root Mean Squared Error</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Variant 1</th>\n",
              "      <td>0.267457</td>\n",
              "      <td>32.670764</td>\n",
              "      <td>10303.669020</td>\n",
              "      <td>101.506990</td>\n",
              "      <td>20.359547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 2</th>\n",
              "      <td>0.218135</td>\n",
              "      <td>35.847519</td>\n",
              "      <td>10570.002746</td>\n",
              "      <td>102.810519</td>\n",
              "      <td>35.415313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 3</th>\n",
              "      <td>0.321394</td>\n",
              "      <td>35.613701</td>\n",
              "      <td>10749.518369</td>\n",
              "      <td>103.679884</td>\n",
              "      <td>53.225895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 4</th>\n",
              "      <td>0.289567</td>\n",
              "      <td>36.751198</td>\n",
              "      <td>10643.890040</td>\n",
              "      <td>103.169230</td>\n",
              "      <td>71.943429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 5</th>\n",
              "      <td>0.242413</td>\n",
              "      <td>35.048419</td>\n",
              "      <td>11375.714233</td>\n",
              "      <td>106.656993</td>\n",
              "      <td>90.810725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Merged</th>\n",
              "      <td>0.312393</td>\n",
              "      <td>33.411610</td>\n",
              "      <td>10226.326922</td>\n",
              "      <td>101.125303</td>\n",
              "      <td>290.967386</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Score  Mean Absolute Error  ...  Root Mean Squared Error  Time Taken\n",
              "Variant 1  0.267457            32.670764  ...               101.506990   20.359547\n",
              "Variant 2  0.218135            35.847519  ...               102.810519   35.415313\n",
              "Variant 3  0.321394            35.613701  ...               103.679884   53.225895\n",
              "Variant 4  0.289567            36.751198  ...               103.169230   71.943429\n",
              "Variant 5  0.242413            35.048419  ...               106.656993   90.810725\n",
              "Merged     0.312393            33.411610  ...               101.125303  290.967386\n",
              "\n",
              "[6 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJuHVvkRCri4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f856ebd-45d0-4e03-ad88-6e81ef81ac01"
      },
      "source": [
        "rfr_hits_data = {\"Hits@10\": [], \"Time Taken\": []}\n",
        "for i in range(6):\n",
        "  start = time.time()\n",
        "  rfr.fit(x_train_non_zero_list[i], y_train_non_zero_list[i])\n",
        "  variant_scores = []\n",
        "  for j in range(11):\n",
        "    score = rfr.score(x_test_non_zero_list[j], y_test_non_zero_list[j])\n",
        "    y_predicted = rfr.predict(x_test_non_zero_list[i])\n",
        "    variant_scores.append(y_predicted)\n",
        "  \n",
        "  hitsAt10Score = hitsAt10(variant_scores, y_test_non_zero_list)\n",
        "  end = time.time()\n",
        "  rfr_hits_data[\"Hits@10\"].append(hitsAt10Score)\n",
        "  rfr_hits_data[\"Time Taken\"].append(end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuybaPkjC_Up",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "5443de59-295c-4dc0-efbc-dae584288232"
      },
      "source": [
        "print(\"Hits @ 10\")\n",
        "rfr_hits_df = pd.DataFrame(rfr_hits_data, index = [\"Variant 1\", \"Variant 2\", \"Variant 3\", \"Variant 4\", \"Variant 5\", \"Merged\"])\n",
        "rfr_hits_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hits @ 10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hits@10</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Variant 1</th>\n",
              "      <td>2.363636</td>\n",
              "      <td>16.970503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 2</th>\n",
              "      <td>1.272727</td>\n",
              "      <td>34.992805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 3</th>\n",
              "      <td>1.636364</td>\n",
              "      <td>52.918341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 4</th>\n",
              "      <td>1.727273</td>\n",
              "      <td>70.801265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 5</th>\n",
              "      <td>1.454545</td>\n",
              "      <td>91.073345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Merged</th>\n",
              "      <td>2.090909</td>\n",
              "      <td>291.198200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Hits@10  Time Taken\n",
              "Variant 1  2.363636   16.970503\n",
              "Variant 2  1.272727   34.992805\n",
              "Variant 3  1.636364   52.918341\n",
              "Variant 4  1.727273   70.801265\n",
              "Variant 5  1.454545   91.073345\n",
              "Merged     2.090909  291.198200"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtciNoALWvCR"
      },
      "source": [
        "**Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjadIyTNK9q8"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg = DecisionTreeRegressor(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb1LllwGXB4Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c5228bd-5735-4165-d2b6-67a87ffea855"
      },
      "source": [
        "scores = []\n",
        "tree_data = {\"Score\": [], \"Mean Absolute Error\": [], \"Mean Squared Error\": [], \"Root Mean Squared Error\": [], \"Time Taken\": []}\n",
        "for i in range(6):\n",
        "  start = time.time()\n",
        "  x_test_non_zero_list, y_test_non_zero_list = process_test_data_non_zero(testing_files, columns_to_drop, scaler_x_list[i], scaler_y_list[i])\n",
        "  x_test_non_zero_merged = x_test_non_zero_list[10]\n",
        "  y_test_non_zero_merged = y_test_non_zero_list[10]  \n",
        "  tree_reg.fit(x_train_non_zero_list[i], y_train_non_zero_list[i])\n",
        "  score = tree_reg.score(x_test_non_zero_merged, y_test_non_zero_merged)\n",
        "  if i == 5:\n",
        "    print(\"Variant Merged Score: \" +str(score))\n",
        "  else:\n",
        "    print(\"Variant Score\" + str(i + 1) + \": \" + str(score))\n",
        "    scores.append(score)\n",
        "  \n",
        "  y_predicted = tree_reg.predict(x_test_non_zero_merged)\n",
        "\n",
        "  y_test_non_zero_merged_inversed = scaler_y_list[5].inverse_transform(y_test_non_zero_merged)\n",
        "  y_predicted_inversed = scaler_y_list[5].inverse_transform(np.array(y_predicted).reshape(-1, 1))\n",
        "  mae = mean_absolute_error(y_test_non_zero_merged_inversed, y_predicted_inversed)\n",
        "  mse = mean_squared_error(y_test_non_zero_merged_inversed, y_predicted_inversed)\n",
        "  rms = sqrt(mse)\n",
        "\n",
        "  end = time.time()\n",
        "  tree_data[\"Score\"].append(score)\n",
        "  tree_data[\"Mean Absolute Error\"].append(mae)\n",
        "  tree_data[\"Mean Squared Error\"].append(mse)\n",
        "  tree_data[\"Root Mean Squared Error\"].append(rms)\n",
        "  tree_data[\"Time Taken\"].append(end - start)\n",
        "\n",
        "print(\"Average Score over 5 Variants: \" + str(sum(scores)/len(scores)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Score1: 0.10407977798472268\n",
            "Variant Score2: -0.26952899171274103\n",
            "Variant Score3: 0.19336007900740104\n",
            "Variant Score4: 0.2769881015760516\n",
            "Variant Score5: -0.1551413560202084\n",
            "Variant Merged Score: -0.2440781680410229\n",
            "Average Score over 5 Variants: 0.029951522167045174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZsSZ7wF-Tn5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "9cb0fe33-9c54-4af9-808f-c6e42c501220"
      },
      "source": [
        "print(\"Decision Tree Score\")\n",
        "tree_df = pd.DataFrame(tree_data, index = [\"Variant 1\", \"Variant 2\", \"Variant 3\", \"Variant 4\", \"Variant 5\", \"Merged\"])\n",
        "tree_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Score\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Score</th>\n",
              "      <th>Mean Absolute Error</th>\n",
              "      <th>Mean Squared Error</th>\n",
              "      <th>Root Mean Squared Error</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Variant 1</th>\n",
              "      <td>0.104080</td>\n",
              "      <td>36.831937</td>\n",
              "      <td>12601.674654</td>\n",
              "      <td>112.257181</td>\n",
              "      <td>1.007047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 2</th>\n",
              "      <td>-0.269529</td>\n",
              "      <td>39.282287</td>\n",
              "      <td>17162.704907</td>\n",
              "      <td>131.006507</td>\n",
              "      <td>1.289822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 3</th>\n",
              "      <td>0.193360</td>\n",
              "      <td>40.472012</td>\n",
              "      <td>12777.658544</td>\n",
              "      <td>113.038306</td>\n",
              "      <td>1.559675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 4</th>\n",
              "      <td>0.276988</td>\n",
              "      <td>37.006650</td>\n",
              "      <td>10832.345669</td>\n",
              "      <td>104.078555</td>\n",
              "      <td>1.901530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 5</th>\n",
              "      <td>-0.155141</td>\n",
              "      <td>41.194370</td>\n",
              "      <td>17345.278867</td>\n",
              "      <td>131.701476</td>\n",
              "      <td>2.196645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Merged</th>\n",
              "      <td>-0.244078</td>\n",
              "      <td>40.287900</td>\n",
              "      <td>18502.349096</td>\n",
              "      <td>136.023340</td>\n",
              "      <td>5.263527</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Score  Mean Absolute Error  ...  Root Mean Squared Error  Time Taken\n",
              "Variant 1  0.104080            36.831937  ...               112.257181    1.007047\n",
              "Variant 2 -0.269529            39.282287  ...               131.006507    1.289822\n",
              "Variant 3  0.193360            40.472012  ...               113.038306    1.559675\n",
              "Variant 4  0.276988            37.006650  ...               104.078555    1.901530\n",
              "Variant 5 -0.155141            41.194370  ...               131.701476    2.196645\n",
              "Merged    -0.244078            40.287900  ...               136.023340    5.263527\n",
              "\n",
              "[6 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogHH6UutYXvq"
      },
      "source": [
        "**Hits@10 Score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL8u3ZiWYbOO"
      },
      "source": [
        "tree_hits_data = {\"Hits@10\": [], \"Time Taken\": []}\n",
        "for i in range(6):\n",
        "  start = time.time()\n",
        "  tree_reg.fit(x_train_non_zero_list[i], y_train_non_zero_list[i])\n",
        "  variant_scores = []\n",
        "  for j in range(11):\n",
        "    score = tree_reg.score(x_test_non_zero_list[j], y_test_non_zero_list[j])\n",
        "    y_predicted = tree_reg.predict(x_test_non_zero_list[i])\n",
        "    variant_scores.append(y_predicted)\n",
        "  \n",
        "  hitsAt10Score = hitsAt10(variant_scores, y_test_non_zero_list)\n",
        "  end = time.time()\n",
        "  tree_hits_data[\"Hits@10\"].append(hitsAt10Score)\n",
        "  tree_hits_data[\"Time Taken\"].append(end - start)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7-e9ROk-3D8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "8d93c36a-afed-434e-e1a3-82e355db2e4e"
      },
      "source": [
        "print(\"Hits @ 10\")\n",
        "tree_hits_df = pd.DataFrame(tree_hits_data, index = [\"Variant 1\", \"Variant 2\", \"Variant 3\", \"Variant 4\", \"Variant 5\", \"Merged\"])\n",
        "tree_hits_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hits @ 10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hits@10</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Variant 1</th>\n",
              "      <td>2.090909</td>\n",
              "      <td>0.319867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 2</th>\n",
              "      <td>1.363636</td>\n",
              "      <td>0.605518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 3</th>\n",
              "      <td>1.727273</td>\n",
              "      <td>0.899240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 4</th>\n",
              "      <td>1.727273</td>\n",
              "      <td>1.201777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 5</th>\n",
              "      <td>1.636364</td>\n",
              "      <td>1.518887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Merged</th>\n",
              "      <td>1.363636</td>\n",
              "      <td>4.574254</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Hits@10  Time Taken\n",
              "Variant 1  2.090909    0.319867\n",
              "Variant 2  1.363636    0.605518\n",
              "Variant 3  1.727273    0.899240\n",
              "Variant 4  1.727273    1.201777\n",
              "Variant 5  1.636364    1.518887\n",
              "Merged     1.363636    4.574254"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZggEkpiER8p"
      },
      "source": [
        "**Gradient Boosting Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsNbpthkERHU"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "gbr = GradientBoostingRegressor(n_estimators=3, learning_rate=0.5, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySbIMKEWEj1X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2e8ae26-4362-4c24-a422-30a588c6f4a0"
      },
      "source": [
        "scores = []\n",
        "gbr_data = {\"Score\": [], \"Mean Absolute Error\": [], \"Mean Squared Error\": [], \"Root Mean Squared Error\": [], \"Time Taken\": []}\n",
        "for i in range(6):\n",
        "  start = time.time()\n",
        "  x_test_non_zero_list, y_test_non_zero_list = process_test_data_non_zero(testing_files, columns_to_drop, scaler_x_list[i], scaler_y_list[i])\n",
        "  x_test_non_zero_merged = x_test_non_zero_list[10]\n",
        "  y_test_non_zero_merged = y_test_non_zero_list[10]   \n",
        "  gbr.fit(x_train_non_zero_list[i], y_train_non_zero_list[i])\n",
        "  score = gbr.score(x_test_non_zero_merged, y_test_non_zero_merged)\n",
        "  if i == 5:\n",
        "    print(\"Variant Merged Score: \" +str(score))\n",
        "  else:\n",
        "    print(\"Variant Score\" + str(i + 1) + \": \" + str(score))\n",
        "    scores.append(score)\n",
        "  \n",
        "  y_predicted = gbr.predict(x_test_non_zero_merged)\n",
        "\n",
        "  y_test_non_zero_merged_inversed = scaler_y_list[5].inverse_transform(y_test_non_zero_merged)\n",
        "  y_predicted_inversed = scaler_y_list[5].inverse_transform(np.array(y_predicted).reshape(-1, 1))\n",
        "  mae = mean_absolute_error(y_test_non_zero_merged_inversed, y_predicted_inversed)\n",
        "  mse = mean_squared_error(y_test_non_zero_merged_inversed, y_predicted_inversed)\n",
        "  rms = sqrt(mse)\n",
        "\n",
        "  end = time.time()\n",
        "  gbr_data[\"Score\"].append(score)\n",
        "  gbr_data[\"Mean Absolute Error\"].append(mae)\n",
        "  gbr_data[\"Mean Squared Error\"].append(mse)\n",
        "  gbr_data[\"Root Mean Squared Error\"].append(rms)\n",
        "  gbr_data[\"Time Taken\"].append(end - start)\n",
        "\n",
        "print(\"Average Score over 5 Variants: \" + str(sum(scores)/len(scores)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Score1: 0.3040806765822581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Score2: 0.17460879673885088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Score3: 0.2379167375607879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Score4: 0.21644455298360288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Score5: 0.24674004678386785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Merged Score: 0.25210848975894573\n",
            "Average Score over 5 Variants: 0.23595816212987356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PowmsNNSEyLJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "a71e8ec1-02a8-4fc7-ae92-1f399d4029cc"
      },
      "source": [
        "print(\"Gradient Boosting Score\")\n",
        "gbr_df = pd.DataFrame(gbr_data, index = [\"Variant 1\", \"Variant 2\", \"Variant 3\", \"Variant 4\", \"Variant 5\", \"Merged\"])\n",
        "rfr_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Score\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Score</th>\n",
              "      <th>Mean Absolute Error</th>\n",
              "      <th>Mean Squared Error</th>\n",
              "      <th>Root Mean Squared Error</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Variant 1</th>\n",
              "      <td>0.267457</td>\n",
              "      <td>32.670764</td>\n",
              "      <td>10303.669020</td>\n",
              "      <td>101.506990</td>\n",
              "      <td>20.359547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 2</th>\n",
              "      <td>0.218135</td>\n",
              "      <td>35.847519</td>\n",
              "      <td>10570.002746</td>\n",
              "      <td>102.810519</td>\n",
              "      <td>35.415313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 3</th>\n",
              "      <td>0.321394</td>\n",
              "      <td>35.613701</td>\n",
              "      <td>10749.518369</td>\n",
              "      <td>103.679884</td>\n",
              "      <td>53.225895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 4</th>\n",
              "      <td>0.289567</td>\n",
              "      <td>36.751198</td>\n",
              "      <td>10643.890040</td>\n",
              "      <td>103.169230</td>\n",
              "      <td>71.943429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 5</th>\n",
              "      <td>0.242413</td>\n",
              "      <td>35.048419</td>\n",
              "      <td>11375.714233</td>\n",
              "      <td>106.656993</td>\n",
              "      <td>90.810725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Merged</th>\n",
              "      <td>0.312393</td>\n",
              "      <td>33.411610</td>\n",
              "      <td>10226.326922</td>\n",
              "      <td>101.125303</td>\n",
              "      <td>290.967386</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Score  Mean Absolute Error  ...  Root Mean Squared Error  Time Taken\n",
              "Variant 1  0.267457            32.670764  ...               101.506990   20.359547\n",
              "Variant 2  0.218135            35.847519  ...               102.810519   35.415313\n",
              "Variant 3  0.321394            35.613701  ...               103.679884   53.225895\n",
              "Variant 4  0.289567            36.751198  ...               103.169230   71.943429\n",
              "Variant 5  0.242413            35.048419  ...               106.656993   90.810725\n",
              "Merged     0.312393            33.411610  ...               101.125303  290.967386\n",
              "\n",
              "[6 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8C4MkeiE3JL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fa71fcd-ac43-40b6-8d64-89aeb7f86008"
      },
      "source": [
        "gbr_hits_data = {\"Hits@10\": [], \"Time Taken\": []}\n",
        "for i in range(6):\n",
        "  start = time.time()\n",
        "  gbr.fit(x_train_non_zero_list[i], y_train_non_zero_list[i])\n",
        "  variant_scores = []\n",
        "  for j in range(11):\n",
        "    score = gbr.score(x_test_non_zero_list[j], y_test_non_zero_list[j])\n",
        "    y_predicted = gbr.predict(x_test_non_zero_list[i])\n",
        "    variant_scores.append(y_predicted)\n",
        "  \n",
        "  hitsAt10Score = hitsAt10(variant_scores, y_test_non_zero_list)\n",
        "  end = time.time()\n",
        "  gbr_hits_data[\"Hits@10\"].append(hitsAt10Score)\n",
        "  gbr_hits_data[\"Time Taken\"].append(end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHC-oDUlE7SO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "a3ec8938-4329-4ddf-9d8f-3faedb6c252d"
      },
      "source": [
        "print(\"Hits @ 10\")\n",
        "gbr_hits_df = pd.DataFrame(gbr_hits_data, index = [\"Variant 1\", \"Variant 2\", \"Variant 3\", \"Variant 4\", \"Variant 5\", \"Merged\"])\n",
        "gbr_hits_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hits @ 10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hits@10</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Variant 1</th>\n",
              "      <td>2.272727</td>\n",
              "      <td>0.178179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 2</th>\n",
              "      <td>1.272727</td>\n",
              "      <td>0.290805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 3</th>\n",
              "      <td>1.636364</td>\n",
              "      <td>0.386660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 4</th>\n",
              "      <td>1.727273</td>\n",
              "      <td>0.496800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 5</th>\n",
              "      <td>1.454545</td>\n",
              "      <td>0.617114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Merged</th>\n",
              "      <td>1.909091</td>\n",
              "      <td>1.830441</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Hits@10  Time Taken\n",
              "Variant 1  2.272727    0.178179\n",
              "Variant 2  1.272727    0.290805\n",
              "Variant 3  1.636364    0.386660\n",
              "Variant 4  1.727273    0.496800\n",
              "Variant 5  1.454545    0.617114\n",
              "Merged     1.909091    1.830441"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5_8IB-o_r4z"
      },
      "source": [
        "##Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEbB1cCs_uui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d686eb16-66d4-4bd2-f49d-eea39fd0b67b"
      },
      "source": [
        "scores = []\n",
        "mlp_data = {\"Score\": [], \"Mean Absolute Error\": [], \"Mean Squared Error\": [], \"Root Mean Squared Error\": [], \"Time Taken\": []}\n",
        "for i in range(6):\n",
        "  start = time.time()\n",
        "  x_test_non_zero_list, y_test_non_zero_list = process_test_data_non_zero(testing_files, columns_to_drop, scaler_x_list[i], scaler_y_list[i])\n",
        "  x_test_non_zero_merged = x_test_non_zero_list[10]\n",
        "  y_test_non_zero_merged = y_test_non_zero_list[10]  \n",
        "  mlp.fit(x_train_non_zero_list[i], y_train_non_zero_list[i])\n",
        "  score = mlp.score(x_test_non_zero_merged, y_test_non_zero_merged)\n",
        "  if i == 5:\n",
        "    print(\"Variant Merged Score: \" +str(score))\n",
        "  else:\n",
        "    print(\"Variant Score\" + str(i + 1) + \": \" + str(score))\n",
        "    scores.append(score)\n",
        "  \n",
        "  y_predicted = mlp.predict(x_test_non_zero_merged)\n",
        "\n",
        "  y_test_non_zero_merged_inversed = scaler_y_list[5].inverse_transform(y_test_non_zero_merged)\n",
        "  y_predicted_inversed = scaler_y_list[5].inverse_transform(np.array(y_predicted).reshape(-1, 1))\n",
        "  mae = mean_absolute_error(y_test_non_zero_merged_inversed, y_predicted_inversed)\n",
        "  mse = mean_squared_error(y_test_non_zero_merged_inversed, y_predicted_inversed)\n",
        "  rms = sqrt(mse)\n",
        "\n",
        "  end = time.time()\n",
        "  mlp_data[\"Score\"].append(score)\n",
        "  mlp_data[\"Mean Absolute Error\"].append(mae)\n",
        "  mlp_data[\"Mean Squared Error\"].append(mse)\n",
        "  mlp_data[\"Root Mean Squared Error\"].append(rms)\n",
        "  mlp_data[\"Time Taken\"].append(end - start)\n",
        "\n",
        "print(\"Average Score over 5 Variants: \" + str(sum(scores)/len(scores)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Score1: 0.04495012468380666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Score2: 0.2735197524859928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Score3: 0.24595780890736785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Score4: 0.18959910834051896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Score5: 0.3135620358159962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Merged Score: 0.1538749442454601\n",
            "Average Score over 5 Variants: 0.2135177660467365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyjbBADCHZZQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "b2c010e4-2af6-4579-ab19-9acf0c067caf"
      },
      "source": [
        "print(\"Multilayer Perceptron Score\")\n",
        "mlp_df = pd.DataFrame(mlp_data, index = [\"Variant 1\", \"Variant 2\", \"Variant 3\", \"Variant 4\", \"Variant 5\", \"Merged\"])\n",
        "mlp_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multilayer Perceptron Score\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Score</th>\n",
              "      <th>Mean Absolute Error</th>\n",
              "      <th>Mean Squared Error</th>\n",
              "      <th>Root Mean Squared Error</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Variant 1</th>\n",
              "      <td>0.223332</td>\n",
              "      <td>29.404103</td>\n",
              "      <td>10924.324315</td>\n",
              "      <td>104.519493</td>\n",
              "      <td>4.392838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 2</th>\n",
              "      <td>0.326572</td>\n",
              "      <td>27.102187</td>\n",
              "      <td>9104.042187</td>\n",
              "      <td>95.415105</td>\n",
              "      <td>6.914516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 3</th>\n",
              "      <td>0.354082</td>\n",
              "      <td>31.074626</td>\n",
              "      <td>10231.721403</td>\n",
              "      <td>101.151972</td>\n",
              "      <td>14.555664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 4</th>\n",
              "      <td>0.183387</td>\n",
              "      <td>29.790108</td>\n",
              "      <td>12234.705702</td>\n",
              "      <td>110.610604</td>\n",
              "      <td>21.668374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 5</th>\n",
              "      <td>0.231307</td>\n",
              "      <td>35.257148</td>\n",
              "      <td>11542.486034</td>\n",
              "      <td>107.435962</td>\n",
              "      <td>37.184265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Merged</th>\n",
              "      <td>0.175740</td>\n",
              "      <td>31.153248</td>\n",
              "      <td>12258.672212</td>\n",
              "      <td>110.718888</td>\n",
              "      <td>219.573498</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Score  Mean Absolute Error  ...  Root Mean Squared Error  Time Taken\n",
              "Variant 1  0.223332            29.404103  ...               104.519493    4.392838\n",
              "Variant 2  0.326572            27.102187  ...                95.415105    6.914516\n",
              "Variant 3  0.354082            31.074626  ...               101.151972   14.555664\n",
              "Variant 4  0.183387            29.790108  ...               110.610604   21.668374\n",
              "Variant 5  0.231307            35.257148  ...               107.435962   37.184265\n",
              "Merged     0.175740            31.153248  ...               110.718888  219.573498\n",
              "\n",
              "[6 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChdsAv3QAjQr"
      },
      "source": [
        "## Calculate Hits@10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTJoW6KMAk08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c5e34c44-3e50-456d-e420-c169aa5ac590"
      },
      "source": [
        "mlp_hits_data = {\"Hits@10\": [], \"Time Taken\": []}\n",
        "for i in range(6):\n",
        "  start = time.time()\n",
        "  mlp.fit(x_train_non_zero_list[i], y_train_non_zero_list[i])\n",
        "  variant_scores = []\n",
        "  for j in range(11):\n",
        "    score = mlp.score(x_test_non_zero_list[j], y_test_non_zero_list[j])\n",
        "    y_predicted = mlp.predict(x_test_non_zero_list[j])\n",
        "    variant_scores.append(y_predicted)\n",
        "\n",
        "  hitsAt10Score = hitsAt10(variant_scores, y_test_non_zero_list)\n",
        "  end = time.time()\n",
        "  mlp_hits_data[\"Hits@10\"].append(hitsAt10Score)\n",
        "  mlp_hits_data[\"Time Taken\"].append(end - start)\n",
        "\n",
        "print(\"Hits @ 10\")\n",
        "hits_df = pd.DataFrame(mlp_hits_data, index = [\"Variant 1\", \"Variant 2\", \"Variant 3\", \"Variant 4\", \"Variant 5\", \"Merged\"])\n",
        "hits_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hits @ 10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hits@10</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Variant 1</th>\n",
              "      <td>5.090909</td>\n",
              "      <td>3.737025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 2</th>\n",
              "      <td>5.818182</td>\n",
              "      <td>6.382496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 3</th>\n",
              "      <td>5.363636</td>\n",
              "      <td>13.823197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 4</th>\n",
              "      <td>5.454545</td>\n",
              "      <td>20.978622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant 5</th>\n",
              "      <td>5.454545</td>\n",
              "      <td>36.526745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Merged</th>\n",
              "      <td>6.090909</td>\n",
              "      <td>215.153288</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Hits@10  Time Taken\n",
              "Variant 1  5.090909    3.737025\n",
              "Variant 2  5.818182    6.382496\n",
              "Variant 3  5.363636   13.823197\n",
              "Variant 4  5.454545   20.978622\n",
              "Variant 5  5.454545   36.526745\n",
              "Merged     6.090909  215.153288"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R0pL6EnyKjy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "db2eef0a-6128-4500-e1f5-68c2174e34d7"
      },
      "source": [
        "# Test for various hidden layer sizes\n",
        "hidden_layer_list = [(150, 4), (150, 5, 20, 5), (150, 5, 40), (4,), (20, 4), (20, 10, 4), (83, 5, 20, 5)]\n",
        "hidden_layer_string_list = [\"(150, 4)\", \"(150, 5, 20, 5)\", \"(150, 5, 40)\", \"(4,)\", \"(20, 4)\", \"(20, 10, 4)\", \"(83, 5, 20, 5)\"]\n",
        "train_results = []\n",
        "test_results = []\n",
        "mlp_data = {\"Score\": [], \"Mean Absolute Error\": [], \"Mean Squared Error\": [], \"Root Mean Squared Error\": [], \"Hits@10\": []}\n",
        "for hidden_layer in hidden_layer_list:\n",
        "    mlp = MLPRegressor(alpha = 1e-4, hidden_layer_sizes = hidden_layer, \n",
        "    random_state = 12, max_iter = 500, activation = 'relu', early_stopping = True, learning_rate_init = 0.01)\n",
        "    layer_data = []\n",
        "    x_test_non_zero_list, y_test_non_zero_list = process_test_data_non_zero(testing_files, columns_to_drop, scaler_x_list[i], scaler_y_list[i])\n",
        "    x_test_non_zero_merged = x_test_non_zero_list[10]\n",
        "    y_test_non_zero_merged = y_test_non_zero_list[10]  \n",
        "    mlp.fit(x_train_non_zero_list[i], y_train_non_zero_list[i])\n",
        "    score = mlp.score(x_test_non_zero_merged, y_test_non_zero_merged)\n",
        "    if i == 5:\n",
        "        print(\"Variant Merged Score: \" +str(score))\n",
        "    else:\n",
        "        print(\"Variant Score\" + str(i + 1) + \": \" + str(score))\n",
        "    scores.append(score)\n",
        "  \n",
        "    y_predicted = mlp.predict(x_test_non_zero_merged)\n",
        "\n",
        "    y_test_non_zero_merged_inversed = scaler_y_list[5].inverse_transform(y_test_non_zero_merged)\n",
        "    y_predicted_inversed = scaler_y_list[5].inverse_transform(np.array(y_predicted).reshape(-1, 1))\n",
        "    mae = mean_absolute_error(y_test_non_zero_merged_inversed, y_predicted_inversed)\n",
        "    mse = mean_squared_error(y_test_non_zero_merged_inversed, y_predicted_inversed)\n",
        "    rms = sqrt(mse)\n",
        "\n",
        "    layer_data.append(score)\n",
        "    layer_data.append(mae)\n",
        "    layer_data.append(mse)\n",
        "    layer_data.append(rms)\n",
        "    \n",
        "    variant_scores = []\n",
        "    for j in range(11):\n",
        "      score = mlp.score(x_test_non_zero_list[j], y_test_non_zero_list[j])\n",
        "      y_predicted = mlp.predict(x_test_non_zero_list[j])\n",
        "      variant_scores.append(y_predicted)\n",
        "\n",
        "    hitsAt10Score = hitsAt10(variant_scores, y_test_non_zero_list)\n",
        "    layer_data.append(hitsAt10Score)\n",
        "    test_results.append(layer_data)\n",
        "    print(layer_data)\n",
        "\n",
        "plot_list = [\"Score\", \"Mean Absolute Error\", \"Mean Squared Error\", \"Root Mean Squared Error\", \"Hits@10 Score\"]\n",
        "lim_list = [[-0.3, 0.30], [26, 38], [10000, 20000], [100, 140], [4, 7]]\n",
        "for i in range(len(plot_list)):\n",
        "    plot = plot_list[i]\n",
        "    lim = lim_list[i]\n",
        "    plt.title(plot)\n",
        "    plt.ylim(lim)\n",
        "    plt.bar(\"Set 1\", test_results[0][i], width = 1, label = hidden_layer_string_list[0])\n",
        "    plt.bar(\"Set 2\", test_results[1][i], width = 1, label = hidden_layer_string_list[1])\n",
        "    plt.bar(\"Set 3\", test_results[2][i], width = 1, label = hidden_layer_string_list[2])\n",
        "    plt.bar(\"Set 4\", test_results[3][i], width = 1, label = hidden_layer_string_list[3])\n",
        "    plt.bar(\"Set 5\", test_results[4][i], width = 1, label = hidden_layer_string_list[4])\n",
        "    plt.bar(\"Set 6\", test_results[5][i], width = 1, label = hidden_layer_string_list[5])\n",
        "    plt.bar(\"Set 7\", test_results[6][i], width = 1, label = hidden_layer_string_list[6])\n",
        "\n",
        "    plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
        "    plt.show()\n",
        "    plt.clf()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Merged Score: 0.2665136033685096\n",
            "[0.2665136033685096, 33.35419849809712, 10908.656478546098, 104.44451387481344, 5.636363636363637]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Merged Score: 0.17573998910097477\n",
            "[0.17573998910097477, 31.153248480148086, 12258.672211500561, 110.71888823276976, 6.090909090909091]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Merged Score: 0.2951192124735742\n",
            "[0.2951192124735742, 30.815780024921768, 10483.224235330965, 102.387617587924, 5.7272727272727275]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Merged Score: 0.15844427203981726\n",
            "[0.15844427203981726, 32.13622968305211, 12515.899934927698, 111.87448294820271, 5.818181818181818]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Merged Score: -0.26887371348617317\n",
            "[-0.26887371348617317, 33.723490387099964, 18871.11679050263, 137.37218346704194, 5.909090909090909]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Merged Score: 0.2916072643376333\n",
            "[0.2916072643376333, 35.540563849755415, 10535.455109634006, 102.6423650820362, 5.818181818181818]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variant Merged Score: 0.1538749442454601\n",
            "[0.1538749442454601, 31.077034687544405, 12583.856515275242, 112.17778975927116, 5.636363636363637]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CwgN87nEPPw"
      },
      "source": [
        "**Diagrams**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9pRmDOxVPr5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "c2ca6611-381e-48dc-9582-f1cdb0a704c7"
      },
      "source": [
        "plt.title(\"Score\")\n",
        "plt.bar([\"Variant 1\", \"Variant 2\", \"Variant 3\", \"Variant 4\", \"Variant 5\", \"Merged\"], poly_data['Score'], width = 0.1, label = 'Poly Reg')\n",
        "plt.bar(np.arange(len(tree_data['Score'])) + 0.1, tree_data['Score'], width = 0.1, label = 'DT')\n",
        "plt.bar(np.arange(len(rfr_data['Score'])) + 0.2, rfr_data['Score'], width = 0.1, label = 'RFR')\n",
        "plt.bar(np.arange(len(gbr_data['Score'])) + 0.3, gbr_data['Score'], width = 0.1, label = 'GBR')\n",
        "plt.bar(np.arange(len(mlp_data['Score'])) + 0.4, mlp_data['Score'], width = 0.1, label = 'MLP')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSxxoouFVlb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "2985a9e1-7e2f-4b0d-8669-4ea8b898f8fc"
      },
      "source": [
        "plt.title(\"MAE\")\n",
        "plt.bar([\"Variant 1\", \"Variant 2\", \"Variant 3\", \"Variant 4\", \"Variant 5\", \"Merged\"], list(poly_df[\"Mean Absolute Error\"]), width = 0.1, label = 'Poly Reg')\n",
        "plt.bar(np.arange(len(list(tree_df[\"Mean Absolute Error\"]))) + 0.1, list(tree_df[\"Mean Absolute Error\"]), width = 0.1, label = 'DT')\n",
        "plt.bar(np.arange(len(rfr_data['Mean Absolute Error'])) + 0.2, rfr_data['Mean Absolute Error'], width = 0.1, label = 'RFR')\n",
        "plt.bar(np.arange(len(gbr_data['Mean Absolute Error'])) + 0.3, gbr_data['Mean Absolute Error'], width = 0.1, label = 'GBR')\n",
        "plt.bar(np.arange(len(mlp_data['Mean Absolute Error'])) + 0.4, mlp_data['Mean Absolute Error'], width = 0.1, label = 'MLP')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laHr9KLQHX_Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "360b49cf-ed62-4af6-e6b2-52d2a02df636"
      },
      "source": [
        "plt.title(\"Hits@10\")\n",
        "plt.bar([\"Variant 1\", \"Variant 2\", \"Variant 3\", \"Variant 4\", \"Variant 5\", \"Merged\"], poly_hits_data['Hits@10'], width = 0.1, label = 'Poly Reg')\n",
        "plt.bar(np.arange(len(tree_hits_data['Hits@10'])) + 0.1, tree_hits_data['Hits@10'], width = 0.1, label = 'DT')\n",
        "plt.bar(np.arange(len(rfr_hits_data['Hits@10'])) + 0.2, rfr_hits_data['Hits@10'], width = 0.1, label = 'RFR')\n",
        "plt.bar(np.arange(len(gbr_hits_data['Hits@10'])) + 0.3, gbr_hits_data['Hits@10'], width = 0.1, label = 'GBR')\n",
        "plt.bar(np.arange(len(mlp_hits_data['Hits@10'])) + 0.4, mlp_hits_data['Hits@10'], width = 0.1, label = 'MLP')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWS6MpwOWCCH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "488b3d79-ea85-48de-a062-c4e3f5f4be17"
      },
      "source": [
        "plt.title(\"Time taken\")\n",
        "plt.bar([\"Variant 1\", \"Variant 2\", \"Variant 3\", \"Variant 4\", \"Variant 5\", \"Merged\"], list(poly_df[\"Time Taken\"]), width = 0.1, label = 'Poly Reg')\n",
        "plt.bar(np.arange(len(list(tree_df[\"Time Taken\"]))) + 0.1, list(tree_df[\"Time Taken\"]), width = 0.1, label = 'DT')\n",
        "plt.bar(np.arange(len(rfr_data['Time Taken'])) + 0.2, rfr_data['Time Taken'], width = 0.1, label = 'RFR')\n",
        "plt.bar(np.arange(len(gbr_data['Time Taken'])) + 0.3, gbr_data['Time Taken'], width = 0.1, label = 'GBR')\n",
        "plt.bar(np.arange(len(mlp_data['Time Taken'])) + 0.4, mlp_data['Time Taken'], width = 0.1, label = 'MLP')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtdHoGnXwh3g"
      },
      "source": [
        "# Methods\n",
        "\n",
        "1. log target variable\n",
        "2. sqrt target variable\n",
        "3. boxcox target variable\n",
        "\n",
        "If the model used `target+1` remember to -1 aft prediction.\n",
        "\n",
        "Imputation of target not used since imputation is more for missing values.\n",
        "\n",
        "Since the 0s are true values (not due to sensitivity of instruments, or no data), can consider a mixture of models. Part of the model determines the probability of 0, the other part determines the distribution of the data when it is positive.\n",
        "* See: https://robjhyndman.com/hyndsight/transformations/\n",
        "\n",
        "Use generalized linear models to predict targets that arent normally distributed?\n",
        "* GammaRegressor - http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.GammaRegressor.html\n",
        "* PoissonRegressor\n",
        "* TweedieRegressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6myJfblFuRQF"
      },
      "source": [
        "n_bins = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJbsL3JUsg1i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "8685022d-d500-4ba2-8adc-d1fa77476d7d"
      },
      "source": [
        "print(merged_df[\"target\"].skew())\n",
        "\n",
        "plt.hist(merged_df[\"target\"], bins=n_bins);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.21490543026231976\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FmBvs0B1gpX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "5f1e2101-61c0-4125-e0d2-43f5a2686d13"
      },
      "source": [
        "h_loc_0 = merged_df[\"h_local\"][merged_df[\"target\"] == 0]\n",
        "plt.hist(h_loc_0, bins=n_bins);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_pe5BQZ6qhA"
      },
      "source": [
        "test = merged_df[\"target\"].apply(lambda x: 1 if x != 0 else 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy498iiQ6yaS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "6c68ed67-d6b0-4c46-c4ad-a15e58089406"
      },
      "source": [
        "plt.hist(test, bins=3);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNvAgYQWsYU6"
      },
      "source": [
        "merged_df[\"target2\"] = merged_df[\"target\"].apply(lambda x: x+1)\n",
        "merged_df[\"target3\"] = merged_df[\"target\"].apply(lambda x: 0.0001 if x == 0 else x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC7HRIWcq7Hn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "7d84d49f-bc0a-4983-d14d-0703f25213f3"
      },
      "source": [
        "target_log = np.log(merged_df[\"target2\"])\n",
        "print(target_log.skew())\n",
        "\n",
        "plt.hist(target_log, bins=n_bins);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.21490543026231973\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T1WEttPt_oA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "25dbda65-b7d8-427c-f154-a672a5c65617"
      },
      "source": [
        "target_sqrt = np.sqrt(merged_df[\"target\"])\n",
        "print(target_sqrt.skew())\n",
        "\n",
        "plt.hist(target_sqrt, bins=n_bins);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.21490543026231976\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fICsjxfPu843"
      },
      "source": [
        "from scipy import stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOme2PjSu6KH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "b7e8553c-060e-482c-f27b-cfe54993c033"
      },
      "source": [
        "target_bc = stats.boxcox(merged_df[\"target2\"])[0]\n",
        "target_bc = pd.Series(target_bc)\n",
        "print(target_bc.skew())\n",
        "\n",
        "plt.hist(target_bc, bins=n_bins);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.21490543026232\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}